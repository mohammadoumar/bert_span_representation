{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "727a80c2",
   "metadata": {},
   "source": [
    "# Implementation of the Kuribayashi BERT minus model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9a0108",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "831997f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.25.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2021.10.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.0.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.28.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.5)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.5)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (58.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: IProgress in /opt/conda/lib/python3.8/site-packages (0.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from IProgress) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.8/site-packages (1.15.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets) (1.21.2)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.8/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.11.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (2.0.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch-lr-finder in /opt/conda/lib/python3.8/site-packages (0.2.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from torch-lr-finder) (3.4.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from torch-lr-finder) (4.62.3)\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from torch-lr-finder) (1.10.0a0+0aef44c)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torch-lr-finder) (1.21.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from torch-lr-finder) (21.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=0.4.1->torch-lr-finder) (3.10.0.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->torch-lr-finder) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->torch-lr-finder) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib->torch-lr-finder) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->torch-lr-finder) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->torch-lr-finder) (1.3.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->torch-lr-finder) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers --upgrade\n",
    "!pip install ipywidgets\n",
    "!pip install IProgress\n",
    "!pip install datasets\n",
    "!pip install torch-lr-finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f03e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import BertModel, BertForSequenceClassification\n",
    "from transformers import BatchEncoding, default_data_collator, DataCollatorWithPadding\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import datasets\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f848efb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.25.1\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831ac856",
   "metadata": {},
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d2dc65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e24b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbdd1c9",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "166a965d",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "0c699094-439f-4dda-85a9-815e7948540c",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "# DATA_FOLDER = '/notebooks/Data/bert_sequence_classification'\n",
    "DATA_FILE = '/notebooks/KURI-BERT/notebooks/full_formula_w_fts/pe_dataset_for_bert_minus_w_fts.pt'\n",
    "RESULTS_FOLDER = '/notebooks/KURI-BERT/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86ab0c4a",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "35aada91-232a-421e-a28f-94b359c6d65d",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "924d435b",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "dc52e71e-65fa-4946-acdf-e4fffe9d0f79",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cccfc2e",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "013a6d64-65e7-4189-a468-40ecfd8a6736",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a8f0832",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "626737f9-ff56-4992-b72b-60750375e455",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "dataset = torch.load(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c85457c",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 6,
     "id": "4fbfcc7b-55fb-456e-ab02-2ae975803046",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['paragraph', 'paragraph_components_list', 'paragraph_labels_list', 'paragraph_markers_list', 'split', 'essay_nr', 'paragraph_fts_as_txt_list', 'paragraph_labels', 'paragraph_ac_spans', 'paragraph_am_spans', 'paragraph_w_fts_as_txt', 'ac_spans_new', 'sanity_new', 'am_spans_new', 'feature_spans_new'],\n",
       "        num_rows: 1088\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['paragraph', 'paragraph_components_list', 'paragraph_labels_list', 'paragraph_markers_list', 'split', 'essay_nr', 'paragraph_fts_as_txt_list', 'paragraph_labels', 'paragraph_ac_spans', 'paragraph_am_spans', 'paragraph_w_fts_as_txt', 'ac_spans_new', 'sanity_new', 'am_spans_new', 'feature_spans_new'],\n",
       "        num_rows: 358\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['paragraph', 'paragraph_components_list', 'paragraph_labels_list', 'paragraph_markers_list', 'split', 'essay_nr', 'paragraph_fts_as_txt_list', 'paragraph_labels', 'paragraph_ac_spans', 'paragraph_am_spans', 'paragraph_w_fts_as_txt', 'ac_spans_new', 'sanity_new', 'am_spans_new', 'feature_spans_new'],\n",
       "        num_rows: 273\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bb3c716",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[23, 50], [75, 102], [142, 169]],\n",
       " [[47, 74], [111, 138], [159, 186]],\n",
       " [[25, 52], [72, 99], [132, 159]],\n",
       " [[21, 48], [85, 112]],\n",
       " [[14, 41], [75, 102], [118, 145], [158, 185]],\n",
       " [[9, 36],\n",
       "  [51, 78],\n",
       "  [97, 124],\n",
       "  [138, 165],\n",
       "  [177, 204],\n",
       "  [228, 255],\n",
       "  [280, 307]],\n",
       " [[23, 50], [60, 87], [102, 129], [163, 190]],\n",
       " [[43, 70]],\n",
       " [[22, 49], [68, 95]],\n",
       " [[19, 46], [76, 103], [116, 143]],\n",
       " [[25, 52], [78, 105], [130, 157], [174, 201]],\n",
       " [[21, 48], [62, 89], [105, 132], [145, 172], [192, 219]],\n",
       " [[31, 58]],\n",
       " [[61, 88]],\n",
       " [[31, 58], [84, 111], [145, 172], [206, 233]],\n",
       " [[19, 46], [65, 92], [116, 143], [163, 190], [210, 237]],\n",
       " [[81, 108], [130, 157]],\n",
       " [[32, 59], [69, 96]],\n",
       " [[23, 50], [64, 91], [110, 137], [155, 182], [201, 228]],\n",
       " [[16, 43], [59, 86], [111, 138], [152, 179], [195, 222], [244, 271]],\n",
       " [[18, 45], [70, 97], [113, 140], [165, 192]],\n",
       " [[16, 43], [53, 80], [101, 128], [145, 172], [199, 226], [251, 278]],\n",
       " [[19, 46],\n",
       "  [71, 98],\n",
       "  [127, 154],\n",
       "  [174, 201],\n",
       "  [230, 257],\n",
       "  [283, 310],\n",
       "  [344, 371]],\n",
       " [[24, 51], [66, 93]],\n",
       " [[26, 53]],\n",
       " [[11, 38], [50, 77], [92, 119], [139, 166], [209, 236]],\n",
       " [[57, 84]],\n",
       " [[14, 41], [55, 82], [137, 164]],\n",
       " [[24, 51], [76, 103], [121, 148]],\n",
       " [[17, 44], [70, 97], [116, 143], [176, 203]],\n",
       " [[11, 38], [79, 106], [143, 170], [186, 213], [235, 262], [276, 303]],\n",
       " [[90, 117], [132, 159]],\n",
       " [[21, 48]],\n",
       " [[15, 42], [61, 88], [96, 123], [139, 166], [200, 227]],\n",
       " [[19, 46], [65, 92], [115, 142]],\n",
       " [[20, 47], [70, 97], [125, 152], [169, 196]],\n",
       " [[17, 44],\n",
       "  [59, 86],\n",
       "  [103, 130],\n",
       "  [152, 179],\n",
       "  [200, 227],\n",
       "  [251, 278],\n",
       "  [301, 328]],\n",
       " [[18, 45], [78, 105], [134, 161], [185, 212]],\n",
       " [[16, 43], [61, 88], [117, 144], [176, 203], [226, 253]],\n",
       " [[60, 87]],\n",
       " [[10, 37],\n",
       "  [57, 84],\n",
       "  [102, 129],\n",
       "  [139, 166],\n",
       "  [179, 206],\n",
       "  [215, 242],\n",
       "  [259, 286]],\n",
       " [[14, 41], [61, 88], [112, 139], [159, 186]],\n",
       " [[11, 38],\n",
       "  [51, 78],\n",
       "  [94, 121],\n",
       "  [135, 162],\n",
       "  [178, 205],\n",
       "  [220, 247],\n",
       "  [269, 296],\n",
       "  [314, 341]],\n",
       " [[21, 48], [70, 97], [126, 153]],\n",
       " [[61, 88]],\n",
       " [[11, 38],\n",
       "  [49, 76],\n",
       "  [110, 137],\n",
       "  [165, 192],\n",
       "  [212, 239],\n",
       "  [259, 286],\n",
       "  [309, 336]],\n",
       " [[14, 41], [61, 88]],\n",
       " [[67, 94]],\n",
       " [[22, 49], [67, 94], [107, 134], [170, 197], [223, 250], [271, 298]],\n",
       " [[33, 60], [94, 121]],\n",
       " [[55, 82], [98, 125], [152, 179], [214, 241]],\n",
       " [[14, 41], [62, 89], [115, 142], [171, 198], [221, 248], [271, 298]],\n",
       " [[22, 49], [74, 101]],\n",
       " [[27, 54]],\n",
       " [[24, 51], [77, 104], [131, 158]],\n",
       " [[31, 58]],\n",
       " [[16, 43], [70, 97], [112, 139], [158, 185], [216, 243], [279, 306]],\n",
       " [[11, 38], [53, 80], [104, 131]],\n",
       " [[14, 41],\n",
       "  [58, 85],\n",
       "  [109, 136],\n",
       "  [158, 185],\n",
       "  [211, 238],\n",
       "  [267, 294],\n",
       "  [329, 356]],\n",
       " [[79, 106]],\n",
       " [[16, 43], [58, 85], [117, 144], [181, 208], [233, 260], [282, 309]],\n",
       " [[79, 106]],\n",
       " [[20, 47], [62, 89], [118, 145], [177, 204], [226, 253], [266, 293]],\n",
       " [[61, 88], [110, 137], [169, 196], [215, 242]],\n",
       " [[26, 53], [67, 94], [117, 144], [158, 185], [220, 247]],\n",
       " [[15, 42], [78, 105], [137, 164]],\n",
       " [[17, 44], [59, 86], [107, 134], [152, 179], [220, 247]],\n",
       " [[20, 47], [72, 99], [113, 140], [165, 192], [212, 239]],\n",
       " [[21, 48]],\n",
       " [[15, 42], [65, 92], [118, 145], [161, 188], [202, 229], [254, 281]],\n",
       " [[35, 62]],\n",
       " [[65, 92]],\n",
       " [[31, 58], [97, 124], [143, 170], [202, 229], [252, 279]],\n",
       " [[15, 42], [99, 126], [171, 198]],\n",
       " [[10, 37], [49, 76]],\n",
       " [[62, 89]],\n",
       " [[15, 42], [75, 102], [134, 161]],\n",
       " [[21, 48], [71, 98], [112, 139], [168, 195], [214, 241]],\n",
       " [[43, 70]],\n",
       " [[30, 57], [81, 108], [134, 161], [180, 207], [226, 253]],\n",
       " [[32, 59],\n",
       "  [79, 106],\n",
       "  [143, 170],\n",
       "  [189, 216],\n",
       "  [236, 263],\n",
       "  [279, 306],\n",
       "  [325, 352]],\n",
       " [[10, 37], [55, 82], [92, 119], [141, 168], [197, 224], [266, 293]],\n",
       " [[22, 49], [68, 95], [129, 156], [192, 219], [234, 261]],\n",
       " [[94, 121]],\n",
       " [[22, 49], [61, 88], [106, 133], [158, 185], [203, 230]],\n",
       " [[22, 49], [85, 112], [136, 163], [178, 205], [231, 258], [274, 301]],\n",
       " [[9, 36],\n",
       "  [55, 82],\n",
       "  [106, 133],\n",
       "  [150, 177],\n",
       "  [208, 235],\n",
       "  [248, 275],\n",
       "  [298, 325]],\n",
       " [[20, 47], [60, 87], [112, 139]],\n",
       " [[22, 49], [74, 101], [123, 150], [167, 194], [218, 245], [266, 293]],\n",
       " [[42, 69]],\n",
       " [[16, 43], [65, 92]],\n",
       " [[18, 45], [58, 85], [99, 126], [146, 173], [187, 214]],\n",
       " [[16, 43],\n",
       "  [58, 85],\n",
       "  [123, 150],\n",
       "  [168, 195],\n",
       "  [217, 244],\n",
       "  [268, 295],\n",
       "  [319, 346]],\n",
       " [[23, 50], [63, 90], [109, 136], [157, 184], [211, 238]],\n",
       " [[31, 58], [86, 113], [122, 149], [216, 243]],\n",
       " [[15, 42], [70, 97], [128, 155], [180, 207]],\n",
       " [[52, 79]],\n",
       " [[32, 59], [74, 101], [119, 146], [171, 198]],\n",
       " [[14, 41],\n",
       "  [64, 91],\n",
       "  [100, 127],\n",
       "  [143, 170],\n",
       "  [207, 234],\n",
       "  [244, 271],\n",
       "  [283, 310],\n",
       "  [325, 352],\n",
       "  [374, 401],\n",
       "  [417, 444],\n",
       "  [454, 481]],\n",
       " [[15, 42],\n",
       "  [60, 87],\n",
       "  [101, 128],\n",
       "  [145, 172],\n",
       "  [190, 217],\n",
       "  [256, 283],\n",
       "  [304, 331],\n",
       "  [345, 372],\n",
       "  [389, 416]],\n",
       " [[39, 66], [113, 140], [176, 203], [216, 243]],\n",
       " [[23, 50], [70, 97], [120, 147], [175, 202]],\n",
       " [[16, 43], [70, 97], [122, 149], [174, 201]],\n",
       " [[12, 39], [55, 82], [105, 132], [147, 174]],\n",
       " [[24, 51], [84, 111], [131, 158]],\n",
       " [[29, 56], [93, 120], [146, 173], [207, 234]],\n",
       " [[42, 69]],\n",
       " [[40, 67], [84, 111], [136, 163]],\n",
       " [[52, 79], [98, 125], [146, 173]],\n",
       " [[25, 52], [82, 109]],\n",
       " [[39, 66]],\n",
       " [[62, 89]],\n",
       " [[24, 51], [80, 107]],\n",
       " [[22, 49],\n",
       "  [68, 95],\n",
       "  [122, 149],\n",
       "  [165, 192],\n",
       "  [205, 232],\n",
       "  [250, 277],\n",
       "  [296, 323],\n",
       "  [333, 360],\n",
       "  [383, 410],\n",
       "  [424, 451],\n",
       "  [471, 498]],\n",
       " [[23, 50], [72, 99], [141, 168]],\n",
       " [[18, 45], [69, 96]],\n",
       " [[35, 62], [89, 116], [132, 159], [188, 215]],\n",
       " [[19, 46], [68, 95], [112, 139], [168, 195]],\n",
       " [[21, 48]],\n",
       " [[80, 107]],\n",
       " [[16, 43], [69, 96], [126, 153], [163, 190], [199, 226]],\n",
       " [[32, 59], [80, 107], [135, 162], [203, 230]],\n",
       " [[31, 58], [79, 106], [129, 156]],\n",
       " [[24, 51]],\n",
       " [[21, 48], [62, 89], [101, 128], [144, 171]],\n",
       " [[12, 39], [61, 88], [112, 139], [152, 179]],\n",
       " [[56, 83]],\n",
       " [[64, 91]],\n",
       " [[18, 45], [67, 94], [119, 146]],\n",
       " [[13, 40], [63, 90], [111, 138], [159, 186]],\n",
       " [[15, 42], [63, 90], [109, 136], [154, 181], [204, 231], [242, 269]],\n",
       " [[41, 68]],\n",
       " [[66, 93]],\n",
       " [[31, 58], [82, 109], [140, 167], [191, 218]],\n",
       " [[91, 118]],\n",
       " [[19, 46], [61, 88], [114, 141]],\n",
       " [[25, 52],\n",
       "  [65, 92],\n",
       "  [105, 132],\n",
       "  [150, 177],\n",
       "  [201, 228],\n",
       "  [244, 271],\n",
       "  [299, 326]],\n",
       " [[26, 53], [80, 107]],\n",
       " [[26, 53], [78, 105], [123, 150]],\n",
       " [[31, 58], [84, 111]],\n",
       " [[27, 54], [73, 100], [119, 146], [163, 190]],\n",
       " [[21, 48], [58, 85], [99, 126]],\n",
       " [[36, 63], [88, 115]],\n",
       " [[16, 43], [61, 88]],\n",
       " [[12, 39], [71, 98], [119, 146], [167, 194]],\n",
       " [[18, 45], [65, 92], [110, 137], [150, 177], [190, 217], [238, 265]],\n",
       " [[35, 62], [89, 116], [143, 170], [194, 221]],\n",
       " [[26, 53], [74, 101], [123, 150], [181, 208], [235, 262], [286, 313]],\n",
       " [[14, 41], [57, 84], [98, 125]],\n",
       " [[12, 39], [54, 81], [112, 139], [183, 210], [229, 256], [274, 301]],\n",
       " [[26, 53], [76, 103], [137, 164], [185, 212]],\n",
       " [[19, 46], [75, 102], [131, 158], [184, 211]],\n",
       " [[28, 55]],\n",
       " [[22, 49], [81, 108], [125, 152], [172, 199]],\n",
       " [[15, 42], [53, 80], [97, 124], [155, 182]],\n",
       " [[28, 55], [78, 105], [124, 151], [177, 204], [235, 262]],\n",
       " [[31, 58], [72, 99], [137, 164]],\n",
       " [[53, 80]],\n",
       " [[25, 52],\n",
       "  [65, 92],\n",
       "  [118, 145],\n",
       "  [163, 190],\n",
       "  [209, 236],\n",
       "  [264, 291],\n",
       "  [306, 333]],\n",
       " [[14, 41], [65, 92], [108, 135], [151, 178], [210, 237], [257, 284]],\n",
       " [[17, 44], [54, 81], [101, 128]],\n",
       " [[16, 43],\n",
       "  [65, 92],\n",
       "  [113, 140],\n",
       "  [153, 180],\n",
       "  [199, 226],\n",
       "  [245, 272],\n",
       "  [283, 310],\n",
       "  [326, 353],\n",
       "  [373, 400],\n",
       "  [423, 450],\n",
       "  [462, 489],\n",
       "  [512, 539]],\n",
       " [[23, 50], [80, 107], [156, 183], [204, 231]],\n",
       " [[47, 74], [90, 117]],\n",
       " [[80, 107]],\n",
       " [[18, 45], [76, 103]],\n",
       " [[11, 38], [59, 86], [102, 129], [145, 172], [189, 216]],\n",
       " [[28, 55], [78, 105], [127, 154], [176, 203]],\n",
       " [[73, 100]],\n",
       " [[20, 47], [82, 109], [144, 171]],\n",
       " [[20, 47]],\n",
       " [[18, 45], [66, 93], [116, 143], [181, 208], [233, 260]],\n",
       " [[21, 48], [67, 94], [120, 147]],\n",
       " [[51, 78]],\n",
       " [[13, 40],\n",
       "  [59, 86],\n",
       "  [116, 143],\n",
       "  [174, 201],\n",
       "  [217, 244],\n",
       "  [284, 311],\n",
       "  [325, 352]],\n",
       " [[24, 51], [80, 107]],\n",
       " [[16, 43]],\n",
       " [[14, 41], [59, 86], [106, 133], [159, 186]],\n",
       " [[47, 74]],\n",
       " [[16, 43], [70, 97], [124, 151]],\n",
       " [[13, 40], [63, 90], [104, 131], [160, 187], [209, 236], [277, 304]],\n",
       " [[41, 68]],\n",
       " [[28, 55]],\n",
       " [[16, 43], [71, 98], [116, 143], [178, 205], [228, 255]],\n",
       " [[89, 116], [130, 157]],\n",
       " [[24, 51], [120, 147], [160, 187], [223, 250]],\n",
       " [[19, 46], [62, 89], [168, 195]],\n",
       " [[15, 42], [81, 108], [141, 168]],\n",
       " [[17, 44], [63, 90], [112, 139], [167, 194], [218, 245]],\n",
       " [[25, 52], [94, 121], [142, 169]],\n",
       " [[49, 76]],\n",
       " [[13, 40], [66, 93]],\n",
       " [[23, 50], [66, 93], [115, 142], [168, 195], [218, 245]],\n",
       " [[30, 57], [86, 113], [129, 156]],\n",
       " [[12, 39], [65, 92], [111, 138], [156, 183], [201, 228], [246, 273]],\n",
       " [[18, 45], [55, 82], [98, 125], [139, 166]],\n",
       " [[14, 41],\n",
       "  [67, 94],\n",
       "  [114, 141],\n",
       "  [151, 178],\n",
       "  [189, 216],\n",
       "  [231, 258],\n",
       "  [277, 304],\n",
       "  [336, 363],\n",
       "  [380, 407],\n",
       "  [434, 461]],\n",
       " [[88, 115]],\n",
       " [[23, 50], [67, 94], [118, 145], [174, 201], [213, 240], [252, 279]],\n",
       " [[15, 42], [68, 95]],\n",
       " [[83, 110]],\n",
       " [[20, 47],\n",
       "  [73, 100],\n",
       "  [113, 140],\n",
       "  [156, 183],\n",
       "  [197, 224],\n",
       "  [240, 267],\n",
       "  [277, 304],\n",
       "  [316, 343]],\n",
       " [[17, 44], [81, 108], [141, 168], [186, 213], [231, 258]],\n",
       " [[14, 41], [74, 101]],\n",
       " [[28, 55], [91, 118], [154, 181], [213, 240]],\n",
       " [[26, 53], [80, 107]],\n",
       " [[17, 44], [82, 109], [126, 153], [183, 210], [237, 264], [281, 308]],\n",
       " [[27, 54], [80, 107], [122, 149], [183, 210]],\n",
       " [[11, 38],\n",
       "  [48, 75],\n",
       "  [84, 111],\n",
       "  [119, 146],\n",
       "  [167, 194],\n",
       "  [210, 237],\n",
       "  [252, 279]],\n",
       " [[65, 92]],\n",
       " [[45, 72], [104, 131]],\n",
       " [[27, 54], [71, 98], [120, 147], [161, 188]],\n",
       " [[28, 55], [73, 100], [112, 139], [167, 194], [217, 244]],\n",
       " [[21, 48], [64, 91], [115, 142], [166, 193]],\n",
       " [[41, 68], [84, 111]],\n",
       " [[19, 46]],\n",
       " [[13, 40], [67, 94]],\n",
       " [[12, 39],\n",
       "  [67, 94],\n",
       "  [118, 145],\n",
       "  [153, 180],\n",
       "  [191, 218],\n",
       "  [228, 255],\n",
       "  [272, 299]],\n",
       " [[18, 45],\n",
       "  [65, 92],\n",
       "  [111, 138],\n",
       "  [160, 187],\n",
       "  [212, 239],\n",
       "  [270, 297],\n",
       "  [326, 353]],\n",
       " [[21, 48], [65, 92], [128, 155]],\n",
       " [[44, 71], [81, 108]],\n",
       " [[15, 42], [57, 84], [98, 125], [146, 173]],\n",
       " [[24, 51], [63, 90], [104, 131], [159, 186], [218, 245], [270, 297]],\n",
       " [[15, 42], [62, 89], [112, 139], [179, 206]],\n",
       " [[36, 63], [104, 131], [165, 192]],\n",
       " [[20, 47]],\n",
       " [[23, 50],\n",
       "  [85, 112],\n",
       "  [127, 154],\n",
       "  [183, 210],\n",
       "  [230, 257],\n",
       "  [275, 302],\n",
       "  [318, 345],\n",
       "  [364, 391]],\n",
       " [[20, 47], [64, 91]],\n",
       " [[62, 89]],\n",
       " [[15, 42], [62, 89], [111, 138], [169, 196], [233, 260], [296, 323]],\n",
       " [[34, 61]],\n",
       " [[90, 117]],\n",
       " [[17, 44], [68, 95], [114, 141], [155, 182], [212, 239], [262, 289]],\n",
       " [[20, 47],\n",
       "  [72, 99],\n",
       "  [119, 146],\n",
       "  [160, 187],\n",
       "  [209, 236],\n",
       "  [252, 279],\n",
       "  [292, 319]],\n",
       " [[19, 46], [71, 98], [124, 151]],\n",
       " [[21, 48], [61, 88], [103, 130], [157, 184], [215, 242]],\n",
       " [[61, 88], [113, 140]],\n",
       " [[33, 60], [80, 107], [124, 151], [186, 213]],\n",
       " [[112, 139]],\n",
       " [[41, 68]],\n",
       " [[29, 56], [88, 115], [155, 182], [208, 235]],\n",
       " [[25, 52], [80, 107], [143, 170], [189, 216]],\n",
       " [[31, 58], [84, 111], [143, 170], [194, 221], [237, 264], [276, 303]],\n",
       " [[19, 46], [60, 87]],\n",
       " [[53, 80]],\n",
       " [[13, 40], [62, 89], [113, 140], [157, 184]],\n",
       " [[29, 56], [77, 104], [118, 145], [160, 187], [219, 246]],\n",
       " [[79, 106]],\n",
       " [[29, 56], [80, 107], [132, 159]],\n",
       " [[35, 62]],\n",
       " [[24, 51], [73, 100], [111, 138], [172, 199], [212, 239], [266, 293]],\n",
       " [[71, 98], [112, 139]],\n",
       " [[21, 48], [73, 100], [115, 142], [165, 192], [209, 236]],\n",
       " [[20, 47], [68, 95], [119, 146], [181, 208]],\n",
       " [[13, 40], [57, 84], [102, 129], [150, 177]],\n",
       " [[26, 53], [83, 110], [141, 168]],\n",
       " [[31, 58], [78, 105]],\n",
       " [[19, 46], [69, 96], [113, 140]],\n",
       " [[27, 54], [85, 112], [136, 163]],\n",
       " [[11, 38], [55, 82], [130, 157], [177, 204], [229, 256], [275, 302]],\n",
       " [[14, 41], [53, 80], [98, 125], [150, 177]],\n",
       " [[75, 102]],\n",
       " [[28, 55], [71, 98]],\n",
       " [[20, 47], [68, 95]],\n",
       " [[15, 42],\n",
       "  [69, 96],\n",
       "  [113, 140],\n",
       "  [165, 192],\n",
       "  [208, 235],\n",
       "  [264, 291],\n",
       "  [304, 331]],\n",
       " [[27, 54]],\n",
       " [[52, 79]],\n",
       " [[16, 43], [69, 96], [120, 147], [183, 210], [235, 262]],\n",
       " [[93, 120]],\n",
       " [[19, 46], [72, 99]],\n",
       " [[6, 33], [63, 90], [110, 137], [157, 184], [204, 231], [244, 271]],\n",
       " [[25, 52], [71, 98], [126, 153], [182, 209], [259, 286]],\n",
       " [[26, 53], [72, 99], [124, 151]],\n",
       " [[17, 44], [58, 85], [112, 139], [191, 218], [230, 257]],\n",
       " [[22, 49]],\n",
       " [[81, 108]],\n",
       " [[32, 59], [85, 112], [133, 160]],\n",
       " [[33, 60], [85, 112], [138, 165], [216, 243]],\n",
       " [[13, 40], [60, 87], [108, 135], [149, 176], [187, 214], [240, 267]],\n",
       " [[17, 44], [63, 90], [103, 130], [157, 184]],\n",
       " [[20, 47]],\n",
       " [[25, 52]],\n",
       " [[55, 82]],\n",
       " [[22, 49], [61, 88], [107, 134], [150, 177], [193, 220], [244, 271]],\n",
       " [[10, 37], [71, 98], [141, 168], [198, 225]],\n",
       " [[33, 60], [87, 114]],\n",
       " [[77, 104]],\n",
       " [[28, 55], [97, 124], [146, 173], [208, 235]],\n",
       " [[28, 55], [97, 124], [145, 172]],\n",
       " [[9, 36], [49, 76], [93, 120], [143, 170]],\n",
       " [[31, 58], [83, 110], [131, 158], [185, 212]],\n",
       " [[96, 123]],\n",
       " [[78, 105]],\n",
       " [[27, 54], [66, 93], [131, 158]],\n",
       " [[12, 39], [63, 90]],\n",
       " [[14, 41], [67, 94]],\n",
       " [[56, 83], [107, 134]],\n",
       " [[21, 48], [73, 100], [115, 142], [157, 184], [200, 227]],\n",
       " [[20, 47], [75, 102]],\n",
       " [[22, 49], [78, 105], [117, 144], [188, 215], [231, 258]],\n",
       " [[24, 51]],\n",
       " [[14, 41], [55, 82], [113, 140]],\n",
       " [[31, 58]],\n",
       " [[15, 42], [70, 97]],\n",
       " [[15, 42], [70, 97], [119, 146], [169, 196]],\n",
       " [[76, 103]],\n",
       " [[17, 44], [73, 100], [143, 170], [192, 219], [238, 265]],\n",
       " [[36, 63], [81, 108], [134, 161]],\n",
       " [[13, 40]],\n",
       " [[23, 50],\n",
       "  [66, 93],\n",
       "  [110, 137],\n",
       "  [150, 177],\n",
       "  [192, 219],\n",
       "  [241, 268],\n",
       "  [289, 316],\n",
       "  [332, 359],\n",
       "  [376, 403]],\n",
       " [[30, 57], [98, 125], [139, 166]],\n",
       " [[64, 91]],\n",
       " [[18, 45], [89, 116], [139, 166]],\n",
       " [[12, 39], [61, 88], [110, 137], [170, 197], [221, 248], [269, 296]],\n",
       " [[23, 50], [69, 96], [108, 135], [163, 190], [212, 239], [259, 286]],\n",
       " [[33, 60], [80, 107]],\n",
       " [[40, 67]],\n",
       " [[16, 43], [62, 89], [103, 130], [169, 196], [233, 260]],\n",
       " [[14, 41], [55, 82], [97, 124], [145, 172], [184, 211]],\n",
       " [[23, 50],\n",
       "  [68, 95],\n",
       "  [114, 141],\n",
       "  [172, 199],\n",
       "  [225, 252],\n",
       "  [268, 295],\n",
       "  [327, 354]],\n",
       " [[19, 46], [76, 103], [117, 144]],\n",
       " [[62, 89]],\n",
       " [[69, 96]],\n",
       " [[23, 50], [67, 94]],\n",
       " [[10, 37], [61, 88], [105, 132], [152, 179], [200, 227], [254, 281]],\n",
       " [[27, 54], [71, 98], [116, 143], [163, 190], [211, 238], [263, 290]],\n",
       " [[51, 78], [96, 123], [142, 169]],\n",
       " [[17, 44], [76, 103], [118, 145], [168, 195]],\n",
       " [[12, 39], [62, 89]],\n",
       " [[34, 61], [82, 109]],\n",
       " [[20, 47], [85, 112]],\n",
       " [[46, 73], [102, 129]],\n",
       " [[27, 54], [71, 98], [137, 164], [206, 233]],\n",
       " [[58, 85]],\n",
       " [[12, 39],\n",
       "  [67, 94],\n",
       "  [130, 157],\n",
       "  [169, 196],\n",
       "  [219, 246],\n",
       "  [265, 292],\n",
       "  [318, 345]],\n",
       " [[70, 97]],\n",
       " [[14, 41], [67, 94], [123, 150]],\n",
       " [[38, 65], [94, 121]],\n",
       " [[15, 42], [56, 83], [111, 138], [152, 179], [198, 225]],\n",
       " [[19, 46], [70, 97], [137, 164], [209, 236]],\n",
       " [[12, 39], [58, 85], [129, 156]],\n",
       " [[88, 115]],\n",
       " [[13, 40],\n",
       "  [62, 89],\n",
       "  [104, 131],\n",
       "  [146, 173],\n",
       "  [184, 211],\n",
       "  [236, 263],\n",
       "  [281, 308],\n",
       "  [328, 355]],\n",
       " [[28, 55], [75, 102], [138, 165], [175, 202]],\n",
       " [[27, 54], [91, 118], [136, 163], [174, 201], [216, 243]],\n",
       " [[12, 39],\n",
       "  [54, 81],\n",
       "  [92, 119],\n",
       "  [141, 168],\n",
       "  [179, 206],\n",
       "  [226, 253],\n",
       "  [273, 300]],\n",
       " [[31, 58]],\n",
       " [[12, 39], [66, 93], [114, 141]],\n",
       " [[38, 65], [89, 116], [142, 169], [198, 225]],\n",
       " [[23, 50],\n",
       "  [70, 97],\n",
       "  [111, 138],\n",
       "  [170, 197],\n",
       "  [216, 243],\n",
       "  [266, 293],\n",
       "  [311, 338]],\n",
       " [[23, 50], [81, 108], [153, 180], [199, 226], [248, 275]],\n",
       " [[27, 54], [73, 100], [118, 145]],\n",
       " [[41, 68], [85, 112]],\n",
       " [[17, 44], [71, 98], [119, 146], [180, 207], [230, 257], [298, 325]],\n",
       " [[10, 37], [62, 89], [119, 146], [183, 210], [229, 256], [281, 308]],\n",
       " [[23, 50],\n",
       "  [69, 96],\n",
       "  [114, 141],\n",
       "  [167, 194],\n",
       "  [209, 236],\n",
       "  [248, 275],\n",
       "  [289, 316]],\n",
       " [[30, 57], [78, 105]],\n",
       " [[10, 37], [69, 96]],\n",
       " [[21, 48]],\n",
       " [[20, 47], [75, 102]],\n",
       " [[43, 70], [97, 124]],\n",
       " [[49, 76], [97, 124]],\n",
       " [[13, 40], [60, 87], [139, 166]],\n",
       " [[23, 50], [83, 110], [140, 167], [207, 234]],\n",
       " [[19, 46], [61, 88], [107, 134], [151, 178], [189, 216], [232, 259]],\n",
       " [[31, 58], [99, 126]],\n",
       " [[22, 49], [81, 108]],\n",
       " [[27, 54], [92, 119], [144, 171], [187, 214]],\n",
       " [[13, 40], [74, 101], [121, 148], [171, 198]],\n",
       " [[21, 48]],\n",
       " [[16, 43],\n",
       "  [64, 91],\n",
       "  [110, 137],\n",
       "  [159, 186],\n",
       "  [201, 228],\n",
       "  [250, 277],\n",
       "  [293, 320],\n",
       "  [337, 364],\n",
       "  [379, 406],\n",
       "  [422, 449]],\n",
       " [[23, 50], [87, 114], [141, 168], [182, 209]],\n",
       " [[19, 46], [67, 94], [117, 144], [158, 185], [196, 223], [249, 276]],\n",
       " [[55, 82]],\n",
       " [[10, 37], [61, 88], [114, 141], [173, 200], [220, 247]],\n",
       " [[20, 47],\n",
       "  [67, 94],\n",
       "  [104, 131],\n",
       "  [151, 178],\n",
       "  [199, 226],\n",
       "  [248, 275],\n",
       "  [288, 315]],\n",
       " [[45, 72], [97, 124], [149, 176], [203, 230]],\n",
       " [[24, 51], [63, 90], [109, 136]],\n",
       " [[21, 48], [74, 101], [136, 163]],\n",
       " [[102, 129]],\n",
       " [[25, 52], [84, 111]],\n",
       " [[21, 48], [71, 98], [129, 156], [194, 221]],\n",
       " [[17, 44], [106, 133], [150, 177], [195, 222]],\n",
       " [[13, 40], [62, 89], [114, 141], [172, 199]],\n",
       " [[11, 38],\n",
       "  [55, 82],\n",
       "  [100, 127],\n",
       "  [141, 168],\n",
       "  [182, 209],\n",
       "  [224, 251],\n",
       "  [261, 288],\n",
       "  [316, 343]],\n",
       " [[21, 48], [67, 94], [132, 159], [174, 201], [217, 244]],\n",
       " [[34, 61], [79, 106], [126, 153]],\n",
       " [[15, 42], [65, 92]],\n",
       " [[89, 116], [137, 164]],\n",
       " [[21, 48], [69, 96], [104, 131], [146, 173]],\n",
       " [[69, 96]],\n",
       " [[11, 38],\n",
       "  [62, 89],\n",
       "  [109, 136],\n",
       "  [153, 180],\n",
       "  [191, 218],\n",
       "  [230, 257],\n",
       "  [278, 305],\n",
       "  [326, 353]],\n",
       " [[27, 54], [86, 113], [137, 164], [188, 215]],\n",
       " [[47, 74], [102, 129], [147, 174], [190, 217]],\n",
       " [[18, 45], [66, 93], [113, 140], [157, 184], [205, 232]],\n",
       " [[23, 50], [77, 104], [121, 148], [188, 215], [239, 266], [291, 318]],\n",
       " [[81, 108]],\n",
       " [[27, 54], [78, 105], [151, 178], [196, 223]],\n",
       " [[24, 51], [75, 102], [137, 164], [198, 225]],\n",
       " [[18, 45], [86, 113], [123, 150], [171, 198], [226, 253], [269, 296]],\n",
       " [[20, 47]],\n",
       " [[21, 48], [71, 98], [113, 140], [164, 191]],\n",
       " [[20, 47], [66, 93], [109, 136], [161, 188], [219, 246], [263, 290]],\n",
       " [[51, 78], [109, 136], [173, 200], [219, 246], [269, 296]],\n",
       " [[26, 53]],\n",
       " [[20, 47],\n",
       "  [63, 90],\n",
       "  [130, 157],\n",
       "  [169, 196],\n",
       "  [220, 247],\n",
       "  [283, 310],\n",
       "  [336, 363]],\n",
       " [[25, 52], [83, 110], [156, 183], [208, 235]],\n",
       " [[17, 44], [77, 104], [140, 167], [193, 220]],\n",
       " [[24, 51], [67, 94], [127, 154], [182, 209]],\n",
       " [[15, 42], [62, 89], [118, 145], [158, 185], [213, 240], [261, 288]],\n",
       " [[13, 40], [58, 85], [98, 125]],\n",
       " [[27, 54], [89, 116], [131, 158]],\n",
       " [[17, 44], [58, 85], [108, 135], [164, 191], [213, 240]],\n",
       " [[17, 44], [75, 102], [128, 155], [179, 206]],\n",
       " [[20, 47], [62, 89], [117, 144]],\n",
       " [[100, 127]],\n",
       " [[44, 71], [86, 113], [141, 168], [193, 220], [243, 270]],\n",
       " [[17, 44]],\n",
       " [[86, 113]],\n",
       " [[12, 39], [55, 82], [106, 133], [166, 193], [214, 241]],\n",
       " [[15, 42], [62, 89], [110, 137], [155, 182]],\n",
       " [[20, 47], [63, 90], [123, 150]],\n",
       " [[9, 36], [71, 98], [113, 140], [155, 182], [205, 232], [253, 280]],\n",
       " [[10, 37], [64, 91]],\n",
       " [[18, 45], [57, 84], [104, 131], [154, 181], [239, 266], [284, 311]],\n",
       " [[44, 71]],\n",
       " [[20, 47], [65, 92], [114, 141], [186, 213]],\n",
       " [[24, 51], [85, 112], [138, 165], [200, 227], [259, 286], [310, 337]],\n",
       " [[12, 39], [54, 81], [111, 138], [158, 185], [204, 231]],\n",
       " [[49, 76]],\n",
       " [[78, 105], [123, 150]],\n",
       " [[24, 51], [79, 106], [130, 157], [176, 203]],\n",
       " [[5, 32], [47, 74], [94, 121], [143, 170], [213, 240], [257, 284]],\n",
       " [[54, 81], [94, 121], [163, 190]],\n",
       " [[22, 49], [88, 115], [133, 160], [189, 216], [237, 264]],\n",
       " [[20, 47], [77, 104]],\n",
       " [[17, 44], [62, 89], [107, 134], [153, 180]],\n",
       " [[39, 66]],\n",
       " [[20, 47], [79, 106]],\n",
       " [[21, 48], [76, 103], [115, 142], [153, 180]],\n",
       " [[79, 106]],\n",
       " [[31, 58]],\n",
       " [[21, 48], [62, 89]],\n",
       " [[42, 69]],\n",
       " [[16, 43], [68, 95], [109, 136], [150, 177]],\n",
       " [[21, 48], [79, 106], [122, 149], [166, 193], [218, 245], [270, 297]],\n",
       " [[24, 51], [74, 101], [124, 151], [187, 214], [235, 262], [277, 304]],\n",
       " [[17, 44], [74, 101]],\n",
       " [[56, 83]],\n",
       " [[11, 38], [51, 78], [105, 132], [144, 171], [190, 217]],\n",
       " [[35, 62]],\n",
       " [[27, 54], [78, 105], [128, 155], [179, 206]],\n",
       " [[22, 49], [83, 110], [137, 164]],\n",
       " [[19, 46], [71, 98]],\n",
       " [[34, 61]],\n",
       " [[34, 61], [85, 112]],\n",
       " [[16, 43]],\n",
       " [[37, 64], [88, 115], [163, 190]],\n",
       " [[13, 40], [61, 88], [105, 132], [151, 178], [200, 227]],\n",
       " [[21, 48], [62, 89], [112, 139], [160, 187], [218, 245]],\n",
       " [[26, 53], [80, 107], [152, 179]],\n",
       " [[15, 42], [57, 84], [99, 126]],\n",
       " [[90, 117]],\n",
       " [[18, 45], [64, 91], [104, 131], [151, 178], [200, 227]],\n",
       " [[37, 64]],\n",
       " [[21, 48], [77, 104]],\n",
       " [[22, 49]],\n",
       " [[19, 46],\n",
       "  [66, 93],\n",
       "  [121, 148],\n",
       "  [175, 202],\n",
       "  [219, 246],\n",
       "  [270, 297],\n",
       "  [319, 346],\n",
       "  [362, 389],\n",
       "  [412, 439]],\n",
       " [[18, 45], [64, 91], [114, 141], [165, 192], [223, 250], [279, 306]],\n",
       " [[26, 53]],\n",
       " [[35, 62], [79, 106], [121, 148], [165, 192]],\n",
       " [[90, 117]],\n",
       " [[24, 51], [69, 96]],\n",
       " [[31, 58], [96, 123], [141, 168], [195, 222], [261, 288], [302, 329]],\n",
       " [[39, 66], [96, 123], [144, 171]],\n",
       " [[19, 46], [82, 109], [129, 156]],\n",
       " [[18, 45], [68, 95], [122, 149], [172, 199]],\n",
       " [[9, 36],\n",
       "  [50, 77],\n",
       "  [89, 116],\n",
       "  [127, 154],\n",
       "  [172, 199],\n",
       "  [215, 242],\n",
       "  [277, 304]],\n",
       " [[51, 78], [114, 141], [163, 190]],\n",
       " [[11, 38], [65, 92], [109, 136]],\n",
       " [[94, 121]],\n",
       " [[12, 39], [71, 98], [124, 151], [171, 198], [223, 250], [274, 301]],\n",
       " [[26, 53], [94, 121]],\n",
       " [[15, 42], [66, 93], [113, 140], [170, 197], [223, 250]],\n",
       " [[13, 40], [87, 114]],\n",
       " [[16, 43], [59, 86], [108, 135], [162, 189], [208, 235]],\n",
       " [[34, 61], [83, 110], [123, 150], [182, 209], [242, 269]],\n",
       " [[77, 104]],\n",
       " [[12, 39], [75, 102], [125, 152]],\n",
       " [[22, 49], [69, 96]],\n",
       " [[20, 47], [59, 86]],\n",
       " [[24, 51], [83, 110], [143, 170]],\n",
       " [[19, 46], [73, 100], [135, 162], [183, 210]],\n",
       " [[18, 45], [65, 92]],\n",
       " [[19, 46],\n",
       "  [63, 90],\n",
       "  [104, 131],\n",
       "  [151, 178],\n",
       "  [205, 232],\n",
       "  [253, 280],\n",
       "  [292, 319],\n",
       "  [351, 378]],\n",
       " [[19, 46], [62, 89], [108, 135]],\n",
       " [[25, 52], [76, 103], [139, 166]],\n",
       " [[35, 62], [89, 116], [153, 180], [209, 236], [270, 297]],\n",
       " [[65, 92], [111, 138]],\n",
       " [[36, 63], [104, 131], [148, 175], [205, 232], [268, 295]],\n",
       " [[56, 83]],\n",
       " [[32, 59], [76, 103]],\n",
       " [[19, 46], [78, 105]],\n",
       " [[34, 61], [71, 98], [112, 139], [174, 201], [223, 250]],\n",
       " [[24, 51], [77, 104]],\n",
       " [[35, 62], [78, 105]],\n",
       " [[26, 53], [93, 120]],\n",
       " [[11, 38], [68, 95], [115, 142], [173, 200], [233, 260], [281, 308]],\n",
       " [[13, 40], [70, 97], [112, 139], [160, 187], [208, 235]],\n",
       " [[80, 107]],\n",
       " [[16, 43], [64, 91], [119, 146], [166, 193]],\n",
       " [[29, 56]],\n",
       " [[12, 39], [63, 90], [102, 129], [148, 175], [210, 237], [256, 283]],\n",
       " [[19, 46]],\n",
       " [[41, 68], [96, 123]],\n",
       " [[27, 54], [98, 125], [145, 172], [195, 222], [244, 271]],\n",
       " [[22, 49], [89, 116], [144, 171], [191, 218], [256, 283]],\n",
       " [[13, 40],\n",
       "  [60, 87],\n",
       "  [99, 126],\n",
       "  [140, 167],\n",
       "  [201, 228],\n",
       "  [243, 270],\n",
       "  [283, 310]],\n",
       " [[16, 43],\n",
       "  [61, 88],\n",
       "  [103, 130],\n",
       "  [138, 165],\n",
       "  [179, 206],\n",
       "  [220, 247],\n",
       "  [272, 299]],\n",
       " [[62, 89]],\n",
       " [[21, 48], [68, 95], [122, 149], [167, 194], [235, 262], [283, 310]],\n",
       " [[22, 49], [70, 97]],\n",
       " [[18, 45],\n",
       "  [67, 94],\n",
       "  [109, 136],\n",
       "  [159, 186],\n",
       "  [204, 231],\n",
       "  [248, 275],\n",
       "  [301, 328],\n",
       "  [348, 375]],\n",
       " [[19, 46], [70, 97], [119, 146], [183, 210]],\n",
       " [[16, 43], [58, 85], [101, 128], [144, 171]],\n",
       " [[10, 37], [54, 81]],\n",
       " [[13, 40], [73, 100], [123, 150], [169, 196], [215, 242]],\n",
       " [[20, 47], [81, 108]],\n",
       " [[11, 38], [51, 78], [101, 128], [151, 178], [195, 222]],\n",
       " [[21, 48],\n",
       "  [71, 98],\n",
       "  [121, 148],\n",
       "  [174, 201],\n",
       "  [220, 247],\n",
       "  [276, 303],\n",
       "  [333, 360]],\n",
       " [[9, 36], [61, 88], [123, 150]],\n",
       " [[14, 41], [60, 87], [108, 135], [171, 198], [216, 243]],\n",
       " [[56, 83], [102, 129]],\n",
       " [[68, 95]],\n",
       " [[17, 44], [69, 96], [137, 164], [188, 215]],\n",
       " [[11, 38],\n",
       "  [58, 85],\n",
       "  [106, 133],\n",
       "  [162, 189],\n",
       "  [199, 226],\n",
       "  [240, 267],\n",
       "  [286, 313]],\n",
       " [[31, 58], [84, 111], [137, 164]],\n",
       " [[72, 99]],\n",
       " [[8, 35], [52, 79]],\n",
       " [[21, 48], [75, 102]],\n",
       " [[12, 39], [69, 96], [127, 154], [183, 210], [237, 264]],\n",
       " [[12, 39], [64, 91], [123, 150], [175, 202], [229, 256], [277, 304]],\n",
       " [[19, 46], [69, 96]],\n",
       " [[17, 44], [57, 84], [104, 131], [170, 197]],\n",
       " [[44, 71], [96, 123], [143, 170], [204, 231], [251, 278], [299, 326]],\n",
       " [[22, 49], [72, 99], [130, 157], [175, 202], [211, 238], [267, 294]],\n",
       " [[12, 39], [54, 81], [118, 145], [164, 191], [204, 231], [249, 276]],\n",
       " [[17, 44]],\n",
       " [[28, 55], [75, 102]],\n",
       " [[17, 44], [75, 102], [124, 151], [188, 215]],\n",
       " [[31, 58]],\n",
       " [[18, 45], [83, 110], [132, 159], [185, 212], [271, 298]],\n",
       " [[20, 47]],\n",
       " [[39, 66], [82, 109]],\n",
       " [[15, 42], [76, 103]],\n",
       " [[13, 40], [59, 86], [112, 139], [162, 189]],\n",
       " [[14, 41], [52, 79], [94, 121], [160, 187], [209, 236]],\n",
       " [[17, 44],\n",
       "  [67, 94],\n",
       "  [121, 148],\n",
       "  [172, 199],\n",
       "  [218, 245],\n",
       "  [261, 288],\n",
       "  [310, 337]],\n",
       " [[43, 70], [93, 120]],\n",
       " [[29, 56]],\n",
       " [[12, 39], [57, 84], [112, 139], [172, 199]],\n",
       " [[64, 91], [105, 132]],\n",
       " [[88, 115]],\n",
       " [[19, 46], [69, 96], [122, 149], [171, 198]],\n",
       " [[19, 46], [60, 87]],\n",
       " [[28, 55], [81, 108], [159, 186], [218, 245]],\n",
       " [[70, 97]],\n",
       " [[22, 49], [63, 90], [105, 132], [148, 175], [191, 218]],\n",
       " [[17, 44], [63, 90], [123, 150], [171, 198], [219, 246]],\n",
       " [[12, 39], [49, 76], [125, 152], [163, 190], [205, 232]],\n",
       " [[37, 64], [100, 127]],\n",
       " [[20, 47], [66, 93], [122, 149], [164, 191], [203, 230]],\n",
       " [[18, 45],\n",
       "  [65, 92],\n",
       "  [104, 131],\n",
       "  [162, 189],\n",
       "  [213, 240],\n",
       "  [257, 284],\n",
       "  [303, 330],\n",
       "  [350, 377]],\n",
       " [[16, 43], [73, 100]],\n",
       " [[53, 80]],\n",
       " [[16, 43], [75, 102]],\n",
       " [[26, 53], [92, 119], [137, 164], [189, 216], [240, 267]],\n",
       " [[11, 38], [54, 81], [96, 123], [163, 190]],\n",
       " [[12, 39], [70, 97], [120, 147], [165, 192], [224, 251]],\n",
       " [[32, 59], [78, 105], [142, 169], [193, 220]],\n",
       " [[20, 47], [80, 107], [120, 147], [178, 205], [222, 249]],\n",
       " [[26, 53], [81, 108]],\n",
       " [[27, 54], [82, 109], [140, 167]],\n",
       " [[11, 38], [71, 98], [124, 151], [180, 207]],\n",
       " [[23, 50], [77, 104], [135, 162]],\n",
       " [[22, 49], [76, 103], [124, 151]],\n",
       " [[19, 46], [67, 94]],\n",
       " [[34, 61]],\n",
       " [[50, 77], [103, 130]],\n",
       " [[20, 47], [77, 104], [131, 158], [179, 206]],\n",
       " [[35, 62], [93, 120], [154, 181], [216, 243], [282, 309], [322, 349]],\n",
       " [[19, 46], [61, 88]],\n",
       " [[18, 45], [81, 108], [134, 161], [177, 204]],\n",
       " [[20, 47], [80, 107], [146, 173]],\n",
       " [[55, 82]],\n",
       " [[27, 54], [89, 116]],\n",
       " [[49, 76]],\n",
       " [[19, 46], [62, 89], [106, 133]],\n",
       " [[13, 40]],\n",
       " [[12, 39], [57, 84], [104, 131], [167, 194]],\n",
       " [[21, 48], [87, 114], [140, 167]],\n",
       " [[11, 38], [74, 101], [122, 149], [161, 188]],\n",
       " [[19, 46], [70, 97]],\n",
       " [[19, 46], [73, 100]],\n",
       " [[34, 61], [77, 104]],\n",
       " [[71, 98]],\n",
       " [[25, 52], [63, 90], [141, 168], [190, 217]],\n",
       " [[24, 51]],\n",
       " [[27, 54], [68, 95]],\n",
       " [[18, 45], [89, 116]],\n",
       " [[99, 126]],\n",
       " [[14, 41], [67, 94], [125, 152], [174, 201]],\n",
       " [[19, 46], [77, 104], [135, 162], [201, 228]],\n",
       " [[18, 45], [67, 94], [119, 146], [160, 187], [216, 243]],\n",
       " [[26, 53], [81, 108], [161, 188], [221, 248], [313, 340]],\n",
       " [[18, 45], [62, 89]],\n",
       " [[31, 58], [92, 119], [149, 176]],\n",
       " [[14, 41], [57, 84]],\n",
       " [[14, 41], [81, 108], [131, 158], [177, 204], [231, 258], [282, 309]],\n",
       " [[28, 55], [78, 105], [130, 157], [172, 199], [234, 261], [293, 320]],\n",
       " [[19, 46], [74, 101], [118, 145], [156, 183], [205, 232], [258, 285]],\n",
       " [[19, 46], [68, 95], [160, 187]],\n",
       " [[15, 42], [84, 111], [128, 155], [210, 237], [255, 282]],\n",
       " [[18, 45], [67, 94], [121, 148], [164, 191], [213, 240]],\n",
       " [[27, 54], [73, 100]],\n",
       " [[32, 59], [84, 111], [133, 160]],\n",
       " [[35, 62]],\n",
       " [[20, 47], [69, 96], [123, 150], [171, 198]],\n",
       " [[22, 49], [72, 99], [127, 154]],\n",
       " [[28, 55], [80, 107], [142, 169], [189, 216], [236, 263], [289, 316]],\n",
       " [[26, 53]],\n",
       " [[24, 51], [86, 113], [147, 174]],\n",
       " [[16, 43], [68, 95], [121, 148], [164, 191]],\n",
       " [[29, 56], [86, 113], [135, 162]],\n",
       " [[12, 39], [55, 82]],\n",
       " [[83, 110]],\n",
       " [[20, 47], [78, 105]],\n",
       " [[21, 48], [67, 94], [120, 147]],\n",
       " [[13, 40], [57, 84], [99, 126], [142, 169], [185, 212]],\n",
       " [[45, 72]],\n",
       " [[36, 63], [81, 108]],\n",
       " [[23, 50], [74, 101], [127, 154], [182, 209], [226, 253], [264, 291]],\n",
       " [[20, 47], [67, 94], [110, 137], [150, 177], [203, 230], [260, 287]],\n",
       " [[20, 47], [73, 100], [120, 147], [185, 212], [234, 261]],\n",
       " [[28, 55]],\n",
       " [[27, 54], [65, 92]],\n",
       " [[20, 47],\n",
       "  [75, 102],\n",
       "  [124, 151],\n",
       "  [175, 202],\n",
       "  [222, 249],\n",
       "  [263, 290],\n",
       "  [318, 345]],\n",
       " [[21, 48], [63, 90], [111, 138], [160, 187]],\n",
       " [[16, 43], [76, 103], [129, 156], [170, 197], [213, 240]],\n",
       " [[50, 77], [133, 160]],\n",
       " [[33, 60], [78, 105], [131, 158], [201, 228], [248, 275]],\n",
       " [[16, 43], [91, 118], [134, 161], [181, 208]],\n",
       " [[11, 38], [68, 95], [118, 145], [189, 216], [238, 265], [281, 308]],\n",
       " [[31, 58], [81, 108]],\n",
       " [[119, 146]],\n",
       " [[16, 43], [58, 85], [115, 142], [156, 183]],\n",
       " [[18, 45], [67, 94]],\n",
       " [[20, 47],\n",
       "  [60, 87],\n",
       "  [116, 143],\n",
       "  [158, 185],\n",
       "  [211, 238],\n",
       "  [267, 294],\n",
       "  [336, 363],\n",
       "  [389, 416]],\n",
       " [[14, 41],\n",
       "  [62, 89],\n",
       "  [110, 137],\n",
       "  [151, 178],\n",
       "  [212, 239],\n",
       "  [272, 299],\n",
       "  [323, 350]],\n",
       " [[16, 43], [66, 93], [120, 147], [181, 208]],\n",
       " [[23, 50], [81, 108]],\n",
       " [[18, 45], [71, 98], [118, 145]],\n",
       " [[31, 58],\n",
       "  [84, 111],\n",
       "  [138, 165],\n",
       "  [180, 207],\n",
       "  [223, 250],\n",
       "  [290, 317],\n",
       "  [339, 366]],\n",
       " [[11, 38],\n",
       "  [52, 79],\n",
       "  [98, 125],\n",
       "  [143, 170],\n",
       "  [193, 220],\n",
       "  [241, 268],\n",
       "  [298, 325]],\n",
       " [[25, 52], [79, 106], [138, 165]],\n",
       " [[4, 31], [50, 77], [92, 119], [137, 164], [183, 210]],\n",
       " [[18, 45], [69, 96]],\n",
       " [[21, 48], [79, 106], [137, 164]],\n",
       " [[21, 48], [86, 113]],\n",
       " [[15, 42], [60, 87], [148, 175], [193, 220], [248, 275]],\n",
       " [[26, 53], [85, 112], [131, 158], [185, 212], [240, 267]],\n",
       " [[17, 44], [86, 113], [150, 177], [192, 219], [235, 262], [293, 320]],\n",
       " [[11, 38], [68, 95], [114, 141], [158, 185], [202, 229], [240, 267]],\n",
       " [[34, 61], [77, 104]],\n",
       " [[85, 112]],\n",
       " [[13, 40], [54, 81], [99, 126]],\n",
       " [[14, 41], [54, 81], [115, 142]],\n",
       " [[26, 53], [81, 108], [136, 163], [184, 211], [235, 262], [290, 317]],\n",
       " [[11, 38], [53, 80], [111, 138], [186, 213]],\n",
       " [[33, 60], [72, 99]],\n",
       " [[8, 35], [64, 91], [104, 131], [147, 174], [210, 237]],\n",
       " [[19, 46], [97, 124], [168, 195]],\n",
       " [[17, 44], [65, 92], [137, 164], [198, 225]],\n",
       " [[19, 46], [80, 107], [148, 175], [202, 229], [256, 283]],\n",
       " [[21, 48], [69, 96], [137, 164], [191, 218]],\n",
       " [[12, 39], [52, 79], [111, 138], [166, 193], [219, 246], [265, 292]],\n",
       " [[18, 45], [68, 95], [125, 152], [174, 201]],\n",
       " [[43, 70], [92, 119], [138, 165]],\n",
       " [[42, 69], [93, 120], [151, 178], [198, 225], [256, 283]],\n",
       " [[11, 38], [58, 85], [110, 137], [177, 204]],\n",
       " [[23, 50], [76, 103]],\n",
       " [[22, 49], [65, 92]],\n",
       " [[18, 45], [74, 101], [130, 157]],\n",
       " [[77, 104]],\n",
       " [[17, 44], [55, 82], [101, 128], [145, 172], [194, 221], [240, 267]],\n",
       " [[26, 53], [91, 118], [133, 160]],\n",
       " [[17, 44]],\n",
       " [[26, 53], [71, 98]],\n",
       " [[17, 44], [64, 91], [120, 147], [166, 193]],\n",
       " [[19, 46],\n",
       "  [69, 96],\n",
       "  [123, 150],\n",
       "  [162, 189],\n",
       "  [204, 231],\n",
       "  [246, 273],\n",
       "  [287, 314]],\n",
       " [[65, 92]],\n",
       " [[37, 64], [100, 127], [159, 186], [206, 233]],\n",
       " [[37, 64]],\n",
       " [[27, 54], [74, 101]],\n",
       " [[49, 76], [102, 129], [153, 180], [203, 230]],\n",
       " [[23, 50], [74, 101], [130, 157]],\n",
       " [[23, 50], [82, 109]],\n",
       " [[35, 62], [95, 122]],\n",
       " [[19, 46],\n",
       "  [77, 104],\n",
       "  [116, 143],\n",
       "  [176, 203],\n",
       "  [222, 249],\n",
       "  [277, 304],\n",
       "  [325, 352]],\n",
       " [[34, 61], [92, 119]],\n",
       " [[32, 59], [95, 122]],\n",
       " [[37, 64], [87, 114], [137, 164], [179, 206]],\n",
       " [[81, 108], [133, 160], [187, 214]],\n",
       " [[22, 49], [75, 102]],\n",
       " [[15, 42], [73, 100], [123, 150], [167, 194]],\n",
       " [[20, 47], [72, 99]],\n",
       " [[21, 48], [81, 108], [150, 177], [202, 229]],\n",
       " [[34, 61], [96, 123]],\n",
       " [[15, 42], [69, 96], [122, 149], [176, 203], [238, 265], [288, 315]],\n",
       " [[28, 55]],\n",
       " [[26, 53], [78, 105], [133, 160], [184, 211]],\n",
       " [[26, 53]],\n",
       " [[17, 44], [68, 95], [122, 149], [188, 215]],\n",
       " [[65, 92], [24, 51], [109, 136], [154, 181], [198, 225]],\n",
       " [[51, 78]],\n",
       " [[56, 83]],\n",
       " [[11, 38], [51, 78]],\n",
       " [[39, 66], [128, 155], [167, 194]],\n",
       " [[17, 44], [73, 100], [125, 152], [165, 192]],\n",
       " [[62, 89]],\n",
       " [[24, 51], [72, 99], [108, 135], [164, 191]],\n",
       " [[23, 50], [89, 116]],\n",
       " [[18, 45], [72, 99], [128, 155], [167, 194], [221, 248]],\n",
       " [[11, 38], [55, 82], [99, 126], [149, 176]],\n",
       " [[55, 82]],\n",
       " [[51, 78], [98, 125]],\n",
       " [[27, 54]],\n",
       " [[30, 57], [78, 105], [138, 165]],\n",
       " [[18, 45], [78, 105], [120, 147], [164, 191]],\n",
       " [[70, 97], [121, 148]],\n",
       " [[9, 36], [76, 103], [129, 156]],\n",
       " [[7, 34], [61, 88], [144, 171], [190, 217], [248, 275]],\n",
       " [[27, 54], [90, 117]],\n",
       " [[18, 45], [62, 89], [104, 131], [148, 175]],\n",
       " [[11, 38], [48, 75], [119, 146], [161, 188]],\n",
       " [[13, 40], [53, 80], [115, 142], [169, 196], [215, 242], [260, 287]],\n",
       " [[65, 92], [107, 134]],\n",
       " [[16, 43], [82, 109], [143, 170]],\n",
       " [[19, 46], [94, 121]],\n",
       " [[16, 43]],\n",
       " [[18, 45], [61, 88], [104, 131]],\n",
       " [[24, 51], [77, 104], [122, 149], [168, 195]],\n",
       " [[19, 46], [57, 84]],\n",
       " [[102, 129]],\n",
       " [[23, 50], [71, 98]],\n",
       " [[10, 37], [54, 81], [106, 133], [165, 192]],\n",
       " [[45, 72], [107, 134], [161, 188], [217, 244]],\n",
       " [[45, 72], [102, 129]],\n",
       " [[24, 51], [100, 127], [149, 176], [194, 221]],\n",
       " [[21, 48], [76, 103], [129, 156]],\n",
       " [[18, 45], [65, 92], [126, 153]],\n",
       " [[35, 62], [74, 101]],\n",
       " [[23, 50], [88, 115], [132, 159], [204, 231], [245, 272]],\n",
       " [[27, 54], [76, 103], [132, 159], [182, 209]],\n",
       " [[62, 89]],\n",
       " [[11, 38], [59, 86], [117, 144]],\n",
       " [[23, 50],\n",
       "  [61, 88],\n",
       "  [110, 137],\n",
       "  [167, 194],\n",
       "  [214, 241],\n",
       "  [251, 278],\n",
       "  [298, 325]],\n",
       " [[27, 54], [95, 122], [136, 163], [186, 213], [239, 266]],\n",
       " [[27, 54],\n",
       "  [69, 96],\n",
       "  [113, 140],\n",
       "  [168, 195],\n",
       "  [222, 249],\n",
       "  [277, 304],\n",
       "  [318, 345]],\n",
       " [[21, 48], [66, 93], [119, 146]],\n",
       " [[66, 93]],\n",
       " [[25, 52], [67, 94], [118, 145], [172, 199]],\n",
       " [[15, 42], [64, 91], [111, 138], [153, 180], [213, 240]],\n",
       " [[44, 71], [89, 116]],\n",
       " [[43, 70]],\n",
       " [[12, 39],\n",
       "  [68, 95],\n",
       "  [111, 138],\n",
       "  [153, 180],\n",
       "  [194, 221],\n",
       "  [233, 260],\n",
       "  [288, 315]],\n",
       " [[9, 36], [52, 79], [103, 130], [155, 182]],\n",
       " [[39, 66], [86, 113]],\n",
       " [[17, 44], [89, 116], [158, 185]],\n",
       " [[51, 78]],\n",
       " [[7, 34],\n",
       "  [50, 77],\n",
       "  [88, 115],\n",
       "  [130, 157],\n",
       "  [171, 198],\n",
       "  [213, 240],\n",
       "  [270, 297],\n",
       "  [330, 357],\n",
       "  [379, 406]],\n",
       " [[48, 75]],\n",
       " [[38, 65]],\n",
       " [[14, 41], [77, 104], [125, 152], [174, 201], [218, 245]],\n",
       " [[18, 45], [70, 97], [126, 153], [202, 229]],\n",
       " [[27, 54], [70, 97], [133, 160], [195, 222]],\n",
       " [[73, 100], [124, 151], [173, 200]],\n",
       " [[13, 40], [67, 94], [107, 134], [152, 179], [203, 230]],\n",
       " [[33, 60], [82, 109], [118, 145]],\n",
       " [[69, 96]],\n",
       " [[30, 57], [75, 102], [127, 154], [175, 202], [214, 241]],\n",
       " [[14, 41],\n",
       "  [71, 98],\n",
       "  [126, 153],\n",
       "  [163, 190],\n",
       "  [208, 235],\n",
       "  [247, 274],\n",
       "  [285, 312],\n",
       "  [332, 359]],\n",
       " [[16, 43],\n",
       "  [58, 85],\n",
       "  [115, 142],\n",
       "  [163, 190],\n",
       "  [230, 257],\n",
       "  [269, 296],\n",
       "  [322, 349]],\n",
       " [[38, 65], [80, 107], [133, 160]],\n",
       " [[14, 41], [53, 80], [95, 122], [138, 165], [185, 212]],\n",
       " [[39, 66]],\n",
       " [[24, 51], [79, 106], [138, 165], [179, 206]],\n",
       " [[34, 61], [83, 110]],\n",
       " [[9, 36],\n",
       "  [50, 77],\n",
       "  [96, 123],\n",
       "  [132, 159],\n",
       "  [176, 203],\n",
       "  [231, 258],\n",
       "  [280, 307],\n",
       "  [328, 355]],\n",
       " [[33, 60], [92, 119], [138, 165], [174, 201], [216, 243], [275, 302]],\n",
       " [[63, 90]],\n",
       " [[23, 50], [72, 99], [117, 144], [161, 188]],\n",
       " [[9, 36], [57, 84], [113, 140], [166, 193], [217, 244], [273, 300]],\n",
       " [[10, 37], [49, 76], [96, 123], [137, 164], [179, 206], [217, 244]],\n",
       " [[21, 48], [64, 91], [118, 145], [223, 250], [280, 307]],\n",
       " [[24, 51], [71, 98], [122, 149], [167, 194], [207, 234], [258, 285]],\n",
       " [[25, 52], [80, 107], [143, 170], [190, 217]],\n",
       " [[15, 42], [69, 96]],\n",
       " [[94, 121]],\n",
       " [[16, 43], [67, 94], [127, 154], [178, 205]],\n",
       " [[20, 47], [70, 97], [123, 150], [167, 194], [225, 252]],\n",
       " [[85, 112]],\n",
       " [[55, 82], [108, 135]],\n",
       " [[21, 48], [65, 92], [126, 153]],\n",
       " [[16, 43], [55, 82], [110, 137], [156, 183], [207, 234]],\n",
       " [[27, 54], [72, 99], [129, 156], [173, 200], [218, 245]],\n",
       " [[15, 42], [79, 106]],\n",
       " [[16, 43], [76, 103], [136, 163]],\n",
       " [[24, 51], [84, 111], [137, 164], [189, 216]],\n",
       " [[31, 58], [94, 121], [141, 168], [205, 232]],\n",
       " [[55, 82], [95, 122], [144, 171], [195, 222]],\n",
       " [[24, 51], [102, 129], [149, 176], [205, 232], [258, 285]],\n",
       " [[45, 72]],\n",
       " [[13, 40], [62, 89], [102, 129], [145, 172]],\n",
       " [[20, 47], [74, 101], [131, 158]],\n",
       " [[18, 45],\n",
       "  [64, 91],\n",
       "  [110, 137],\n",
       "  [148, 175],\n",
       "  [189, 216],\n",
       "  [251, 278],\n",
       "  [304, 331]],\n",
       " [[27, 54], [73, 100], [120, 147], [169, 196], [218, 245]],\n",
       " [[22, 49], [87, 114]],\n",
       " [[19, 46]],\n",
       " [[28, 55], [97, 124], [166, 193]],\n",
       " [[16, 43],\n",
       "  [53, 80],\n",
       "  [92, 119],\n",
       "  [141, 168],\n",
       "  [189, 216],\n",
       "  [230, 257],\n",
       "  [280, 307],\n",
       "  [321, 348]],\n",
       " [[39, 66]],\n",
       " [[22, 49], [79, 106]],\n",
       " [[12, 39], [67, 94], [113, 140], [157, 184], [209, 236]],\n",
       " [[16, 43], [62, 89], [108, 135], [166, 193]],\n",
       " [[22, 49], [65, 92], [114, 141], [178, 205]],\n",
       " [[44, 71]],\n",
       " [[20, 47],\n",
       "  [62, 89],\n",
       "  [103, 130],\n",
       "  [166, 193],\n",
       "  [209, 236],\n",
       "  [274, 301],\n",
       "  [321, 348],\n",
       "  [363, 390]],\n",
       " [[40, 67], [94, 121]],\n",
       " [[28, 55], [109, 136], [173, 200]],\n",
       " [[26, 53], [80, 107]],\n",
       " [[17, 44], [81, 108], [120, 147], [182, 209]],\n",
       " [[22, 49], [95, 122], [158, 185]],\n",
       " [[37, 64], [92, 119], [147, 174]],\n",
       " [[16, 43], [77, 104], [168, 195], [215, 242]],\n",
       " [[27, 54], [79, 106]],\n",
       " [[36, 63], [118, 145], [187, 214], [232, 259], [289, 316]],\n",
       " [[21, 48]],\n",
       " [[20, 47], [61, 88]],\n",
       " [[16, 43], [77, 104], [123, 150], [189, 216]],\n",
       " [[18, 45], [59, 86]],\n",
       " [[18, 45], [63, 90], [102, 129], [155, 182]],\n",
       " [[15, 42], [68, 95], [112, 139], [149, 176], [189, 216], [228, 255]],\n",
       " [[78, 105]],\n",
       " [[26, 53], [70, 97]],\n",
       " [[17, 44], [63, 90], [108, 135], [151, 178]],\n",
       " [[43, 70]],\n",
       " [[22, 49]],\n",
       " [[35, 62]],\n",
       " [[14, 41], [70, 97], [126, 153], [167, 194], [218, 245]],\n",
       " [[26, 53], [77, 104], [118, 145], [162, 189], [201, 228], [237, 264]],\n",
       " [[19, 46], [79, 106], [139, 166], [180, 207], [246, 273]],\n",
       " [[26, 53], [71, 98]],\n",
       " [[14, 41], [78, 105], [146, 173], [195, 222]],\n",
       " [[24, 51], [82, 109], [132, 159], [193, 220], [251, 278]],\n",
       " [[28, 55], [82, 109], [130, 157], [171, 198]],\n",
       " [[13, 40]],\n",
       " [[18, 45], [69, 96], [115, 142], [171, 198], [224, 251]],\n",
       " [[68, 95], [122, 149]],\n",
       " [[14, 41], [60, 87], [105, 132], [177, 204], [228, 255]],\n",
       " [[18, 45], [67, 94]],\n",
       " [[18, 45],\n",
       "  [61, 88],\n",
       "  [100, 127],\n",
       "  [140, 167],\n",
       "  [202, 229],\n",
       "  [248, 275],\n",
       "  [304, 331],\n",
       "  [359, 386]],\n",
       " [[13, 40], [55, 82], [97, 124], [143, 170], [196, 223], [261, 288]],\n",
       " [[24, 51], [83, 110]],\n",
       " [[24, 51], [85, 112], [145, 172], [185, 212], [244, 271], [300, 327]],\n",
       " [[25, 52],\n",
       "  [77, 104],\n",
       "  [131, 158],\n",
       "  [171, 198],\n",
       "  [213, 240],\n",
       "  [257, 284],\n",
       "  [304, 331]],\n",
       " [[14, 41], [59, 86]],\n",
       " [[21, 48], [75, 102], [134, 161]],\n",
       " [[25, 52], [76, 103], [133, 160]],\n",
       " [[8, 35], [60, 87], [118, 145], [180, 207]],\n",
       " [[18, 45], [88, 115], [147, 174]],\n",
       " [[14, 41], [74, 101], [113, 140], [183, 210]],\n",
       " [[62, 89], [121, 148], [166, 193], [204, 231], [249, 276]],\n",
       " [[16, 43], [65, 92], [119, 146], [167, 194]],\n",
       " [[60, 87]],\n",
       " [[43, 70], [91, 118]],\n",
       " [[19, 46],\n",
       "  [68, 95],\n",
       "  [102, 129],\n",
       "  [145, 172],\n",
       "  [196, 223],\n",
       "  [245, 272],\n",
       "  [308, 335],\n",
       "  [353, 380],\n",
       "  [393, 420]],\n",
       " [[23, 50], [77, 104], [126, 153], [164, 191], [218, 245]],\n",
       " [[12, 39], [66, 93], [129, 156]],\n",
       " [[41, 68]],\n",
       " [[9, 36], [55, 82], [102, 129], [140, 167], [198, 225]],\n",
       " [[31, 58], [80, 107], [127, 154], [170, 197]],\n",
       " [[27, 54], [63, 90], [106, 133]],\n",
       " [[83, 110]],\n",
       " [[25, 52], [62, 89]],\n",
       " [[24, 51], [74, 101], [127, 154], [177, 204], [228, 255], [281, 308]],\n",
       " [[45, 72], [108, 135], [155, 182]],\n",
       " [[12, 39], [51, 78], [94, 121], [141, 168], [187, 214], [230, 257]],\n",
       " [[17, 44]],\n",
       " [[32, 59], [82, 109], [132, 159], [173, 200], [219, 246], [261, 288]],\n",
       " [[24, 51], [81, 108], [131, 158]],\n",
       " [[11, 38], [51, 78], [101, 128], [150, 177], [199, 226]],\n",
       " [[27, 54]],\n",
       " [[20, 47],\n",
       "  [79, 106],\n",
       "  [128, 155],\n",
       "  [171, 198],\n",
       "  [215, 242],\n",
       "  [268, 295],\n",
       "  [308, 335]],\n",
       " [[16, 43], [74, 101]],\n",
       " [[58, 85]],\n",
       " [[14, 41],\n",
       "  [51, 78],\n",
       "  [96, 123],\n",
       "  [136, 163],\n",
       "  [176, 203],\n",
       "  [229, 256],\n",
       "  [277, 304]],\n",
       " [[20, 47], [102, 129]],\n",
       " [[10, 37], [49, 76]],\n",
       " [[11, 38], [54, 81], [115, 142]],\n",
       " [[17, 44], [65, 92]],\n",
       " [[12, 39],\n",
       "  [53, 80],\n",
       "  [113, 140],\n",
       "  [155, 182],\n",
       "  [199, 226],\n",
       "  [243, 270],\n",
       "  [299, 326]],\n",
       " [[21, 48]],\n",
       " [[24, 51]],\n",
       " [[20, 47], [85, 112], [139, 166]],\n",
       " [[62, 89], [108, 135]],\n",
       " [[21, 48], [66, 93], [122, 149], [169, 196], [214, 241]],\n",
       " [[17, 44], [63, 90]],\n",
       " [[9, 36], [58, 85], [127, 154], [174, 201]],\n",
       " [[62, 89], [117, 144]],\n",
       " [[20, 47], [91, 118], [151, 178], [206, 233]],\n",
       " [[13, 40], [70, 97], [113, 140], [164, 191], [201, 228]],\n",
       " [[58, 85]],\n",
       " [[12, 39], [66, 93], [112, 139]],\n",
       " [[18, 45]],\n",
       " [[13, 40], [58, 85], [109, 136], [154, 181], [211, 238]],\n",
       " [[20, 47], [89, 116], [147, 174], [209, 236]],\n",
       " [[22, 49], [78, 105], [143, 170], [193, 220]],\n",
       " [[16, 43], [62, 89], [112, 139], [153, 180], [198, 225]],\n",
       " [[67, 94]],\n",
       " [[64, 91]],\n",
       " [[35, 62]],\n",
       " [[10, 37], [71, 98], [118, 145], [165, 192], [208, 235]],\n",
       " [[30, 57], [83, 110]],\n",
       " [[96, 123]],\n",
       " [[49, 76]],\n",
       " [[15, 42], [58, 85], [102, 129]],\n",
       " [[15, 42], [64, 91], [131, 158], [170, 197]],\n",
       " [[56, 83]],\n",
       " [[28, 55], [91, 118], [158, 185]],\n",
       " [[10, 37]],\n",
       " [[67, 94]],\n",
       " [[14, 41],\n",
       "  [56, 83],\n",
       "  [100, 127],\n",
       "  [142, 169],\n",
       "  [195, 222],\n",
       "  [246, 273],\n",
       "  [291, 318]],\n",
       " [[52, 79]],\n",
       " [[19, 46], [73, 100], [127, 154], [185, 212]],\n",
       " [[9, 36], [51, 78], [97, 124], [137, 164]],\n",
       " [[17, 44], [55, 82], [97, 124], [136, 163], [174, 201]],\n",
       " [[69, 96]],\n",
       " [[29, 56], [87, 114], [144, 171]],\n",
       " [[76, 103]],\n",
       " [[87, 114]],\n",
       " [[19, 46],\n",
       "  [72, 99],\n",
       "  [109, 136],\n",
       "  [181, 208],\n",
       "  [225, 252],\n",
       "  [285, 312],\n",
       "  [327, 354]],\n",
       " [[55, 82]],\n",
       " [[15, 42], [63, 90], [118, 145]],\n",
       " [[11, 38], [82, 109], [138, 165]],\n",
       " [[21, 48]],\n",
       " [[29, 56], [85, 112], [165, 192]],\n",
       " [[13, 40], [63, 90], [120, 147], [168, 195]],\n",
       " [[25, 52], [82, 109], [144, 171], [192, 219]],\n",
       " [[18, 45],\n",
       "  [64, 91],\n",
       "  [118, 145],\n",
       "  [164, 191],\n",
       "  [205, 232],\n",
       "  [250, 277],\n",
       "  [290, 317]],\n",
       " [[18, 45], [69, 96]],\n",
       " [[56, 83]],\n",
       " [[16, 43], [84, 111], [131, 158]],\n",
       " [[23, 50]],\n",
       " [[6, 33], [69, 96], [134, 161]],\n",
       " [[23, 50], [78, 105], [162, 189], [231, 258]],\n",
       " [[29, 56], [70, 97], [133, 160], [183, 210]],\n",
       " [[40, 67]],\n",
       " [[57, 84]],\n",
       " [[17, 44], [72, 99]],\n",
       " [[59, 86]],\n",
       " [[29, 56], [105, 132], [146, 173]],\n",
       " [[19, 46],\n",
       "  [62, 89],\n",
       "  [113, 140],\n",
       "  [155, 182],\n",
       "  [197, 224],\n",
       "  [242, 269],\n",
       "  [288, 315],\n",
       "  [335, 362]],\n",
       " [[11, 38], [55, 82], [112, 139], [161, 188]],\n",
       " [[10, 37], [70, 97], [111, 138], [151, 178]],\n",
       " [[16, 43], [61, 88], [110, 137], [160, 187], [212, 239]],\n",
       " [[56, 83]],\n",
       " [[27, 54], [88, 115], [140, 167]],\n",
       " [[83, 110], [135, 162]],\n",
       " [[10, 37], [70, 97], [129, 156]],\n",
       " [[23, 50], [87, 114], [137, 164], [191, 218], [237, 264]],\n",
       " [[21, 48], [62, 89], [112, 139]],\n",
       " [[12, 39],\n",
       "  [54, 81],\n",
       "  [97, 124],\n",
       "  [149, 176],\n",
       "  [195, 222],\n",
       "  [256, 283],\n",
       "  [303, 330]],\n",
       " [[20, 47], [73, 100], [121, 148], [174, 201], [222, 249], [263, 290]],\n",
       " [[17, 44], [86, 113], [143, 170], [193, 220], [239, 266]],\n",
       " [[15, 42], [79, 106], [132, 159], [182, 209], [227, 254], [275, 302]],\n",
       " [[54, 81]],\n",
       " [[38, 65], [110, 137]],\n",
       " [[12, 39], [68, 95], [113, 140], [164, 191]],\n",
       " [[14, 41], [54, 81], [100, 127]],\n",
       " [[97, 124]],\n",
       " [[25, 52], [71, 98], [124, 151], [176, 203]],\n",
       " [[90, 117]],\n",
       " [[21, 48], [85, 112], [128, 155]],\n",
       " [[68, 95]],\n",
       " [[34, 61], [79, 106], [135, 162]],\n",
       " [[23, 50], [89, 116], [137, 164], [198, 225]],\n",
       " [[25, 52], [104, 131]],\n",
       " [[40, 67], [93, 120], [133, 160], [188, 215]],\n",
       " [[18, 45], [68, 95], [114, 141]],\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['feature_spans_new']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e800192",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbcf9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 0\n",
    "MAX_SPAN = 0\n",
    "\n",
    "for split in ['train', 'test', 'validation']:\n",
    "    \n",
    "    for col_name in ['am_spans_new', 'ac_spans_new', 'feature_spans_new']:\n",
    "        \n",
    "        for x in dataset[split][col_name]:\n",
    "            \n",
    "            if max(x,key=itemgetter(1))[1] > MAX_SPAN:\n",
    "                \n",
    "                MAX_SPAN = max(x,key=itemgetter(1))[1]\n",
    "                MAX_SPAN = min(MAX_SPAN, tokenizer.model_max_length - 1)\n",
    "            \n",
    "            if len(x) > MAX_LENGTH:\n",
    "                \n",
    "                MAX_LENGTH = len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84a9a38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SPAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20b0685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding(batch, padding_target):    \n",
    "    \n",
    "    if padding_target == 'am_spans':\n",
    "        \n",
    "        col_name = 'am_spans_new'\n",
    "        padding_val = [[-1,-1]]\n",
    "        max_length = MAX_LENGTH\n",
    "        \n",
    "    elif padding_target == 'ac_spans':\n",
    "        \n",
    "        col_name = 'ac_spans_new'\n",
    "        padding_val = [[-1,-1]]\n",
    "        max_length = MAX_LENGTH\n",
    "        \n",
    "    elif padding_target == 'fts_spans':\n",
    "        \n",
    "        col_name = 'feature_spans_new'\n",
    "        padding_val = [[-1,-1]]\n",
    "        max_length = MAX_LENGTH\n",
    "        \n",
    "    elif padding_target == 'label':\n",
    "    \n",
    "        col_name = 'paragraph_labels'\n",
    "        padding_val = [-100] # -1 previously       \n",
    "        max_length = MAX_LENGTH # max([len(l) for l in batch[col_name]]) # cause some batch had 4 x 10\n",
    "\n",
    "    padded_spans = []\n",
    "\n",
    "    for idx, span in enumerate(batch[col_name]):\n",
    "\n",
    "        padded_span = batch[col_name][idx] + (max_length - len(span)) * padding_val\n",
    "        padded_spans.append(padded_span)\n",
    "\n",
    "    return padded_spans         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea4829b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_spans(am_spans_ll, ac_spans_ll, fts_spans_ll):\n",
    "    \n",
    "    spans_ll = []\n",
    "    \n",
    "    for am_spans, ac_spans, fts_spans in zip(am_spans_ll, ac_spans_ll, fts_spans_ll):\n",
    "        \n",
    "        spans = []\n",
    "        \n",
    "        for am_span, ac_span, fts_span in zip(am_spans, ac_spans, fts_spans):\n",
    "\n",
    "            span = [am_span, ac_span, fts_span]\n",
    "            spans.extend(span)\n",
    "            \n",
    "        spans_ll.append(spans)\n",
    "\n",
    "    return spans_ll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a28d15",
   "metadata": {},
   "source": [
    "### tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49944a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length = 200 for use in the max_length in the tokenizer so that the things are of equal dim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecacdf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    \n",
    "    tokenized_text = tokenizer(batch['paragraph_w_fts_as_txt'], truncation=True, padding=True, max_length=512)\n",
    "    tokenized_text['label'] = get_padding(batch, 'label')\n",
    "    tokenized_text['am_spans'] = get_padding(batch, 'am_spans')\n",
    "    tokenized_text['ac_spans'] = get_padding(batch, 'ac_spans')\n",
    "    tokenized_text['fts_spans'] = get_padding(batch, 'fts_spans')\n",
    "    tokenized_text['spans'] = get_combined_spans(tokenized_text['am_spans'], tokenized_text['ac_spans'], tokenized_text['fts_spans'])      \n",
    "    \n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdb38efc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize at 0x7f24a4233a60> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020284175872802734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8879f94e3e4456887c198313f4766b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019970178604125977,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4f479571fb4ecaaf8be6a1ecc7fcaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020010948181152344,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb3a951014945f28d59f77fc4543994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize, batched=True, batch_size=len(dataset['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cd51e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ac_spans', 'ac_spans_new', 'am_spans', 'am_spans_new', 'attention_mask', 'essay_nr', 'feature_spans_new', 'fts_spans', 'input_ids', 'label', 'paragraph', 'paragraph_ac_spans', 'paragraph_am_spans', 'paragraph_components_list', 'paragraph_fts_as_txt_list', 'paragraph_labels', 'paragraph_labels_list', 'paragraph_markers_list', 'paragraph_w_fts_as_txt', 'sanity_new', 'spans', 'split', 'token_type_ids'],\n",
       "        num_rows: 1088\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ac_spans', 'ac_spans_new', 'am_spans', 'am_spans_new', 'attention_mask', 'essay_nr', 'feature_spans_new', 'fts_spans', 'input_ids', 'label', 'paragraph', 'paragraph_ac_spans', 'paragraph_am_spans', 'paragraph_components_list', 'paragraph_fts_as_txt_list', 'paragraph_labels', 'paragraph_labels_list', 'paragraph_markers_list', 'paragraph_w_fts_as_txt', 'sanity_new', 'spans', 'split', 'token_type_ids'],\n",
       "        num_rows: 358\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ac_spans', 'ac_spans_new', 'am_spans', 'am_spans_new', 'attention_mask', 'essay_nr', 'feature_spans_new', 'fts_spans', 'input_ids', 'label', 'paragraph', 'paragraph_ac_spans', 'paragraph_am_spans', 'paragraph_components_list', 'paragraph_fts_as_txt_list', 'paragraph_labels', 'paragraph_labels_list', 'paragraph_markers_list', 'paragraph_w_fts_as_txt', 'sanity_new', 'spans', 'split', 'token_type_ids'],\n",
       "        num_rows: 273\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac61929d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0],\n",
       " [2, 21],\n",
       " [23, 50],\n",
       " [-1, -1],\n",
       " [57, 73],\n",
       " [75, 102],\n",
       " [-1, -1],\n",
       " [105, 140],\n",
       " [142, 169],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['spans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9630f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train'][0]['spans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46699fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][1]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0501ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ac_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'ac_spans_new': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'am_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'am_spans_new': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'essay_nr': Value(dtype='string', id=None),\n",
       " 'feature_spans_new': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'fts_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'label': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'paragraph': Value(dtype='string', id=None),\n",
       " 'paragraph_ac_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_am_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_components_list': Sequence(feature=Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_fts_as_txt_list': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'paragraph_labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'paragraph_labels_list': Sequence(feature=Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_markers_list': Sequence(feature=Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_w_fts_as_txt': Value(dtype='string', id=None),\n",
       " 'sanity_new': Value(dtype='bool', id=None),\n",
       " 'spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'split': Value(dtype='string', id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e96f0cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ac_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'ac_spans_new': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'am_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'am_spans_new': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'essay_nr': Value(dtype='string', id=None),\n",
       " 'feature_spans_new': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'fts_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'label': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'paragraph': Value(dtype='string', id=None),\n",
       " 'paragraph_ac_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_am_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_components_list': Sequence(feature=Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_fts_as_txt_list': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'paragraph_labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'paragraph_labels_list': Sequence(feature=Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_markers_list': Sequence(feature=Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_w_fts_as_txt': Value(dtype='string', id=None),\n",
       " 'sanity_new': Value(dtype='bool', id=None),\n",
       " 'spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'split': Value(dtype='string', id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e463ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test'].features['spans'] = datasets.Array2D(shape=(36, 2), dtype=\"int32\")\n",
    "dataset['train'].features['spans'] = datasets.Array2D(shape=(36, 2), dtype=\"int32\")\n",
    "dataset['validation'].features['spans'] = datasets.Array2D(shape=(36, 2), dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e111a8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019360065460205078,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade4df687cde44c38620077b3fc9e971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01798844337463379,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a553204fde6148219e29a0198c88f60a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02004837989807129,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ad9277e3e240869f53e90a65e6ca4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(lambda batch: batch, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c68cbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'token_type_ids', 'spans', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c180300",
   "metadata": {},
   "source": [
    "## span representation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec80d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minus_one(t):\n",
    "    \n",
    "    return torch.where(t == 0, 0, t-1)\n",
    "\n",
    "def plus_one(t):\n",
    "    \n",
    "    return torch.where(t == MAX_SPAN, MAX_SPAN, t+1) # changed from t == MAX_SPAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7c8d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span_representations(outputs, spans):\n",
    "    \n",
    "    #print('spans shape', spans.shape)\n",
    "    \n",
    "    batch_size = spans.shape[0]\n",
    "    \n",
    "    nr_span_indices = spans.shape[1]\n",
    "    \n",
    "    #print('nr span indices', nr_span_indices)\n",
    "    \n",
    "    # nr_span_indices = 24 # xxx. hardcode just to check\n",
    "    \n",
    "    idx_l_ams = range(0, nr_span_indices, 3) # [0,2,4,6 etc]\n",
    "    idx_l_acs = range(1, nr_span_indices, 3) # [1,3,5,7 etc]\n",
    "    idx_l_fts = range(2, nr_span_indices, 3)\n",
    "    \n",
    "    am_spans = spans[:, idx_l_ams, :] + 1 # adds 1 to all span indices (both am and ac) to offset for the CLS token in the input_ids.\n",
    "    ac_spans = spans[:, idx_l_acs, :] + 1\n",
    "    fts_spans = spans[:, idx_l_fts, :] + 1\n",
    "    \n",
    "    \n",
    "    # fix for [-1, +1] problem\n",
    "    \n",
    "    am_spans_minus_one = minus_one(am_spans) # xxx. added to solve bug 2\n",
    "    am_spans_plus_one = plus_one(am_spans) # xxx. added to solve bug 2\n",
    "    \n",
    "    ac_spans_minus_one = minus_one(ac_spans) # xxx. added to solve bug 2\n",
    "    ac_spans_plus_one = plus_one(ac_spans) # xxx. added to solve bug 2\n",
    "    \n",
    "    fts_spans_minus_one = minus_one(fts_spans) # xxx. added to solve bug 2\n",
    "    fts_spans_plus_one = plus_one(fts_spans) # xxx. added to solve bug 2\n",
    "    \n",
    "    \n",
    "    am_spans = am_spans.flatten(start_dim=1)\n",
    "    ac_spans = ac_spans.flatten(start_dim=1)\n",
    "    fts_spans = fts_spans.flatten(start_dim=1)\n",
    "    \n",
    "    nr_adus = ac_spans.shape[1] // 2\n",
    "    \n",
    "    \n",
    "    am_spans_minus_one = am_spans_minus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    am_spans_plus_one = am_spans_plus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    \n",
    "    ac_spans_minus_one = ac_spans_minus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    ac_spans_plus_one = ac_spans_plus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    \n",
    "    fts_spans_minus_one = fts_spans_minus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    fts_spans_plus_one = fts_spans_plus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    \n",
    "    ############# FOR AMs #################\n",
    "    \n",
    "    outputs_am = outputs[:,am_spans,:]\n",
    "    #print('outputs am juste directly from outputs:', outputs_am.shape)\n",
    "    outputs_am = torch.cat([outputs_am[i,i,:,:] for i in range(batch_size)], dim=0)\n",
    "    outputs_am = outputs_am.reshape(batch_size, nr_adus * 2, -1)\n",
    "    \n",
    "    #print('outputs_ am after reshape:', outputs_am.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    outputs_am_minus_one = outputs[:,am_spans_minus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_am_minus_one = torch.cat([outputs_am_minus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_am_minus_one = outputs_am_minus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    outputs_am_plus_one = outputs[:,am_spans_plus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_am_plus_one = torch.cat([outputs_am_plus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_am_plus_one = outputs_am_plus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Now that we have outputs_am i.e. outputs at am_span indices, now create the four Kuri forumlas for AMs\n",
    "    \n",
    "    # ============== the corrected 1st one =================== \n",
    "    \n",
    "    outputs_am_first_term = torch.cat([outputs_am[:,i+1,:] - outputs_am_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1) # i + 1 here means j in kuri, i here means i in kuri\n",
    "    outputs_am_first_term = outputs_am_first_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "     # ============== the corrected 2nd one ==================\n",
    "    \n",
    "    outputs_am_second_term = torch.cat([outputs_am[:,i,:] - outputs_am_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1) # changed + 2 to + 1 to make it run # changed from +1 to +2 to ensure +2 is not a problem for AMs\n",
    "    outputs_am_second_term = outputs_am_second_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "    \n",
    "        # ============== the corrected third one ================== \n",
    "    \n",
    "    outputs_am_third_term = torch.cat([outputs_am_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_am_third_term = outputs_am_third_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "\n",
    "        # ============== the corrected fourth one ==================\n",
    "    \n",
    "    outputs_am_fourth_term = torch.cat([outputs_am_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1) # changed + 2 to + 1 to make it run # changed from +1 to +2 to ensure +2 is not a problem for AMs\n",
    "    outputs_am_fourth_term = outputs_am_fourth_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "    # ============== NOW CONCATENATE THEM =========\n",
    "    \n",
    "    \n",
    "    am_minus_representations = torch.cat([outputs_am_first_term, outputs_am_second_term, outputs_am_third_term, outputs_am_fourth_term], dim=-1)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### am minus span representation according to kuribayashi paper is now above.\n",
    "    \n",
    "    \n",
    "    outputs_ac = outputs[:,ac_spans,:]\n",
    "    outputs_ac = torch.cat([outputs_ac[i,i,:,:] for i in range(batch_size)], dim=0)\n",
    "    outputs_ac = outputs_ac.reshape(batch_size, nr_adus * 2, -1)\n",
    "    \n",
    "    \n",
    "    outputs_ac_minus_one = outputs[:,ac_spans_minus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_ac_minus_one = torch.cat([outputs_ac_minus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_ac_minus_one = outputs_ac_minus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    outputs_ac_plus_one = outputs[:,ac_spans_plus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_ac_plus_one = torch.cat([outputs_ac_plus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_ac_plus_one = outputs_ac_plus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    ### Now that we have outputs_ac i.e. outputs at ac_span indices, now create the four Kuri forumlas for ACs\n",
    "    \n",
    "    \n",
    "    # ============== the corrected first one ===================\n",
    "    \n",
    "    outputs_ac_first_term = torch.cat([outputs_ac[:,i+1,:] - outputs_ac_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_ac_first_term = outputs_ac_first_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "        # ============== the correct second one ==================\n",
    "    \n",
    "    outputs_ac_second_term = torch.cat([outputs_ac[:,i,:] - outputs_ac_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1) # changed + 2 to + 1 to make it run\n",
    "    outputs_ac_second_term = outputs_ac_second_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "    \n",
    "    # ============== the corrected third term ==================\n",
    "    \n",
    "    outputs_ac_third_term = torch.cat([outputs_ac_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_ac_third_term = outputs_ac_third_term.reshape(batch_size, -1, 768)\n",
    "\n",
    "    \n",
    "     # ============== the corrected fourth term ================== xxx. for .788\n",
    "    \n",
    "    outputs_ac_fourth_term = torch.cat([outputs_ac_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1) # changed + 2 to + 1 to make it run\n",
    "    outputs_ac_fourth_term = outputs_ac_fourth_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "    # ============== NOW CONCATENATE THEM =========\n",
    "    \n",
    "    \n",
    "    ac_minus_representations = torch.cat([outputs_ac_first_term, outputs_ac_second_term, outputs_ac_third_term, outputs_ac_fourth_term], dim=-1)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### ac minus span representation according to kuribayashi paper is now above.\n",
    "    \n",
    "    \n",
    "     ############# FOR Fts #################\n",
    "    \n",
    "    outputs_fts = outputs[:,am_spans,:] # am spans for checking\n",
    "    #print('outputs fts juste directly from the outputs:', outputs_fts.shape)\n",
    "    outputs_fts = torch.cat([outputs_fts[i,i,:,:] for i in range(batch_size)], dim=0)\n",
    "    outputs_fts = outputs_fts.reshape(batch_size, nr_adus * 2, -1)\n",
    "    \n",
    "    #print('output fts after reshape:', outputs_fts.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    outputs_fts_minus_one = outputs[:,fts_spans_minus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_fts_minus_one = torch.cat([outputs_fts_minus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_fts_minus_one = outputs_fts_minus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    outputs_fts_plus_one = outputs[:,fts_spans_plus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_fts_plus_one = torch.cat([outputs_fts_plus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_fts_plus_one = outputs_fts_plus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    #print('outputs_fts_plus_one', outputs_fts_plus_one.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Now that we have outputs_am i.e. outputs at am_span indices, now create the four Kuri forumlas for AMs\n",
    "    \n",
    "    # ============== (batch_size x nr_adus x 768) =================== \n",
    "    \n",
    "    outputs_fts_first_term = torch.cat([outputs_fts[:,i+1,:] - outputs_fts_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1) # i + 1 here means j in kuri, i here means i in kuri\n",
    "    outputs_fts_first_term = outputs_fts_first_term.reshape(batch_size, -1, 768)\n",
    "    #print('outputs_fts_first_term:', outputs_fts_first_term.shape)\n",
    "    \n",
    "     # ============== the corrected 2nd one ==================\n",
    "    \n",
    "    outputs_fts_second_term = torch.cat([outputs_fts[:,i,:] - outputs_fts_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_fts_second_term = outputs_fts_second_term.reshape(batch_size, -1, 768)\n",
    "    #print('outputs_fts_second_term:', outputs_fts_second_term.shape)\n",
    "    \n",
    "        # ============== the corrected third one ================== \n",
    "    \n",
    "    outputs_fts_third_term = torch.cat([outputs_fts_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_fts_third_term = outputs_fts_third_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "\n",
    "        # ============== the corrected fourth one ==================\n",
    "    \n",
    "    outputs_fts_fourth_term = torch.cat([outputs_fts_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_fts_fourth_term = outputs_fts_fourth_term.reshape(batch_size, -1, 768)\n",
    "    #print('outputs_fts_fourth_term:', outputs_fts_fourth_term.shape)\n",
    "    \n",
    "    # ============== NOW CONCATENATE THEM =========\n",
    "    \n",
    "    \n",
    "    fts_minus_representations = torch.cat([outputs_fts_first_term, outputs_fts_second_term, outputs_fts_third_term, outputs_fts_fourth_term], dim=-1)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### fts minus span representation according to kuribayashi paper is now above.\n",
    "    \n",
    "    print('am rep final:', am_minus_representations.shape)\n",
    "    print('ac rep final:', ac_minus_representations.shape)\n",
    "    print('fts rep final:', fts_minus_representations.shape)\n",
    "    \n",
    "\n",
    "    \n",
    "    return am_minus_representations, ac_minus_representations, fts_minus_representations                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63f91c7",
   "metadata": {},
   "source": [
    "### span representation function old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4cc26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_span_representations(outputs, spans):\n",
    "    \n",
    "#     # print(spans.shape)\n",
    "    \n",
    "#     batch_size = spans.shape[0]\n",
    "#     nr_span_indices = spans.shape[1]\n",
    "    \n",
    "#     print('nr span indices: ', nr_span_indices)\n",
    "    \n",
    "#     idx_l_ams = range(0, nr_span_indices, 3) # [0,2,4,6 etc]\n",
    "#     # print('idx am', idx_l_ams)\n",
    "#     idx_l_acs = range(1, nr_span_indices, 3) # [1,3,5,7 etc]\n",
    "#     #print('idx ac', idx_l_acs)\n",
    "#     idx_l_fts = range(2, nr_span_indices, 3) # xxx. added for fts task.\n",
    "#     #print('idx fts', idx_l_fts)\n",
    "    \n",
    "    \n",
    "#     am_spans = spans[:, idx_l_ams, :] + 1 # adds 1 to all span indices (both am and ac) to offset for the CLS token in the input_ids.\n",
    "    \n",
    "#     ac_spans = spans[:, idx_l_acs, :] + 1    \n",
    "    \n",
    "#     fts_spans = spans[:, idx_l_fts, :] + 1 ### xxx. \n",
    "    \n",
    "    \n",
    "#     am_spans = am_spans.flatten(start_dim=1)\n",
    "#     print('am spans:', am_spans.shape)\n",
    "#     ac_spans = ac_spans.flatten(start_dim=1)\n",
    "#     print('ac spans:', ac_spans.shape)\n",
    "#     fts_spans = fts_spans.flatten(start_dim=1) ### xxx\n",
    "#     print('fts spans:', fts_spans.shape)\n",
    "    \n",
    "#     outputs_am = outputs[:,am_spans,:]\n",
    "#     print('outputs am before cat:', outputs_am.shape)\n",
    "#     outputs_am = torch.cat([outputs_am[i,i,:,:] for i in range(batch_size)], dim=0)\n",
    "#     print('outputs am after cat:', outputs_am.shape)\n",
    "#     outputs_am = outputs_am.reshape(batch_size, nr_span_indices, -1)\n",
    "#     print('outputs am after reshape:', outputs_am.shape)\n",
    "    \n",
    "#     ### Now that we have outputs_am i.e. outputs at am_span indices, now create the four Kuri forumlas for AMs\n",
    "    \n",
    "#     # ============== FIRST TERM ===================\n",
    "    \n",
    "#     outputs_am_first_term = torch.cat([outputs_am[:,i+1,:] - outputs_am[:,i-1,:] for i in range(0, nr_span_indices, 3)], dim=1) \n",
    "#     outputs_am_first_term = outputs_am_first_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "#     # ============== SECOND TERM ==================\n",
    "    \n",
    "#     outputs_am_second_term = torch.cat([outputs_am[:,i,:] - outputs_am[:,i+1,:] for i in range(0, nr_span_indices, 3)], dim=1) # changed + 2 to + 1 to make it run # changed from +1 to +2 to ensure +2 is not a problem for AMs\n",
    "#     outputs_am_second_term = outputs_am_second_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "    \n",
    "#     # ============== THIRD TERM ==================\n",
    "    \n",
    "#     outputs_am_third_term = torch.cat([outputs_am[:,i-1,:] for i in range(0, nr_span_indices, 3)], dim=1)\n",
    "#     outputs_am_third_term = outputs_am_third_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "#     # ============== FOURTH TERM ==================\n",
    "    \n",
    "#     outputs_am_fourth_term = torch.cat([outputs_am[:,i+1,:] for i in range(0, nr_span_indices, 3)], dim=1) # changed + 2 to + 1 to make it run # changed from +1 to +2 to ensure +2 is not a problem for AMs\n",
    "#     outputs_am_fourth_term = outputs_am_fourth_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "#     # ============== NOW CONCATENATE THEM =========\n",
    "    \n",
    "    \n",
    "#     am_minus_representations = torch.cat([outputs_am_first_term, outputs_am_second_term, outputs_am_third_term, outputs_am_fourth_term], dim=-1)  \n",
    "    \n",
    "#     print('am reps apres:', am_minus_representations.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     ### am minus span representation according to kuribayashi paper is now here.\n",
    "    \n",
    "\n",
    "    \n",
    "#     outputs_ac = outputs[:,ac_spans,:]\n",
    "#     # print('outputs ac shape:', outputs_ac.shape)\n",
    "#     outputs_ac = torch.cat([outputs_ac[i,i,:,:] for i in range(batch_size)], dim=0)\n",
    "    \n",
    "#     outputs_ac = outputs_ac.reshape(batch_size, nr_span_indices, -1)\n",
    "    \n",
    "#     ### Now that we have outputs_ac i.e. outputs at ac_span indices, now create the four Kuri forumlas for ACs    \n",
    "    \n",
    "#     # ============== FIRST TERM ===================\n",
    "    \n",
    "#     outputs_ac_first_term = torch.cat([outputs_ac[:,i+1,:] - outputs_ac[:,i-1,:] for i in range(0, nr_span_indices, 3)], dim=1)\n",
    "#     outputs_ac_first_term = outputs_ac_first_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "#     # ============== SECOND TERM ==================\n",
    "    \n",
    "#     outputs_ac_second_term = torch.cat([outputs_ac[:,i,:] - outputs_ac[:,i+1,:] for i in range(0, nr_span_indices, 3)], dim=1) # changed + 2 to + 1 to make it run\n",
    "#     outputs_ac_second_term = outputs_ac_second_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "    \n",
    "#     # ============== THIRD TERM ==================\n",
    "    \n",
    "#     outputs_ac_third_term = torch.cat([outputs_ac[:,i-1,:] for i in range(0, nr_span_indices, 3)], dim=1)\n",
    "#     outputs_ac_third_term = outputs_ac_third_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "#     # ============== FOURTH TERM ==================\n",
    "    \n",
    "#     outputs_ac_fourth_term = torch.cat([outputs_ac[:,i+1,:] for i in range(0, nr_span_indices, 3)], dim=1) # changed + 2 to + 1 to make it run\n",
    "#     outputs_ac_fourth_term = outputs_ac_fourth_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "#     # ============== NOW CONCATENATE THEM =========\n",
    "    \n",
    "    \n",
    "#     ac_minus_representations = torch.cat([outputs_ac_first_term, outputs_ac_second_term, outputs_ac_third_term, outputs_ac_fourth_term], dim=-1)   \n",
    "    \n",
    "    \n",
    "    \n",
    "#     ### ac minus span representation according to kuribayashi paper is now here.\n",
    "    \n",
    "#     ### Now that we have outputs_ac i.e. outputs at ac_span indices, now create the four Kuri forumlas for Features as Text \n",
    "    \n",
    "#     outputs_fts = outputs[:,fts_spans,:]\n",
    "#     #print('outputs fts shape:', outputs_fts.shape)\n",
    "#     outputs_fts = torch.cat([outputs_fts[i,i,:,:] for i in range(batch_size)], dim=0)\n",
    "    \n",
    "#     outputs_fts = outputs_fts.reshape(batch_size, nr_span_indices, -1)\n",
    "    \n",
    "#     ### Now that we have outputs_ac i.e. outputs at ac_span indices, now create the four Kuri forumlas for ACs    \n",
    "    \n",
    "#     # ============== FIRST TERM ===================\n",
    "    \n",
    "#     outputs_fts_first_term = torch.cat([outputs_fts[:,i+1,:] - outputs_fts[:,i-1,:] for i in range(0, nr_span_indices, 3)], dim=1)\n",
    "#     outputs_fts_first_term = outputs_fts_first_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "#     # ============== SECOND TERM ==================\n",
    "    \n",
    "#     outputs_fts_second_term = torch.cat([outputs_fts[:,i,:] - outputs_fts[:,i+1,:] for i in range(0, nr_span_indices, 3)], dim=1) # changed + 2 to + 1 to make it run\n",
    "#     outputs_fts_second_term = outputs_fts_second_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "    \n",
    "#     # ============== THIRD TERM ==================\n",
    "    \n",
    "#     outputs_fts_third_term = torch.cat([outputs_fts[:,i-1,:] for i in range(0, nr_span_indices, 3)], dim=1)\n",
    "#     outputs_fts_third_term = outputs_fts_third_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "#     # ============== FOURTH TERM ==================\n",
    "    \n",
    "#     outputs_fts_fourth_term = torch.cat([outputs_fts[:,i+1,:] for i in range(0, nr_span_indices, 3)], dim=1) # changed + 2 to + 1 to make it run\n",
    "#     outputs_fts_fourth_term = outputs_fts_fourth_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "#     # ============== NOW CONCATENATE THEM =========\n",
    "    \n",
    "    \n",
    "#     fts_minus_representations = torch.cat([outputs_fts_first_term, outputs_fts_second_term, outputs_fts_third_term, outputs_fts_fourth_term], dim=-1)\n",
    "    \n",
    "\n",
    "    \n",
    "#     return am_minus_representations, ac_minus_representations, fts_minus_representations                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a8b33c",
   "metadata": {},
   "source": [
    "## custom BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b02aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBERTKuri(nn.Module):\n",
    "\n",
    "    def __init__(self, first_model, model_am, model_ac, model_fts, nr_classes):\n",
    "        \n",
    "        super(CustomBERTKuri, self).__init__()\n",
    "        \n",
    "        self.first_model = first_model\n",
    "        \n",
    "        self.intermediate_linear_am = nn.Linear(3072, 768)\n",
    "        self.intermediate_linear_ac = nn.Linear(3072, 768) \n",
    "        self.intermediate_linear_fts = nn.Linear(3072, 768)\n",
    "        \n",
    "        self.model_am = model_am\n",
    "        self.model_ac = model_ac\n",
    "        self.model_fts = model_fts\n",
    "        \n",
    "        self.nr_classes = nr_classes\n",
    "                \n",
    "        self.fc = nn.Linear(self.model_am.config.hidden_size + self.model_ac.config.hidden_size + self.model_fts.config.hidden_size, self.nr_classes)\n",
    "        # self.fc = nn.Linear(self.model_am.config.hidden_size + self.model_ac.config.hidden_size, self.nr_classes) \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        batch_tokenized, batch_spans = inputs \n",
    "        outputs = self.first_model(batch_tokenized)[0] # ** removed to correct error.\n",
    "        # spans = batch_spans # remove this spans thing cause we are now giving it just the spans themselves.\n",
    "        am_minus_representations, ac_minus_representations, fts_minus_representations = get_span_representations(outputs, batch_spans)\n",
    "        print('passed and gotten reps for all three successfully!')\n",
    "        print('am rep final in model:', am_minus_representations.shape)\n",
    "        print('ac rep final in model:', ac_minus_representations.shape)\n",
    "        print('fts rep final in model:', fts_minus_representations.shape)\n",
    "        #am_minus_representations, ac_minus_representations = get_span_representations(outputs, batch_spans)\n",
    "        \n",
    "        #print('am minus rep:', am_minus_representations.shape)\n",
    "        #print('ac minus rep:', ac_minus_representations.shape)\n",
    "        #print('fts minus rep:', fts_minus_representations.shape)\n",
    "\n",
    "        am_minus_representations = self.intermediate_linear_am(am_minus_representations)\n",
    "        print('passed first linear')\n",
    "        ac_minus_representations = self.intermediate_linear_ac(ac_minus_representations)\n",
    "        print('passed second linear')\n",
    "        fts_minus_representations = self.intermediate_linear_fts(fts_minus_representations)\n",
    "        print('passed third linear')\n",
    "        \n",
    "        #print('am minus rep:', am_minus_representations.shape)\n",
    "        #print('ac minus rep:', ac_minus_representations.shape)\n",
    "        #print('fts minus rep:', fts_minus_representations.shape)\n",
    "\n",
    "        output_model_am = self.model_am(inputs_embeds = am_minus_representations)[0]\n",
    "        output_model_ac = self.model_ac(inputs_embeds = ac_minus_representations)[0]\n",
    "        output_model_fts = self.model_fts(inputs_embeds = fts_minus_representations)[0]\n",
    "\n",
    "        adu_representations = torch.cat([output_model_am, output_model_ac, output_model_fts], dim=-1)\n",
    "        #adu_representations = torch.cat([output_model_am, output_model_ac], dim=-1)\n",
    "        # print(\"adu rep:\", adu_representations.shape)\n",
    "        output = self.fc(adu_representations)\n",
    "        # print(\"model class output avant reshape:\", output.shape)\n",
    "        # output = output.reshape(-1, self.nr_classes)\n",
    "        # print(\"model class output apres:\", output.shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81690411",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12f84d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 1\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b409f20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_model = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "027cc1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_am = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7da85708",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ac = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75ef992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fts = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09c9cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = CustomBERTKuri(first_model, model_am, model_ac, model_fts, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f0b6726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomBERTKuri(\n",
       "  (first_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (intermediate_linear_am): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (intermediate_linear_ac): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (intermediate_linear_fts): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (model_am): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (model_ac): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (model_fts): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=2304, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a78f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(ignore_index=- 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1155e8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(custom_model.parameters(), lr=1.8738174228603844e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d456799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.8738174228603844e-05\n",
    "# best learning rate found by the whole leslie business\n",
    "# new best LR found= 9.999999999999997e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "477ecf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_BATCHES = len(dataset['train']) / BATCH_SIZE\n",
    "num_training_steps = NB_EPOCHS * NR_BATCHES\n",
    "num_warmup_steps = int(0.2 * num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e86c2ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_lambda(current_step: int):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        return max(\n",
    "            0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        )\n",
    "\n",
    "    # return LambdaLR(optimizer, lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb50416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented for LR Finder. remove it from optimizer.\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3974e6",
   "metadata": {},
   "source": [
    "### create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dacd1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset['train'], batch_size=BATCH_SIZE, shuffle=False) # xxx.\n",
    "val_dataloader = DataLoader(dataset['validation'], batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset['test'], batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d806fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(list_of_lists):\n",
    "    return [x for sublist in list_of_lists for x in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33afb4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dummy_labels(test_preds, test_labels):\n",
    "    \n",
    "    idxes = []\n",
    "    test_labels_l = []\n",
    "    for idx, val in enumerate(test_labels):\n",
    "        if val != -100:\n",
    "            idxes.append(idx)\n",
    "            test_labels_l.append(val)\n",
    "    \n",
    "    test_preds_l = []\n",
    "    for idx, val in enumerate(test_preds):\n",
    "        for good_idx in idxes:\n",
    "            if idx == good_idx:\n",
    "                test_preds_l.append(val)\n",
    "        \n",
    "    return test_preds_l, test_labels_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c50ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, b in enumerate(train_dataloader):\n",
    "    if i == 40:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "670199c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'input_ids': tensor([[ 101, 1999, 7091,  ...,    0,    0,    0],\n",
       "         [ 101, 2000, 4088,  ..., 2256, 2147,  102],\n",
       "         [ 101, 4914, 2135,  ...,    0,    0,    0],\n",
       "         [ 101, 2009, 2003,  ...,    0,    0,    0]]),\n",
       " 'label': tensor([[   0,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   1,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2],\n",
       "         [   1,    2,    2,    2, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   1,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]),\n",
       " 'spans': tensor([[[  0,   1],\n",
       "          [  3,  15],\n",
       "          [ 17,  44],\n",
       "          [ -1,  -1],\n",
       "          [ 48,  52],\n",
       "          [ 54,  81],\n",
       "          [ -1,  -1],\n",
       "          [ 84,  99],\n",
       "          [101, 128],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1]],\n",
       " \n",
       "         [[  0,   2],\n",
       "          [  4,  14],\n",
       "          [ 16,  43],\n",
       "          [ -1,  -1],\n",
       "          [ 48,  63],\n",
       "          [ 65,  92],\n",
       "          [ -1,  -1],\n",
       "          [ 95, 111],\n",
       "          [113, 140],\n",
       "          [ -1,  -1],\n",
       "          [143, 151],\n",
       "          [153, 180],\n",
       "          [183, 183],\n",
       "          [185, 197],\n",
       "          [199, 226],\n",
       "          [ -1,  -1],\n",
       "          [234, 243],\n",
       "          [245, 272],\n",
       "          [ -1,  -1],\n",
       "          [275, 281],\n",
       "          [283, 310],\n",
       "          [313, 313],\n",
       "          [315, 324],\n",
       "          [326, 353],\n",
       "          [ -1,  -1],\n",
       "          [356, 371],\n",
       "          [373, 400],\n",
       "          [ -1,  -1],\n",
       "          [406, 421],\n",
       "          [423, 450],\n",
       "          [ -1,  -1],\n",
       "          [453, 460],\n",
       "          [462, 489],\n",
       "          [492, 492],\n",
       "          [494, 510],\n",
       "          [512, 539]],\n",
       " \n",
       "         [[  0,   1],\n",
       "          [  3,  21],\n",
       "          [ 23,  50],\n",
       "          [ -1,  -1],\n",
       "          [ 56,  78],\n",
       "          [ 80, 107],\n",
       "          [110, 110],\n",
       "          [112, 154],\n",
       "          [156, 183],\n",
       "          [ -1,  -1],\n",
       "          [186, 202],\n",
       "          [204, 231],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1]],\n",
       " \n",
       "         [[ -1,  -1],\n",
       "          [ 29,  45],\n",
       "          [ 47,  74],\n",
       "          [ 77,  79],\n",
       "          [ 83,  88],\n",
       "          [ 90, 117],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1],\n",
       "          [ -1,  -1]]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6e8fa5",
   "metadata": {},
   "source": [
    "### training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0d4e7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "839e84f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch_lr_finder import LRFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c12b8bb",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 27,
     "id": "521987db-56d5-4e71-95af-7d1fb4a06e3f",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "# def compute_loss(self, model, inputs, return_outputs=False):\n",
    "\n",
    "#     labels = inputs[\"labels\"]\n",
    "#     labels = labels.flatten() # xxx.\n",
    "\n",
    "\n",
    "\n",
    "#     outputs = model(inputs['input_ids'], inputs['spans'])\n",
    "#     outputs = outputs.flatten(0,1) # xxx. for the 4 x 12 , 3 output of the main class.\n",
    "\n",
    "\n",
    "#     loss_fct = nn.CrossEntropyLoss()#(weight=class_weights)\n",
    "#     # loss = loss_fct(outputs, labels.flatten())\n",
    "#     loss = loss_fct(outputs, labels) # xxx\n",
    "#     #print(\"loss:\", loss)\n",
    "#     return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53637770",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 28,
     "id": "06697293-0ef4-4d24-95a9-6ca0ed569b51",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# metric = load_metric('f1')\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "\n",
    "#     logits, labels = eval_pred\n",
    "\n",
    "    \n",
    "#     print(\"logits\", logits.shape)    \n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "#     print(\"preds:\", predictions.shape)\n",
    "    \n",
    "#     return metric.compute(predictions=predictions, references=labels, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67559344",
   "metadata": {},
   "source": [
    "### LR Finder Leslie Smith "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5a48e93",
   "metadata": {},
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, dataset):\n",
    "        'Initialization'\n",
    "        self.inputs = dataset['input_ids'], dataset['spans']\n",
    "        self.labels = dataset['label']\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        # ID = self.inputs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = self.inputs[0][index], self.inputs[1][index] \n",
    "        # X = torch.load('data/' + ID + '.pt')\n",
    "        y = self.labels[index]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0930b3af",
   "metadata": {},
   "source": [
    "custom_train_dataset = CustomDataset(dataset['train'])\n",
    "custom_test_dataset = CustomDataset(dataset['test'])\n",
    "custom_val_dataset = CustomDataset(dataset['validation'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a62097ed",
   "metadata": {},
   "source": [
    "train_dataloader = DataLoader(custom_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(custom_test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(custom_val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ad5caff",
   "metadata": {},
   "source": [
    "class CustomCrossEntropyLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss(ignore_index=- 100)\n",
    "        \n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        input = input.flatten(0,1) \n",
    "        target = target.flatten()\n",
    "        return self.loss.forward(input, target)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae98d425",
   "metadata": {},
   "source": [
    "loss = CustomCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "992e30d2",
   "metadata": {},
   "source": [
    "optimizer = torch.optim.AdamW(custom_model.parameters(), lr=1e-8, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9962a025",
   "metadata": {},
   "source": [
    "lr_finder = LRFinder(custom_model, optimizer, loss, device=device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31bfeccf",
   "metadata": {},
   "source": [
    "lr_finder.range_test(train_dataloader, val_loader=val_dataloader, step_mode='exp')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "46c2459a",
   "metadata": {},
   "source": [
    "lr_finder.plot() # to inspect the loss-learning rate graph"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0b00672",
   "metadata": {},
   "source": [
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805c68c9",
   "metadata": {},
   "source": [
    "## training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8181a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss=None, optimizer=None, train_dataloader=None, val_dataloader=None, nb_epochs=20):\n",
    "    \"\"\"Training loop\"\"\"\n",
    "\n",
    "    min_f1 = -torch.inf\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Iterrate over epochs\n",
    "    for e in range(nb_epochs):\n",
    "\n",
    "        # Training\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for i, batch in enumerate(tqdm(train_dataloader)):            \n",
    "            \n",
    "            print(i)\n",
    "            # unpack batch             \n",
    "            labels = batch['label'].to(device)\n",
    "            spans = batch['spans'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            \n",
    "            inputs = input_ids, spans\n",
    "            \n",
    "            # Reset gradients to 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute training loss\n",
    "            current_loss = loss(outputs.flatten(0,1), labels.flatten())\n",
    "            train_loss += current_loss.detach().item()\n",
    "\n",
    "            # Compute gradients\n",
    "            current_loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()            \n",
    "            \n",
    "            del batch\n",
    "        \n",
    "        scheduler.step()\n",
    "            \n",
    "        \n",
    "        # Validation\n",
    "        val_loss = 0.0\n",
    "\n",
    "        # Put model in eval mode\n",
    "        model.eval()\n",
    "        \n",
    "        preds_l = []\n",
    "        labels_l = []\n",
    "        \n",
    "        for batch in tqdm(val_dataloader):            \n",
    "            \n",
    "            # unpack batch             \n",
    "            labels = batch['label'].to(device)\n",
    "            spans = batch['spans'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            \n",
    "            inputs = input_ids, spans\n",
    "            \n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute validation loss\n",
    "            current_loss = loss(outputs.flatten(0,1), labels.flatten())\n",
    "            val_loss += current_loss.detach().item()\n",
    "            \n",
    "            preds_for_f1 = torch.argmax(outputs, dim=2).flatten().tolist()\n",
    "            labels_for_f1 = labels.flatten().tolist()\n",
    "            \n",
    "            preds_l.append(preds_for_f1)\n",
    "            labels_l.append(labels_for_f1)\n",
    "            \n",
    "            del batch\n",
    "        \n",
    "        # Prints\n",
    "        \n",
    "        preds_l = flatten_list(preds_l)\n",
    "        labels_l = flatten_list(labels_l)\n",
    "        \n",
    "        preds_l, labels_l = remove_dummy_labels(preds_l, labels_l)\n",
    "        \n",
    "        f1_score_epoch = f1_score(preds_l, labels_l, average='macro')        \n",
    "        \n",
    "        print(f\"Epoch {e+1}/{nb_epochs} \\\n",
    "                \\t Training Loss: {train_loss/len(train_dataloader):.3f} \\\n",
    "                \\t Validation Loss: {val_loss/len(val_dataloader):.3f} \\\n",
    "                \\t F1 score: {f1_score_epoch}\")\n",
    "        \n",
    "        train_losses.append(train_loss/len(train_dataloader))\n",
    "        val_losses.append(val_loss/len(val_dataloader))\n",
    "        \n",
    "\n",
    "        # Save model if val loss decreases\n",
    "        if f1_score_epoch > min_f1:\n",
    "\n",
    "            min_f1 = f1_score_epoch\n",
    "            torch.save(model.first_model.state_dict(), 'first_model.pt')\n",
    "            torch.save(model.model_am.state_dict(), 'model_am.pt')\n",
    "            torch.save(model.model_ac.state_dict(), 'model_ac.pt')\n",
    "            torch.save(model.model_fts.state_dict(), 'model_fts.pt')\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "            \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1427c1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/272 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/272 [00:00<04:10,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/272 [00:01<02:58,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/272 [00:01<02:31,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/272 [00:02<02:21,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/272 [00:02<02:14,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/272 [00:03<02:10,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7/272 [00:03<02:05,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/272 [00:04<02:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/272 [00:04<02:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 10/272 [00:05<02:03,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 11/272 [00:05<02:02,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/272 [00:05<02:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 13/272 [00:06<01:58,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 14/272 [00:06<01:57,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 15/272 [00:07<01:55,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 16/272 [00:07<01:54,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 17/272 [00:08<01:54,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 18/272 [00:08<01:53,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 19/272 [00:09<01:55,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/272 [00:09<01:54,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 21/272 [00:10<01:54,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 22/272 [00:10<01:53,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 23/272 [00:10<01:52,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 24/272 [00:11<01:52,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 25/272 [00:11<01:50,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 26/272 [00:12<01:51,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 27/272 [00:12<01:53,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 28/272 [00:13<01:52,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 29/272 [00:13<01:52,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 30/272 [00:14<01:50,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 31/272 [00:14<01:49,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 32/272 [00:15<01:49,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 33/272 [00:15<01:49,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 34/272 [00:15<01:47,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 35/272 [00:16<01:46,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 36/272 [00:16<01:45,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 37/272 [00:17<01:47,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 38/272 [00:17<01:50,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 39/272 [00:18<01:50,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n",
      "passed first linear\n",
      "passed second linear\n",
      "passed third linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 40/272 [00:18<01:49,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "am rep final: torch.Size([4, 12, 3072])\n",
      "ac rep final: torch.Size([4, 12, 3072])\n",
      "fts rep final: torch.Size([4, 12, 3072])\n",
      "passed and gotten reps for all three successfully!\n",
      "am rep final in model: torch.Size([4, 12, 3072])\n",
      "ac rep final in model: torch.Size([4, 12, 3072])\n",
      "fts rep final in model: torch.Size([4, 12, 3072])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_282/4122650626.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNB_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_282/2827550333.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss, optimizer, train_dataloader, val_dataloader, nb_epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# Forward Pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# Compute training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_282/4101534835.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#print('fts minus rep:', fts_minus_representations.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mam_minus_representations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_linear_am\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mam_minus_representations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'passed first linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mac_minus_representations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_linear_ac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mac_minus_representations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1849\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1851\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train(custom_model, loss, optimizer, train_dataloader, val_dataloader, NB_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3ce292",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7500c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load best model\n",
    "# network_2 = Network()\n",
    "\n",
    "# network_2.load_state_dict(torch.load(path))\n",
    "# network_2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f1c90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_model = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))\n",
    "first_model.load_state_dict(torch.load('first_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5310a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_am = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))\n",
    "model_am.load_state_dict(torch.load('model_am.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd81d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ac = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))\n",
    "model_ac.load_state_dict(torch.load('model_ac.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9133c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fts = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))\n",
    "model_fts.load_state_dict(torch.load('model_fts.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa65b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load best model\n",
    "\n",
    "custom_model_2 = CustomBERTKuri(first_model, model_am, model_ac, model_fts, 3)\n",
    "custom_model_2.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "custom_model_2.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_dataloader=None):\n",
    "    \n",
    "    \"\"\"Prediction loop\"\"\"\n",
    "\n",
    "    preds_l = []\n",
    "    labels_l = []\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch in test_dataloader:            \n",
    "            \n",
    "        # unpack batch             \n",
    "        labels = batch['label'].to(device).flatten().tolist()\n",
    "        spans = batch['spans'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        \n",
    "        inputs = input_ids, spans\n",
    "\n",
    "        # get output\n",
    "        \n",
    "        raw_preds = model(inputs).to('cpu')\n",
    "        # print(raw_preds.shape)\n",
    "        raw_preds = raw_preds.detach()#.numpy()\n",
    "\n",
    "        # Compute argmax\n",
    "        \n",
    "        predictions = torch.argmax(raw_preds, dim=2).flatten().tolist()\n",
    "        preds_l.append(predictions)\n",
    "        labels_l.append(labels)        \n",
    "        \n",
    "        del batch\n",
    "            \n",
    "    return flatten_list(preds_l), flatten_list(labels_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08baad3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test_preds, test_labels = predict(custom_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1e8c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(test_labels, test_preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498b18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove -100s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668bcedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_preds_l, test_labels_l = remove_dummy_labels(test_preds, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09328566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(test_labels_l, test_preds_l, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### -100 done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce21adaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_preds, test_labels = predict(custom_model_2, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c6fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labels, test_preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee31384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_l, test_labels_l = remove_dummy_labels(test_preds, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8db9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_labels_l, test_preds_l, digits=3))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8c49c59",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "           0      0.897     0.677     0.772       155\n",
    "           1      0.577     0.640     0.607       303\n",
    "           2      0.869     0.875     0.872       805\n",
    "\n",
    "    accuracy                          0.794      1263\n",
    "   macro avg      0.781     0.731     0.750      1263\n",
    "weighted avg      0.803     0.794     0.796      1263\n",
    "\n",
    "40 epochs. learning rate: 1.8e-5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "946cd387",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "           0      0.803     0.735     0.768       155\n",
    "           1      0.604     0.508     0.552       303\n",
    "           2      0.843     0.907     0.874       805\n",
    "\n",
    "    accuracy                          0.790      1263\n",
    "   macro avg      0.750     0.717     0.731      1263\n",
    "weighted avg      0.781     0.790     0.784      1263\n",
    "\n",
    "40 epochs. learning rate: 9.999997e-6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
