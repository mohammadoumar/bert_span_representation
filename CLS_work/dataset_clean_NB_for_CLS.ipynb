{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea8d34a8",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7008b3a2-1f1f-432b-a232-71b4d9af1246",
     "kernelId": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting pandas==1.3.4\n",
      "  Downloading pandas-1.3.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 13.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.3.4) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.3.4) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.3.4) (1.21.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.3.4) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.5.3\n",
      "    Uninstalling pandas-1.5.3:\n",
      "      Successfully uninstalled pandas-1.5.3\n",
      "Successfully installed pandas-1.3.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting transformers==4.12.5\n",
      "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 19.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (2021.10.8)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (0.0.46)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (1.21.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (3.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (0.11.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 54.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.12.5) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.12.5) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (2.0.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.12.5) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.12.5) (8.0.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.12.5) (1.1.0)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.25.1\n",
      "    Uninstalling transformers-4.25.1:\n",
      "      Successfully uninstalled transformers-4.25.1\n",
      "Successfully installed tokenizers-0.10.3 transformers-4.12.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting datasets==1.15.1\n",
      "  Downloading datasets-1.15.1-py3-none-any.whl (290 kB)\n",
      "\u001b[K     |████████████████████████████████| 290 kB 20.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (4.62.3)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (3.8.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (21.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (2.26.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (0.70.14)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (1.3.4)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (10.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (1.21.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (2023.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (0.11.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (3.2.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (0.3.6)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (2.0.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (21.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.15.1) (3.10.0.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.15.1) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.15.1) (5.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets==1.15.1) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.15.1) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.15.1) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.15.1) (1.26.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets==1.15.1) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets==1.15.1) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets==1.15.1) (1.16.0)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.8.0\n",
      "    Uninstalling datasets-2.8.0:\n",
      "      Successfully uninstalled datasets-2.8.0\n",
      "Successfully installed datasets-1.15.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas==1.3.4\n",
    "!pip install transformers==4.12.5\n",
    "!pip install datasets==1.15.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0e9ce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.0.4)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.28.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.5)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.5)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (58.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: IProgress in /opt/conda/lib/python3.8/site-packages (0.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from IProgress) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n",
    "!pip install IProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5f053f",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a705b996-66aa-4aa6-9ce0-1edd956b8866",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "import datasets\n",
    "from datasets import concatenate_datasets\n",
    "from datasets import Dataset\n",
    "from datasets import ClassLabel\n",
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c79a68b",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a8a8872d-0a98-4bd7-b38a-37810f8cdab3",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas:\t\t 1.3.4\n",
      "transformers:\t 4.12.5\n",
      "datasets:\t 1.15.1\n"
     ]
    }
   ],
   "source": [
    "print('pandas:\\t\\t', pd.__version__)\n",
    "print('transformers:\\t', transformers.__version__)\n",
    "print('datasets:\\t', datasets.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f05a4c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5bf6295b-ee0c-47fa-8aa7-4aa06f0bab27",
     "kernelId": ""
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "261ea40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_pickle(\"/notebooks/KURI-BERT/notebooks/full_formula_w_fts/df_pe_for_kuri_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0da77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>paragraph_components_list</th>\n",
       "      <th>paragraph_labels_list</th>\n",
       "      <th>paragraph_markers_list</th>\n",
       "      <th>split</th>\n",
       "      <th>essay_nr</th>\n",
       "      <th>structural_fts_as_text_combined</th>\n",
       "      <th>paragraph_labels_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is always said that competition can effecti...</td>\n",
       "      <td>[[we should attach more importance to cooperat...</td>\n",
       "      <td>[[MajorClaim]]</td>\n",
       "      <td>[[from this point of view]]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay001</td>\n",
       "      <td>[Topic: Should students be taught to compete o...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First of all, through cooperation, children ca...</td>\n",
       "      <td>[[through cooperation, children can learn abou...</td>\n",
       "      <td>[[Claim], [Premise], [Premise], [Premise]]</td>\n",
       "      <td>[[first of all], [], [], []]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay001</td>\n",
       "      <td>[Topic: Should students be taught to compete o...</td>\n",
       "      <td>[1, 2, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On the other hand, the significance of competi...</td>\n",
       "      <td>[[the significance of competition is that how ...</td>\n",
       "      <td>[[Premise], [Claim], [Premise], [Premise], [Cl...</td>\n",
       "      <td>[[on the other hand], [hence], [however], [], []]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay001</td>\n",
       "      <td>[Topic: Should students be taught to compete o...</td>\n",
       "      <td>[2, 1, 2, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consequently, no matter from the view of indiv...</td>\n",
       "      <td>[[a more cooperative attitudes towards life is...</td>\n",
       "      <td>[[MajorClaim]]</td>\n",
       "      <td>[[consequently]]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay001</td>\n",
       "      <td>[Topic: Should students be taught to compete o...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The last 50 years have seen an increasing numb...</td>\n",
       "      <td>[[they are able to sustain their cultural iden...</td>\n",
       "      <td>[[MajorClaim]]</td>\n",
       "      <td>[[however]]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay002</td>\n",
       "      <td>[Topic: More people are migrating to other cou...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>In conclusion, fatherhood should be as present...</td>\n",
       "      <td>[[fatherhood should be as present as motherhoo...</td>\n",
       "      <td>[[MajorClaim]]</td>\n",
       "      <td>[[in conclusion]]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay401</td>\n",
       "      <td>[Topic: Fatherhood should be as present as mot...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>Some people believe that studying hard is esse...</td>\n",
       "      <td>[[both of studying hard and playing sports are...</td>\n",
       "      <td>[[MajorClaim]]</td>\n",
       "      <td>[[in my point of view]]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay402</td>\n",
       "      <td>[Topic: Children should studying hard or playi...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>On the other hand, studying hard will give chi...</td>\n",
       "      <td>[[studying hard will give children a better fu...</td>\n",
       "      <td>[[Claim], [Premise], [Premise], [Premise], [Pr...</td>\n",
       "      <td>[[on the other hand], [], [for instance], [], []]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay402</td>\n",
       "      <td>[Topic: Children should studying hard or playi...</td>\n",
       "      <td>[1, 2, 2, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>At the same time, playing sports will give goo...</td>\n",
       "      <td>[[playing sports will give good effects on chi...</td>\n",
       "      <td>[[Claim], [Premise], [Premise], [Premise], [Pr...</td>\n",
       "      <td>[[], [], [firstly], [], [because], [], [so], [...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay402</td>\n",
       "      <td>[Topic: Children should studying hard or playi...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>In conclusion, both studying hard at school an...</td>\n",
       "      <td>[[both studying hard at school and playing spo...</td>\n",
       "      <td>[[MajorClaim]]</td>\n",
       "      <td>[[in conclusion]]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay402</td>\n",
       "      <td>[Topic: Children should studying hard or playi...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1719 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              paragraph  \\\n",
       "0     It is always said that competition can effecti...   \n",
       "1     First of all, through cooperation, children ca...   \n",
       "2     On the other hand, the significance of competi...   \n",
       "3     Consequently, no matter from the view of indiv...   \n",
       "4     The last 50 years have seen an increasing numb...   \n",
       "...                                                 ...   \n",
       "1714  In conclusion, fatherhood should be as present...   \n",
       "1715  Some people believe that studying hard is esse...   \n",
       "1716  On the other hand, studying hard will give chi...   \n",
       "1717  At the same time, playing sports will give goo...   \n",
       "1718  In conclusion, both studying hard at school an...   \n",
       "\n",
       "                              paragraph_components_list  \\\n",
       "0     [[we should attach more importance to cooperat...   \n",
       "1     [[through cooperation, children can learn abou...   \n",
       "2     [[the significance of competition is that how ...   \n",
       "3     [[a more cooperative attitudes towards life is...   \n",
       "4     [[they are able to sustain their cultural iden...   \n",
       "...                                                 ...   \n",
       "1714  [[fatherhood should be as present as motherhoo...   \n",
       "1715  [[both of studying hard and playing sports are...   \n",
       "1716  [[studying hard will give children a better fu...   \n",
       "1717  [[playing sports will give good effects on chi...   \n",
       "1718  [[both studying hard at school and playing spo...   \n",
       "\n",
       "                                  paragraph_labels_list  \\\n",
       "0                                        [[MajorClaim]]   \n",
       "1            [[Claim], [Premise], [Premise], [Premise]]   \n",
       "2     [[Premise], [Claim], [Premise], [Premise], [Cl...   \n",
       "3                                        [[MajorClaim]]   \n",
       "4                                        [[MajorClaim]]   \n",
       "...                                                 ...   \n",
       "1714                                     [[MajorClaim]]   \n",
       "1715                                     [[MajorClaim]]   \n",
       "1716  [[Claim], [Premise], [Premise], [Premise], [Pr...   \n",
       "1717  [[Claim], [Premise], [Premise], [Premise], [Pr...   \n",
       "1718                                     [[MajorClaim]]   \n",
       "\n",
       "                                 paragraph_markers_list  split  essay_nr  \\\n",
       "0                           [[from this point of view]]  TRAIN  essay001   \n",
       "1                          [[first of all], [], [], []]  TRAIN  essay001   \n",
       "2     [[on the other hand], [hence], [however], [], []]  TRAIN  essay001   \n",
       "3                                      [[consequently]]  TRAIN  essay001   \n",
       "4                                           [[however]]  TRAIN  essay002   \n",
       "...                                                 ...    ...       ...   \n",
       "1714                                  [[in conclusion]]  TRAIN  essay401   \n",
       "1715                            [[in my point of view]]  TRAIN  essay402   \n",
       "1716  [[on the other hand], [], [for instance], [], []]  TRAIN  essay402   \n",
       "1717  [[], [], [firstly], [], [because], [], [so], [...  TRAIN  essay402   \n",
       "1718                                  [[in conclusion]]  TRAIN  essay402   \n",
       "\n",
       "                        structural_fts_as_text_combined  \\\n",
       "0     [Topic: Should students be taught to compete o...   \n",
       "1     [Topic: Should students be taught to compete o...   \n",
       "2     [Topic: Should students be taught to compete o...   \n",
       "3     [Topic: Should students be taught to compete o...   \n",
       "4     [Topic: More people are migrating to other cou...   \n",
       "...                                                 ...   \n",
       "1714  [Topic: Fatherhood should be as present as mot...   \n",
       "1715  [Topic: Children should studying hard or playi...   \n",
       "1716  [Topic: Children should studying hard or playi...   \n",
       "1717  [Topic: Children should studying hard or playi...   \n",
       "1718  [Topic: Children should studying hard or playi...   \n",
       "\n",
       "      paragraph_labels_numeric  \n",
       "0                          [0]  \n",
       "1                 [1, 2, 2, 2]  \n",
       "2              [2, 1, 2, 2, 1]  \n",
       "3                          [0]  \n",
       "4                          [0]  \n",
       "...                        ...  \n",
       "1714                       [0]  \n",
       "1715                       [0]  \n",
       "1716           [1, 2, 2, 2, 2]  \n",
       "1717  [1, 2, 2, 2, 2, 2, 2, 2]  \n",
       "1718                       [0]  \n",
       "\n",
       "[1719 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c7a513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_structural_features(x):\n",
    "    \n",
    "    clean_features_list = []\n",
    "    \n",
    "    strct_fts_list = x.structural_fts_as_text_combined\n",
    "    \n",
    "    for strct_fts in strct_fts_list:\n",
    "        \n",
    "        nr_idx = strct_fts.index(\"Structural Features:\")\n",
    "        clean_fts = strct_fts[nr_idx+len(\"Structural Features:\"):]\n",
    "        clean_features_list.append(clean_fts.lstrip())\n",
    "        \n",
    "    return clean_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99be8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['structural_fts_as_text_combined'] = dataset_df.apply(lambda x: clean_structural_features(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "715f08c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(l):\n",
    "    \n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "578de4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paragraphs with fts inserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e70d26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paragraphs_w_fts(x):\n",
    "    \n",
    "    paragraph = x.paragraph\n",
    "    # paragraph = '[CLS] ' + paragraph\n",
    "    para_fts_as_txt = x.structural_fts_as_text_combined\n",
    "    para_acs = x.paragraph_components_list\n",
    "    para_ams = x.paragraph_markers_list\n",
    "    \n",
    "    for am, ac, ac_fts_as_txt in zip(para_ams, para_acs, para_fts_as_txt):\n",
    "        \n",
    "        end_of_component_idx = paragraph.index(ac[0]) + len(ac[0])\n",
    "        end_of_component_char = paragraph[end_of_component_idx]\n",
    "        \n",
    "        if end_of_component_char != \" \":            \n",
    "            new_ac = ac[0] + end_of_component_char\n",
    "        \n",
    "        else:            \n",
    "            new_ac = ac[0]\n",
    "\n",
    "        fts_as_txt_new = ' Start ' + ac_fts_as_txt + ' Start'         \n",
    "        paragraph = paragraph.replace(ac[0] + end_of_component_char, new_ac + fts_as_txt_new, 1)\n",
    "    \n",
    "    paragraph = 'Start ' + paragraph.rstrip()\n",
    "    \n",
    "    if paragraph[-5:] == 'Start':\n",
    "        \n",
    "        paragraph = paragraph[:-6] \n",
    "\n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33d47911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Start First of all, through cooperation, children can learn about interpersonal skills which are significant in the future life of all students. Start 2, Yes, No, No, No Start What we acquired from team work is not only how to achieve the same goal with others but more importantly, how to get along with others. Start 2, No, No, No, No Start During the process of cooperation, children can learn about how to listen to opinions of others, how to communicate with others, how to think comprehensively, and even how to compromise with other team members when conflicts occurred. Start 2, No, No, No, No Start All of these skills help them to get on well with other people and will benefit them for the whole life. Start 2, No, Yes, No, No'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_paragraphs_w_fts(dataset_df.iloc[1])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94b74aa4",
   "metadata": {},
   "source": [
    "'First of all, through cooperation, children can learn about interpersonal skills which are significant in the future life of all students. [SEP] 2, Yes, No, No, No [SEP] What we acquired from team work is not only how to achieve the same goal with others but more importantly, how to get along with others. [SEP] 2, No, No, No, No [SEP] During the process of cooperation, children can learn about how to listen to opinions of others, how to communicate with others, how to think comprehensively, and even how to compromise with other team members when conflicts occurred. [SEP] 2, No, No, No, No [SEP] All of these skills help them to get on well with other people and will benefit them for the whole life. [SEP] 2, No, Yes, No, No [SEP]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adc3b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['full_paragraph_w_cls'] = dataset_df.apply(lambda x: get_paragraphs_w_fts(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71ea5d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Start Nowadays, there is a prevailing opinion that human needs for farmland, housing and industry are more important Start 1, Yes, Yes, Yes, No StartStart 1, Yes, Yes, Yes, No Startthan saving land for endangered animals. People who disagree with the point dispute that the decreasing of land for endangered animals will bring damage to ecological balance. As far as I am concerned, I agree with the opinion human needs for farmland, housing and industry are more important. The reasons are based on the following aspects.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df['full_paragraph_w_cls'][786]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2e58a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['full_paragraph_w_cls'][786] = 'Start Nowadays, there is a prevailing opinion that human needs for farmland, housing and industry are more important Start 1, Yes, Yes, Yes, No Start than saving land for endangered animals. People who disagree with the point dispute that the decreasing of land for endangered animals will bring damage to ecological balance. As far as I am concerned, I agree with the opinion human needs for farmland, housing and industry are more important. Start 1, No, Yes, Yes, No Start The reasons are based on the following aspects.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ce3b364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paragraph', 'paragraph_components_list', 'paragraph_labels_list',\n",
       "       'paragraph_markers_list', 'split', 'essay_nr',\n",
       "       'structural_fts_as_text_combined', 'paragraph_labels_numeric',\n",
       "       'full_paragraph_w_cls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdff3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['paragraph_labels_list'][1470] = [['Premise'], ['Premise'], ['Claim']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb65210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get CLS indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b726381c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019929885864257812,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 231508,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87db0e9e0684361b70385f8a8b25346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019443988800048828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 28,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5e02214fe64e3c9f8b59d53e86b75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.021754741668701172,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 466062,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2507e34ffb541e8b073f57ae56d1da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0207211971282959,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 570,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf836d0cd2bc4336b009c77b13559e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad1daa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CLS_indices(x):\n",
    "    \n",
    "    cls_indices = []\n",
    "    \n",
    "    full_paragraph = x.full_paragraph_w_cls\n",
    "    tokenized_paragraph = tokenizer.tokenize(full_paragraph)\n",
    "    components_list = x.paragraph_components_list\n",
    "    \n",
    "    for idx, token in enumerate(tokenized_paragraph):\n",
    "        \n",
    "        if token == 'start':\n",
    "            \n",
    "            cls_indices.append(idx)\n",
    "    \n",
    "    component_cls_indices = [i for j,i in enumerate(cls_indices) if j % 2 == 0]\n",
    "    features_cls_indices = [i for j,i in enumerate(cls_indices) if j % 2 == 1]\n",
    "    \n",
    "    if len(component_cls_indices) == len(components_list) + 1:\n",
    "        \n",
    "        component_cls_indices = component_cls_indices[:-1]    \n",
    "    \n",
    "    \n",
    "    return component_cls_indices, features_cls_indices     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "954a7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_CLS_indices(x):\n",
    "    \n",
    "#     cls_indices = []\n",
    "    \n",
    "#     full_paragraph = x.full_paragraph_w_cls\n",
    "#     tokenized_paragraph = tokenizer.tokenize(full_paragraph)\n",
    "    \n",
    "#     for idx, token in enumerate(tokenized_paragraph):\n",
    "        \n",
    "#         if token == '[CLS]':\n",
    "            \n",
    "#             cls_indices.append(idx)\n",
    "    \n",
    "#     component_cls_indices = [i for j,i in enumerate(cls_indices) if j % 2 == 0]\n",
    "#     features_cls_indices = [i for j,i in enumerate(cls_indices) if j % 2 == 1]\n",
    "    \n",
    "#     last_cls_idx = full_paragraph.rfind('[CLS]')\n",
    "    \n",
    "#     end_of_last_cls = last_cls_idx + 5\n",
    "    \n",
    "#     if '[CLS]' not in full_paragraph[end_of_last_cls:]:\n",
    "        \n",
    "#         component_cls_indices = component_cls_indices[:-1]\n",
    "    \n",
    "# #     if len(full_paragraph) != last_cls_idx + 4:\n",
    "        \n",
    "# #             component_cls_indices = component_cls_indices[:-1]\n",
    "            \n",
    "    \n",
    "#     return component_cls_indices, features_cls_indices     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6629d504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Start To conclude, as far as I am concerned, international tourism has both triggered economic development and maintained cultural and environment values of the tourist countries. Start 4, Yes, No, No, Yes Start In addition, the authorities should adequately support these sustainable developments.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df['full_paragraph_w_cls'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "333a6069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0], [29])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_CLS_indices(dataset_df.iloc[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37d8ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_CLS_indices(x):\n",
    "    \n",
    "#     cls_indices = []\n",
    "#     component_cls_indices = []\n",
    "    \n",
    "#     full_paragraph = x.full_paragraph_w_cls\n",
    "#     tokenized_paragraph = tokenizer.tokenize(full_paragraph)\n",
    "#     components_list = x.paragraph_components_list\n",
    "    \n",
    "#     for idx, token in enumerate(tokenized_paragraph):\n",
    "        \n",
    "#         if token == '[CLS]':\n",
    "            \n",
    "#             cls_indices.append(idx)\n",
    "            \n",
    "#     for idx_enum, cls_idx in enumerate(cls_indices):\n",
    "        \n",
    "#         if idx_enum == len(cls_indices) - 1:\n",
    "        \n",
    "#             remaining_para = full_paragraph[cls_idx:]\n",
    "\n",
    "#             for component in components_list:\n",
    "\n",
    "#                 if idx_enum % 2 == 0 and component[0] not in remaining_para:\n",
    "\n",
    "#                     component_cls_indices.append(cls_idx)\n",
    "        \n",
    "    \n",
    "#     # component_cls_indices = [i for j,i in enumerate(cls_indices) if j % 2 == 0]\n",
    "#     features_cls_indices = [i for j,i in enumerate(cls_indices) if j % 2 == 1]\n",
    "    \n",
    "#     return component_cls_indices, features_cls_indices     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68858793",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['component_cls_indices'] = dataset_df.apply(lambda x: get_CLS_indices(x)[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5be4673",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['feature_cls_indices'] = dataset_df.apply(lambda x: get_CLS_indices(x)[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24a5d39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity(x):\n",
    "    \n",
    "    return len(x.component_cls_indices) == len(x.paragraph_components_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b083d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['sanity_1'] = dataset_df.apply(lambda x: sanity(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e37935c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1717\n",
       "False       2\n",
       "Name: sanity_1, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df['sanity_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58e3f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "whatever = dataset_df[dataset_df.sanity_1 == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acb099e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>paragraph_components_list</th>\n",
       "      <th>paragraph_labels_list</th>\n",
       "      <th>paragraph_markers_list</th>\n",
       "      <th>split</th>\n",
       "      <th>essay_nr</th>\n",
       "      <th>structural_fts_as_text_combined</th>\n",
       "      <th>paragraph_labels_numeric</th>\n",
       "      <th>full_paragraph_w_cls</th>\n",
       "      <th>component_cls_indices</th>\n",
       "      <th>feature_cls_indices</th>\n",
       "      <th>sanity_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>Learning a foreign language is necessary for c...</td>\n",
       "      <td>[[It seems to me that students should start le...</td>\n",
       "      <td>[[MajorClaim], [Claim]]</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay327</td>\n",
       "      <td>[1, Yes, No, Yes, No, 1, No, Yes, Yes, No]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>Start Learning a foreign language is necessary...</td>\n",
       "      <td>[0, 26, 48, 61]</td>\n",
       "      <td>[19, 43, 51, 85]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>There is no doubt that some behaviors of the t...</td>\n",
       "      <td>[[some behaviors of the tourists are not welco...</td>\n",
       "      <td>[[Claim], [Premise], [Premise], [Premise], [Pr...</td>\n",
       "      <td>[[], [firstly], [therefore,], [so], [moreover]...</td>\n",
       "      <td>TEST</td>\n",
       "      <td>essay359</td>\n",
       "      <td>[2, Yes, No, No, No, 2, No, No, No, No, 2, No,...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>Start There is no doubt that some behaviors of...</td>\n",
       "      <td>[0, 29, 52, 90, 117, 137, 164]</td>\n",
       "      <td>[19, 42, 64, 100, 127, 154, 186]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              paragraph  \\\n",
       "1424  Learning a foreign language is necessary for c...   \n",
       "1552  There is no doubt that some behaviors of the t...   \n",
       "\n",
       "                              paragraph_components_list  \\\n",
       "1424  [[It seems to me that students should start le...   \n",
       "1552  [[some behaviors of the tourists are not welco...   \n",
       "\n",
       "                                  paragraph_labels_list  \\\n",
       "1424                            [[MajorClaim], [Claim]]   \n",
       "1552  [[Claim], [Premise], [Premise], [Premise], [Pr...   \n",
       "\n",
       "                                 paragraph_markers_list  split  essay_nr  \\\n",
       "1424                                           [[], []]  TRAIN  essay327   \n",
       "1552  [[], [firstly], [therefore,], [so], [moreover]...   TEST  essay359   \n",
       "\n",
       "                        structural_fts_as_text_combined  \\\n",
       "1424         [1, Yes, No, Yes, No, 1, No, Yes, Yes, No]   \n",
       "1552  [2, Yes, No, No, No, 2, No, No, No, No, 2, No,...   \n",
       "\n",
       "      paragraph_labels_numeric  \\\n",
       "1424                    [0, 1]   \n",
       "1552  [1, 2, 2, 2, 2, 2, 2, 2]   \n",
       "\n",
       "                                   full_paragraph_w_cls  \\\n",
       "1424  Start Learning a foreign language is necessary...   \n",
       "1552  Start There is no doubt that some behaviors of...   \n",
       "\n",
       "               component_cls_indices               feature_cls_indices  \\\n",
       "1424                 [0, 26, 48, 61]                  [19, 43, 51, 85]   \n",
       "1552  [0, 29, 52, 90, 117, 137, 164]  [19, 42, 64, 100, 127, 154, 186]   \n",
       "\n",
       "      sanity_1  \n",
       "1424     False  \n",
       "1552     False  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29aeb68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Start Learning a foreign language is necessary for children to strengthen their ability to learn. Whether children should start learning a foreign language as they start school or not might be a controversial issue. It seems to me that students should start learning that as they start school. Start 1, Yes, No, Yes, No Start Learning that not only help them to improve their minds and memories, but can extend their visions about the other countries. Start 1, No, Yes, Yes, No'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whatever['full_paragraph_w_cls'][1424]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30ca7b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['It seems to me that students should start learning that as they start school'],\n",
       " ['Learning that not only help them to improve their minds and memories, but can extend their visions about the other countries']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whatever['paragraph_components_list'][1424]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8877b312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 26, 48, 61]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whatever['component_cls_indices'][1424]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10c4039a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 43, 51, 85]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whatever['feature_cls_indices'][1424]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0afe2b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 start\n",
      "1 learning\n",
      "2 a\n",
      "3 foreign\n",
      "4 language\n",
      "5 is\n",
      "6 necessary\n",
      "7 for\n",
      "8 children\n",
      "9 to\n",
      "10 strengthen\n",
      "11 their\n",
      "12 ability\n",
      "13 to\n",
      "14 learn\n",
      "15 .\n",
      "16 whether\n",
      "17 children\n",
      "18 should\n",
      "19 start\n",
      "20 learning\n",
      "21 a\n",
      "22 foreign\n",
      "23 language\n",
      "24 as\n",
      "25 they\n",
      "26 start\n",
      "27 school\n",
      "28 or\n",
      "29 not\n",
      "30 might\n",
      "31 be\n",
      "32 a\n",
      "33 controversial\n",
      "34 issue\n",
      "35 .\n",
      "36 it\n",
      "37 seems\n",
      "38 to\n",
      "39 me\n",
      "40 that\n",
      "41 students\n",
      "42 should\n",
      "43 start\n",
      "44 learning\n",
      "45 that\n",
      "46 as\n",
      "47 they\n",
      "48 start\n",
      "49 school\n",
      "50 .\n",
      "51 start\n",
      "52 1\n",
      "53 ,\n",
      "54 yes\n",
      "55 ,\n",
      "56 no\n",
      "57 ,\n",
      "58 yes\n",
      "59 ,\n",
      "60 no\n",
      "61 start\n",
      "62 learning\n",
      "63 that\n",
      "64 not\n",
      "65 only\n",
      "66 help\n",
      "67 them\n",
      "68 to\n",
      "69 improve\n",
      "70 their\n",
      "71 minds\n",
      "72 and\n",
      "73 memories\n",
      "74 ,\n",
      "75 but\n",
      "76 can\n",
      "77 extend\n",
      "78 their\n",
      "79 visions\n",
      "80 about\n",
      "81 the\n",
      "82 other\n",
      "83 countries\n",
      "84 .\n",
      "85 start\n",
      "86 1\n",
      "87 ,\n",
      "88 no\n",
      "89 ,\n",
      "90 yes\n",
      "91 ,\n",
      "92 yes\n",
      "93 ,\n",
      "94 no\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(tokenizer.tokenize(whatever['full_paragraph_w_cls'][1424])):\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b7b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df91e13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99235e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e042b57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e727b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = dataset_df['full_paragraph_w_cls'][1564]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "580f902c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['their unresponsiveness can be attributed to their attitude towards life'],\n",
       " ['that they are aware of their deteriorating health and lack of enthusiasm comes with their taste for monotony and safe ideology'],\n",
       " [\"This, by all means, is outweigh by youngsters' adventurousness and bravery\"],\n",
       " ['Blatantly seen, success of most companies stems from young people, whose enterprising ideas that catch up with the world is regarded as wind of refreshment']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df['paragraph_components_list'][1564]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86f0a386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 57, 87, 132]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df['feature_cls_indices'][1564]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbdbd5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Start Secondly, their unresponsiveness can be attributed to their attitude towards life. Start 3, Yes, No, No, No Start In other words, that they are aware of their deteriorating health and lack of enthusiasm comes with their taste for monotony and safe ideology. Start 3, No, No, No, No Start This, by all means, is outweigh by youngsters' adventurousness and bravery. Start 3, No, No, No, No Start Blatantly seen, success of most companies stems from young people, whose enterprising ideas that catch up with the world is regarded as wind of refreshment. Start 3, No, Yes, No, No\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1e7f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 start\n",
      "1 secondly\n",
      "2 ,\n",
      "3 their\n",
      "4 un\n",
      "5 ##res\n",
      "6 ##pon\n",
      "7 ##sive\n",
      "8 ##ness\n",
      "9 can\n",
      "10 be\n",
      "11 attributed\n",
      "12 to\n",
      "13 their\n",
      "14 attitude\n",
      "15 towards\n",
      "16 life\n",
      "17 .\n",
      "18 start\n",
      "19 3\n",
      "20 ,\n",
      "21 yes\n",
      "22 ,\n",
      "23 no\n",
      "24 ,\n",
      "25 no\n",
      "26 ,\n",
      "27 no\n",
      "28 start\n",
      "29 in\n",
      "30 other\n",
      "31 words\n",
      "32 ,\n",
      "33 that\n",
      "34 they\n",
      "35 are\n",
      "36 aware\n",
      "37 of\n",
      "38 their\n",
      "39 deteriorating\n",
      "40 health\n",
      "41 and\n",
      "42 lack\n",
      "43 of\n",
      "44 enthusiasm\n",
      "45 comes\n",
      "46 with\n",
      "47 their\n",
      "48 taste\n",
      "49 for\n",
      "50 mono\n",
      "51 ##ton\n",
      "52 ##y\n",
      "53 and\n",
      "54 safe\n",
      "55 ideology\n",
      "56 .\n",
      "57 start\n",
      "58 3\n",
      "59 ,\n",
      "60 no\n",
      "61 ,\n",
      "62 no\n",
      "63 ,\n",
      "64 no\n",
      "65 ,\n",
      "66 no\n",
      "67 start\n",
      "68 this\n",
      "69 ,\n",
      "70 by\n",
      "71 all\n",
      "72 means\n",
      "73 ,\n",
      "74 is\n",
      "75 out\n",
      "76 ##weig\n",
      "77 ##h\n",
      "78 by\n",
      "79 young\n",
      "80 ##sters\n",
      "81 '\n",
      "82 adventurous\n",
      "83 ##ness\n",
      "84 and\n",
      "85 bravery\n",
      "86 .\n",
      "87 start\n",
      "88 3\n",
      "89 ,\n",
      "90 no\n",
      "91 ,\n",
      "92 no\n",
      "93 ,\n",
      "94 no\n",
      "95 ,\n",
      "96 no\n",
      "97 start\n",
      "98 b\n",
      "99 ##lat\n",
      "100 ##antly\n",
      "101 seen\n",
      "102 ,\n",
      "103 success\n",
      "104 of\n",
      "105 most\n",
      "106 companies\n",
      "107 stems\n",
      "108 from\n",
      "109 young\n",
      "110 people\n",
      "111 ,\n",
      "112 whose\n",
      "113 enter\n",
      "114 ##pr\n",
      "115 ##ising\n",
      "116 ideas\n",
      "117 that\n",
      "118 catch\n",
      "119 up\n",
      "120 with\n",
      "121 the\n",
      "122 world\n",
      "123 is\n",
      "124 regarded\n",
      "125 as\n",
      "126 wind\n",
      "127 of\n",
      "128 ref\n",
      "129 ##resh\n",
      "130 ##ment\n",
      "131 .\n",
      "132 start\n",
      "133 3\n",
      "134 ,\n",
      "135 no\n",
      "136 ,\n",
      "137 yes\n",
      "138 ,\n",
      "139 no\n",
      "140 ,\n",
      "141 no\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(tokenizer.tokenize(z)):\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ff9dbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['it is easy to realize that languages, especially oral language, are a quite major part of culture of a country'],\n",
       " ['It helps people distinguish between nations and even regions in a country'],\n",
       " ['The clearance of minority of language means that a national traditional, customs and habitants do not exist'],\n",
       " ['Governments should spend money on keeping and preserving these things for the rich diversity of cultures which make our world more interesting'],\n",
       " ['it is a pride of the country with a rage of culture which is easy to educate people to love their country more']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df['paragraph_components_list'][311]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46044777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6966b1a0",
   "metadata": {},
   "source": [
    "## Spans Computation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c651c4a9",
   "metadata": {},
   "source": [
    "def get_spans(list_texts, paragraph_tokenized):\n",
    "    \n",
    "    spans = []        \n",
    "                \n",
    "    for text in list_texts:  \n",
    "\n",
    "        text_tokenized = tokenizer.tokenize(text)\n",
    "                                            \n",
    "        \n",
    "        for i in range(len(paragraph_tokenized)):\n",
    "            \n",
    "            span = (i, i+len(text_tokenized)-1)\n",
    "            \n",
    "            if paragraph_tokenized[span[0]:span[1]+1] == text_tokenized and span not in spans:\n",
    "                \n",
    "                spans.append(span)    \n",
    "                 \n",
    "    return spans"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b44aa5e",
   "metadata": {},
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2814181",
   "metadata": {},
   "source": [
    "def build_spans(x):\n",
    "    \n",
    "    paragraph = x.full_paragraph\n",
    "    paragraph_tokenized = tokenizer.tokenize(paragraph)\n",
    "    \n",
    "    ac_list = x.paragraph_components_list\n",
    "    fts_list = x.structural_fts_as_text_combined\n",
    "    am_list = x.paragraph_markers_list\n",
    "    \n",
    "    ac_spans = get_spans(flatten_list(ac_list), paragraph_tokenized)\n",
    "    fts_spans = get_spans(fts_list, paragraph_tokenized)\n",
    "    am_spans = get_spans(flatten_list(am_list), paragraph_tokenized)\n",
    "    \n",
    "    return ac_spans, fts_spans, am_spans"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4d9c6b8",
   "metadata": {},
   "source": [
    "dataset_df['ac_spans'] = dataset_df.apply(lambda x: build_spans(x)[0], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f93536bb",
   "metadata": {},
   "source": [
    "dataset_df['fts_spans'] = dataset_df.apply(lambda x: build_spans(x)[1], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a66031e",
   "metadata": {},
   "source": [
    "dataset_df['am_spans'] = dataset_df.apply(lambda x: build_spans(x)[2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86b4f77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>paragraph_components_list</th>\n",
       "      <th>paragraph_labels_list</th>\n",
       "      <th>paragraph_markers_list</th>\n",
       "      <th>split</th>\n",
       "      <th>essay_nr</th>\n",
       "      <th>structural_fts_as_text_combined</th>\n",
       "      <th>paragraph_labels_numeric</th>\n",
       "      <th>full_paragraph_w_cls</th>\n",
       "      <th>component_cls_indices</th>\n",
       "      <th>feature_cls_indices</th>\n",
       "      <th>sanity_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It is always said that competition can effecti...</td>\n",
       "      <td>[[we should attach more importance to cooperat...</td>\n",
       "      <td>[[MajorClaim]]</td>\n",
       "      <td>[[from this point of view]]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay001</td>\n",
       "      <td>[1, Yes, Yes, Yes, No]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>Start It is always said that competition can e...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First of all, through cooperation, children ca...</td>\n",
       "      <td>[[through cooperation, children can learn abou...</td>\n",
       "      <td>[[Claim], [Premise], [Premise], [Premise]]</td>\n",
       "      <td>[[first of all], [], [], []]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay001</td>\n",
       "      <td>[2, Yes, No, No, No, 2, No, No, No, No, 2, No,...</td>\n",
       "      <td>[1, 2, 2, 2]</td>\n",
       "      <td>Start First of all, through cooperation, child...</td>\n",
       "      <td>[0, 36, 75, 129]</td>\n",
       "      <td>[26, 65, 119, 152]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On the other hand, the significance of competi...</td>\n",
       "      <td>[[the significance of competition is that how ...</td>\n",
       "      <td>[[Premise], [Claim], [Premise], [Premise], [Cl...</td>\n",
       "      <td>[[on the other hand], [hence], [however], [], []]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay001</td>\n",
       "      <td>[3, Yes, No, No, No, 3, No, No, No, No, 3, No,...</td>\n",
       "      <td>[2, 1, 2, 2, 1]</td>\n",
       "      <td>Start On the other hand, the significance of c...</td>\n",
       "      <td>[0, 32, 56, 91, 177]</td>\n",
       "      <td>[22, 46, 81, 167, 205]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consequently, no matter from the view of indiv...</td>\n",
       "      <td>[[a more cooperative attitudes towards life is...</td>\n",
       "      <td>[[MajorClaim]]</td>\n",
       "      <td>[[consequently]]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay001</td>\n",
       "      <td>[4, Yes, Yes, No, Yes]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>Start Consequently, no matter from the view of...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The last 50 years have seen an increasing numb...</td>\n",
       "      <td>[[they are able to sustain their cultural iden...</td>\n",
       "      <td>[[MajorClaim]]</td>\n",
       "      <td>[[however]]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay002</td>\n",
       "      <td>[1, Yes, Yes, Yes, No]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>Start The last 50 years have seen an increasin...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[78]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>In conclusion, fatherhood should be as present...</td>\n",
       "      <td>[[fatherhood should be as present as motherhoo...</td>\n",
       "      <td>[[MajorClaim]]</td>\n",
       "      <td>[[in conclusion]]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay401</td>\n",
       "      <td>[4, Yes, Yes, No, Yes]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>Start In conclusion, fatherhood should be as p...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[36]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>Some people believe that studying hard is esse...</td>\n",
       "      <td>[[both of studying hard and playing sports are...</td>\n",
       "      <td>[[MajorClaim]]</td>\n",
       "      <td>[[in my point of view]]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay402</td>\n",
       "      <td>[1, Yes, Yes, Yes, No]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>Start Some people believe that studying hard i...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[45]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>On the other hand, studying hard will give chi...</td>\n",
       "      <td>[[studying hard will give children a better fu...</td>\n",
       "      <td>[[Claim], [Premise], [Premise], [Premise], [Pr...</td>\n",
       "      <td>[[on the other hand], [], [for instance], [], []]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay402</td>\n",
       "      <td>[2, Yes, No, No, No, 2, No, No, No, No, 2, No,...</td>\n",
       "      <td>[1, 2, 2, 2, 2]</td>\n",
       "      <td>Start On the other hand, studying hard will gi...</td>\n",
       "      <td>[0, 25, 51, 110, 137]</td>\n",
       "      <td>[15, 41, 100, 127, 154]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>At the same time, playing sports will give goo...</td>\n",
       "      <td>[[playing sports will give good effects on chi...</td>\n",
       "      <td>[[Claim], [Premise], [Premise], [Premise], [Pr...</td>\n",
       "      <td>[[], [], [firstly], [], [because], [], [so], [...</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay402</td>\n",
       "      <td>[3, Yes, No, No, No, 3, No, No, No, No, 3, No,...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>Start At the same time, playing sports will gi...</td>\n",
       "      <td>[0, 25, 63, 99, 117, 143, 163, 182]</td>\n",
       "      <td>[15, 53, 89, 107, 133, 153, 172, 200]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>In conclusion, both studying hard at school an...</td>\n",
       "      <td>[[both studying hard at school and playing spo...</td>\n",
       "      <td>[[MajorClaim]]</td>\n",
       "      <td>[[in conclusion]]</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>essay402</td>\n",
       "      <td>[4, Yes, Yes, No, Yes]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>Start In conclusion, both studying hard at sch...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[19]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1719 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              paragraph  \\\n",
       "0     It is always said that competition can effecti...   \n",
       "1     First of all, through cooperation, children ca...   \n",
       "2     On the other hand, the significance of competi...   \n",
       "3     Consequently, no matter from the view of indiv...   \n",
       "4     The last 50 years have seen an increasing numb...   \n",
       "...                                                 ...   \n",
       "1714  In conclusion, fatherhood should be as present...   \n",
       "1715  Some people believe that studying hard is esse...   \n",
       "1716  On the other hand, studying hard will give chi...   \n",
       "1717  At the same time, playing sports will give goo...   \n",
       "1718  In conclusion, both studying hard at school an...   \n",
       "\n",
       "                              paragraph_components_list  \\\n",
       "0     [[we should attach more importance to cooperat...   \n",
       "1     [[through cooperation, children can learn abou...   \n",
       "2     [[the significance of competition is that how ...   \n",
       "3     [[a more cooperative attitudes towards life is...   \n",
       "4     [[they are able to sustain their cultural iden...   \n",
       "...                                                 ...   \n",
       "1714  [[fatherhood should be as present as motherhoo...   \n",
       "1715  [[both of studying hard and playing sports are...   \n",
       "1716  [[studying hard will give children a better fu...   \n",
       "1717  [[playing sports will give good effects on chi...   \n",
       "1718  [[both studying hard at school and playing spo...   \n",
       "\n",
       "                                  paragraph_labels_list  \\\n",
       "0                                        [[MajorClaim]]   \n",
       "1            [[Claim], [Premise], [Premise], [Premise]]   \n",
       "2     [[Premise], [Claim], [Premise], [Premise], [Cl...   \n",
       "3                                        [[MajorClaim]]   \n",
       "4                                        [[MajorClaim]]   \n",
       "...                                                 ...   \n",
       "1714                                     [[MajorClaim]]   \n",
       "1715                                     [[MajorClaim]]   \n",
       "1716  [[Claim], [Premise], [Premise], [Premise], [Pr...   \n",
       "1717  [[Claim], [Premise], [Premise], [Premise], [Pr...   \n",
       "1718                                     [[MajorClaim]]   \n",
       "\n",
       "                                 paragraph_markers_list  split  essay_nr  \\\n",
       "0                           [[from this point of view]]  TRAIN  essay001   \n",
       "1                          [[first of all], [], [], []]  TRAIN  essay001   \n",
       "2     [[on the other hand], [hence], [however], [], []]  TRAIN  essay001   \n",
       "3                                      [[consequently]]  TRAIN  essay001   \n",
       "4                                           [[however]]  TRAIN  essay002   \n",
       "...                                                 ...    ...       ...   \n",
       "1714                                  [[in conclusion]]  TRAIN  essay401   \n",
       "1715                            [[in my point of view]]  TRAIN  essay402   \n",
       "1716  [[on the other hand], [], [for instance], [], []]  TRAIN  essay402   \n",
       "1717  [[], [], [firstly], [], [because], [], [so], [...  TRAIN  essay402   \n",
       "1718                                  [[in conclusion]]  TRAIN  essay402   \n",
       "\n",
       "                        structural_fts_as_text_combined  \\\n",
       "0                                [1, Yes, Yes, Yes, No]   \n",
       "1     [2, Yes, No, No, No, 2, No, No, No, No, 2, No,...   \n",
       "2     [3, Yes, No, No, No, 3, No, No, No, No, 3, No,...   \n",
       "3                                [4, Yes, Yes, No, Yes]   \n",
       "4                                [1, Yes, Yes, Yes, No]   \n",
       "...                                                 ...   \n",
       "1714                             [4, Yes, Yes, No, Yes]   \n",
       "1715                             [1, Yes, Yes, Yes, No]   \n",
       "1716  [2, Yes, No, No, No, 2, No, No, No, No, 2, No,...   \n",
       "1717  [3, Yes, No, No, No, 3, No, No, No, No, 3, No,...   \n",
       "1718                             [4, Yes, Yes, No, Yes]   \n",
       "\n",
       "      paragraph_labels_numeric  \\\n",
       "0                          [0]   \n",
       "1                 [1, 2, 2, 2]   \n",
       "2              [2, 1, 2, 2, 1]   \n",
       "3                          [0]   \n",
       "4                          [0]   \n",
       "...                        ...   \n",
       "1714                       [0]   \n",
       "1715                       [0]   \n",
       "1716           [1, 2, 2, 2, 2]   \n",
       "1717  [1, 2, 2, 2, 2, 2, 2, 2]   \n",
       "1718                       [0]   \n",
       "\n",
       "                                   full_paragraph_w_cls  \\\n",
       "0     Start It is always said that competition can e...   \n",
       "1     Start First of all, through cooperation, child...   \n",
       "2     Start On the other hand, the significance of c...   \n",
       "3     Start Consequently, no matter from the view of...   \n",
       "4     Start The last 50 years have seen an increasin...   \n",
       "...                                                 ...   \n",
       "1714  Start In conclusion, fatherhood should be as p...   \n",
       "1715  Start Some people believe that studying hard i...   \n",
       "1716  Start On the other hand, studying hard will gi...   \n",
       "1717  Start At the same time, playing sports will gi...   \n",
       "1718  Start In conclusion, both studying hard at sch...   \n",
       "\n",
       "                    component_cls_indices  \\\n",
       "0                                     [0]   \n",
       "1                        [0, 36, 75, 129]   \n",
       "2                    [0, 32, 56, 91, 177]   \n",
       "3                                     [0]   \n",
       "4                                     [0]   \n",
       "...                                   ...   \n",
       "1714                                  [0]   \n",
       "1715                                  [0]   \n",
       "1716                [0, 25, 51, 110, 137]   \n",
       "1717  [0, 25, 63, 99, 117, 143, 163, 182]   \n",
       "1718                                  [0]   \n",
       "\n",
       "                        feature_cls_indices  sanity_1  \n",
       "0                                      [99]      True  \n",
       "1                        [26, 65, 119, 152]      True  \n",
       "2                    [22, 46, 81, 167, 205]      True  \n",
       "3                                      [40]      True  \n",
       "4                                      [78]      True  \n",
       "...                                     ...       ...  \n",
       "1714                                   [36]      True  \n",
       "1715                                   [45]      True  \n",
       "1716                [15, 41, 100, 127, 154]      True  \n",
       "1717  [15, 53, 89, 107, 133, 153, 172, 200]      True  \n",
       "1718                                   [19]      True  \n",
       "\n",
       "[1719 rows x 12 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9578759a",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa5ccb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dataset_df[dataset_df.split=='TRAIN'].reset_index(drop=True)\n",
    "test_df = dataset_df[dataset_df.split=='TEST'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "614df326",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset.from_pandas(train_df)\n",
    "dataset_test = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16d1ba5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'generator'=Generator(PCG64) of the transform datasets.arrow_dataset.Dataset.train_test_split couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "train_val_datasets = dataset_train.train_test_split(train_size=0.8)\n",
    "dataset_train = train_val_datasets['train']\n",
    "dataset_val = train_val_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bccc15b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\"train\": dataset_train, \"test\": dataset_test, \"validation\": dataset_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c74f81b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['paragraph', 'paragraph_components_list', 'paragraph_labels_list', 'paragraph_markers_list', 'split', 'essay_nr', 'structural_fts_as_text_combined', 'paragraph_labels_numeric', 'full_paragraph_w_cls', 'component_cls_indices', 'feature_cls_indices', 'sanity_1'],\n",
       "        num_rows: 1088\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['paragraph', 'paragraph_components_list', 'paragraph_labels_list', 'paragraph_markers_list', 'split', 'essay_nr', 'structural_fts_as_text_combined', 'paragraph_labels_numeric', 'full_paragraph_w_cls', 'component_cls_indices', 'feature_cls_indices', 'sanity_1'],\n",
       "        num_rows: 358\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['paragraph', 'paragraph_components_list', 'paragraph_labels_list', 'paragraph_markers_list', 'split', 'essay_nr', 'structural_fts_as_text_combined', 'paragraph_labels_numeric', 'full_paragraph_w_cls', 'component_cls_indices', 'feature_cls_indices', 'sanity_1'],\n",
       "        num_rows: 273\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d70be633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(dataset, os.path.join(\"/notebooks/KURI-BERT/notebooks/full_formula_w_fts/CLS_work\", 'pe_dataset_for_cls_implementation.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e291f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset, os.path.join(\"/notebooks/KURI-BERT/notebooks/full_formula_w_fts/CLS_work\", 'pe_dataset_for_start_implementation.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6812bef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf3f0858",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check Area. Or maybe Poland area hehehe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd9935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "a9410dbe",
   "metadata": {},
   "source": [
    "build_spans(dataset_df.iloc[1689])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05f2bff7",
   "metadata": {},
   "source": [
    "dataset_df['full_paragraph'][1689]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b917ecd",
   "metadata": {},
   "source": [
    "dataset_df['paragraph_components_list'][1689]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31bb441e",
   "metadata": {},
   "source": [
    "dataset_df['paragraph_markers_list'][1689]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d54e5586",
   "metadata": {},
   "source": [
    "for i,x in enumerate(tokenizer.tokenize(dataset_df['full_paragraph'][1689])):\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dce65670",
   "metadata": {},
   "source": [
    "whatever = dataset_df[dataset_df.full_paragraph.str.contains('Firstly, by paying taxes')]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7517e9b7",
   "metadata": {},
   "source": [
    "whatever"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac811655",
   "metadata": {},
   "source": [
    "build_spans(dataset_df.iloc[633])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2021f696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f542f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
