{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82db334c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.22.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2021.10.8)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.9.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.28.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.3)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (58.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: IProgress in /opt/conda/lib/python3.8/site-packages (0.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from IProgress) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install ipywidgets\n",
    "!pip install IProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80f0f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import BertModel, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01af1cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01995086669921875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 213450,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9266994b38844e9817be78f3b16bf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01605224609375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 29,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e7759899554972bc2e5ecd02d827af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014772415161132812,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 570,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8785d8ba77450b94df17cf18ca268b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97130ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = BertModel(BertConfig.from_pretrained(\"bert-base-cased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194510f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2251848",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"hello i have a dog. he is very cute.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0af98d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer(sentence, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac744a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 19082,   178,  1138,   170,  3676,   119,  1119,  1110,  1304,\n",
       "         10509,   119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68611bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_1(**tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ab0628a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3602, -1.3389,  1.1931,  ...,  0.2236, -1.7147, -1.3741],\n",
       "         [ 0.7821,  0.2950,  0.5227,  ...,  0.4816, -0.9162, -2.0736],\n",
       "         [-0.3923, -0.9394,  0.1356,  ...,  0.4492, -0.8880, -1.0429],\n",
       "         ...,\n",
       "         [ 0.4152, -1.4623, -0.6928,  ..., -0.9786, -0.8022, -1.2154],\n",
       "         [-0.3496,  0.8795,  1.6792,  ..., -0.0402,  0.0855, -1.8874],\n",
       "         [-1.5621, -0.5006,  0.0178,  ...,  0.0769, -0.4841,  0.3441]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c20f9bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = BertModel(BertConfig.from_pretrained(\"bert-base-cased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bee35b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2.embeddings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75d82e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_output = model_2(inputs_embeds = output[0], output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72c76a4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[[-4.2907e-01, -1.4784e+00,  1.3295e+00,  ...,  2.6151e-01,\n",
      "          -1.9028e+00, -1.5021e+00],\n",
      "         [ 8.4310e-01,  3.5564e-01,  6.3877e-01,  ...,  5.3007e-01,\n",
      "          -1.0241e+00, -2.2756e+00],\n",
      "         [-4.9958e-01, -1.0124e+00,  0.0000e+00,  ...,  5.0764e-01,\n",
      "          -1.0371e+00, -1.1344e+00],\n",
      "         ...,\n",
      "         [ 4.1460e-01, -1.6007e+00, -7.5625e-01,  ..., -1.1261e+00,\n",
      "          -9.1613e-01, -1.3396e+00],\n",
      "         [-4.2398e-01,  9.4550e-01,  0.0000e+00,  ..., -6.8783e-04,\n",
      "           8.9982e-02, -2.0466e+00],\n",
      "         [-1.8043e+00, -5.1347e-01,  1.2788e-02,  ...,  8.1797e-02,\n",
      "          -5.6647e-01,  0.0000e+00]]], grad_fn=<NativeDropoutBackward0>)\n",
      "1 tensor([[[ 0.0263, -0.9214,  0.6803,  ...,  0.4045, -2.0153, -1.4979],\n",
      "         [ 0.9588,  0.7348,  1.0257,  ...,  0.6752, -0.8185, -2.0210],\n",
      "         [-0.3627, -0.7736,  0.1394,  ...,  0.6587, -0.8323, -1.1381],\n",
      "         ...,\n",
      "         [ 0.6147, -0.3676, -0.4106,  ..., -0.9130, -0.8116, -1.2512],\n",
      "         [-0.2526,  1.1204, -0.0131,  ...,  0.5993,  0.1271, -1.7204],\n",
      "         [-1.5486,  0.0124, -0.0560,  ..., -0.0588,  0.0219, -0.3029]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "2 tensor([[[-0.3401, -0.5759,  1.0830,  ...,  0.7085, -0.4946, -0.7584],\n",
      "         [ 0.4302,  0.4996,  1.2773,  ...,  0.6143,  0.0747, -1.1314],\n",
      "         [-0.1238, -0.7214,  0.9797,  ...,  0.6153,  0.2452, -0.9635],\n",
      "         ...,\n",
      "         [ 0.6790,  0.0209,  0.1596,  ..., -1.0944, -0.0469, -0.8107],\n",
      "         [-0.0562,  1.2909,  0.3049,  ...,  0.8275,  0.8954, -1.1665],\n",
      "         [-1.2156,  0.5907,  0.7566,  ..., -0.2660,  0.6737, -0.0483]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "3 tensor([[[-0.6518, -0.7499,  1.1811,  ...,  0.3698, -0.6107, -0.6726],\n",
      "         [-0.5132,  0.1139,  1.0079,  ..., -0.0308, -0.4505, -1.8515],\n",
      "         [ 0.0085, -0.7828,  0.7547,  ...,  0.3604,  0.3767, -1.6391],\n",
      "         ...,\n",
      "         [ 0.0276, -0.5757,  0.0563,  ..., -2.0545, -0.7078, -1.1022],\n",
      "         [-1.1780,  0.9162,  0.4601,  ...,  0.3086,  0.1117, -2.2005],\n",
      "         [-1.8499,  0.4245,  0.9298,  ..., -0.5130,  0.7869, -0.8506]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "4 tensor([[[-0.0778, -0.8642,  0.9030,  ...,  0.5004, -0.6693, -0.2833],\n",
      "         [-0.2625,  0.2803,  0.9435,  ..., -0.4538, -0.1458, -2.1673],\n",
      "         [ 0.2895, -0.7887,  0.8017,  ...,  0.3001,  0.7672, -1.7589],\n",
      "         ...,\n",
      "         [ 0.8225, -0.4171,  0.3267,  ..., -1.6673, -1.1857, -0.1400],\n",
      "         [-0.6948,  0.4160,  0.3955,  ...,  0.4457,  0.1745, -2.0505],\n",
      "         [-1.3134,  0.0736,  1.0406,  ..., -0.4340,  0.7590, -0.7713]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "5 tensor([[[ 1.9050e-01, -7.5807e-01, -2.7959e-01,  ...,  1.7839e+00,\n",
      "          -3.9540e-01, -6.8424e-01],\n",
      "         [-1.1076e-01,  5.2971e-01,  1.5081e-03,  ...,  5.5915e-01,\n",
      "           1.6522e-01, -2.7158e+00],\n",
      "         [ 3.4471e-01, -7.9695e-01,  3.0775e-01,  ...,  1.2939e+00,\n",
      "           9.2929e-01, -1.6214e+00],\n",
      "         ...,\n",
      "         [ 8.6685e-01, -4.5920e-01, -4.4511e-02,  ..., -3.3184e-01,\n",
      "          -7.3937e-01, -6.8691e-01],\n",
      "         [-5.4678e-01,  2.6458e-01,  1.2000e-01,  ...,  1.3322e+00,\n",
      "           8.0492e-01, -3.0992e+00],\n",
      "         [-7.8289e-01,  4.1445e-01,  2.7061e-02,  ...,  7.6955e-01,\n",
      "           6.9841e-01, -1.8919e+00]]], grad_fn=<NativeLayerNormBackward0>)\n",
      "6 tensor([[[-0.6068, -0.5290,  0.4823,  ...,  2.1230,  0.0583, -0.9685],\n",
      "         [-0.2571, -0.0168,  0.4826,  ...,  0.8163,  0.5779, -2.2928],\n",
      "         [-0.2026, -1.0069,  1.0529,  ...,  1.1481,  1.3624, -1.3006],\n",
      "         ...,\n",
      "         [ 0.2072, -0.4513,  0.1930,  ..., -0.1546, -0.4809, -0.4559],\n",
      "         [-1.3198,  0.1117,  1.0799,  ...,  1.2506,  1.2501, -2.4675],\n",
      "         [-0.8624,  0.5853,  0.4166,  ...,  0.4754,  0.8612, -1.4415]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "7 tensor([[[-0.9343, -0.1008,  0.6079,  ...,  2.6297,  0.1025, -0.3295],\n",
      "         [-0.4541,  0.2631,  0.3849,  ...,  1.0449,  0.9454, -1.1876],\n",
      "         [-0.3724, -0.5293,  1.0496,  ...,  1.4561,  1.5169, -0.3897],\n",
      "         ...,\n",
      "         [ 0.0080, -0.1100,  0.3426,  ...,  0.2933, -0.4084, -0.4198],\n",
      "         [-1.3113,  0.5938,  1.1132,  ...,  1.1369,  1.9270, -1.4962],\n",
      "         [-1.2202,  0.5695,  0.5385,  ...,  0.9969,  1.0322, -0.8316]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "8 tensor([[[-0.9806, -0.8851,  0.8975,  ...,  2.8085, -0.6244, -0.2089],\n",
      "         [-0.6136, -0.6502,  0.3270,  ...,  1.4394,  0.3901, -0.5450],\n",
      "         [-1.0896, -0.7298,  1.7607,  ...,  1.6040,  0.4717, -0.1971],\n",
      "         ...,\n",
      "         [-0.4464, -0.3508,  0.2396,  ...,  0.6442, -1.1021, -0.0053],\n",
      "         [-1.6728, -0.0779,  1.0027,  ...,  1.4311,  1.1416, -0.9169],\n",
      "         [-1.5197,  0.0758,  0.6203,  ...,  1.7903,  0.2246, -0.6237]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "9 tensor([[[-1.3206, -1.1086,  1.7084,  ...,  2.4432,  0.1448, -0.0994],\n",
      "         [-0.9106, -0.6441,  1.0472,  ...,  0.8360,  0.6292, -0.6740],\n",
      "         [-1.8246, -0.9623,  1.9519,  ...,  1.1665,  0.4354, -0.2179],\n",
      "         ...,\n",
      "         [-0.7139, -0.3053,  0.4081,  ..., -0.0064, -0.4197,  0.2631],\n",
      "         [-2.2101,  0.0398,  1.8069,  ...,  1.0971,  1.3896, -0.8254],\n",
      "         [-1.5514, -0.0679,  1.4793,  ...,  1.3573,  0.7344, -0.2039]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "10 tensor([[[-1.7937, -0.4400,  1.5969,  ...,  2.0027,  0.3402, -0.2398],\n",
      "         [-0.8620, -0.4075,  1.0605,  ...,  0.5563,  0.8938, -0.9571],\n",
      "         [-1.9243, -1.0303,  1.9287,  ...,  1.0185,  0.3261,  0.1714],\n",
      "         ...,\n",
      "         [-0.9924,  0.1133,  0.7864,  ..., -0.3457,  0.3500,  0.3104],\n",
      "         [-2.0344,  0.5403,  2.0468,  ...,  0.9161,  1.8348, -0.7928],\n",
      "         [-1.7357, -0.1366,  1.5461,  ...,  0.7626,  0.8673,  0.0915]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "11 tensor([[[-2.0557, -0.7527,  1.7000,  ...,  2.2495, -0.0348, -0.0379],\n",
      "         [-0.8381, -0.3342,  1.7399,  ..., -0.0349,  0.5534, -0.7976],\n",
      "         [-2.1834, -1.1683,  2.0886,  ...,  1.0954, -0.2962,  0.1964],\n",
      "         ...,\n",
      "         [-1.3686,  0.0855,  0.5029,  ...,  0.2060, -0.0959,  0.4396],\n",
      "         [-2.1490,  0.0035,  2.2008,  ...,  1.3317,  0.8218, -0.5445],\n",
      "         [-1.7818, -0.1488,  1.9300,  ...,  0.8423,  0.0968,  0.1344]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "12 tensor([[[-1.5057, -0.5740,  1.2075,  ...,  3.0663, -0.2801,  0.4090],\n",
      "         [-0.3003,  0.0585,  1.6438,  ..., -0.0398,  0.4243, -0.5309],\n",
      "         [-1.6502, -0.2776,  2.2829,  ...,  1.7242, -0.0641,  0.7147],\n",
      "         ...,\n",
      "         [-1.0888,  0.1984,  0.4000,  ...,  0.8368, -0.3946,  0.3364],\n",
      "         [-1.4537,  0.3683,  2.0731,  ...,  1.8918,  0.6107, -0.5099],\n",
      "         [-0.6529,  0.3753,  1.5920,  ...,  1.0674, -0.2008, -0.2885]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for x, y in enumerate(new_output[2]):\n",
    "    \n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa058f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47aebee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db852f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cbc1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f08b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac26d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6ba0fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBERTKuri(nn.Module):\n",
    "\n",
    "    def __init__(self, model_am, model_ac, model_combined, nr_classes):\n",
    "        \n",
    "        super(CustomBERTKuri, self).__init__()\n",
    "        \n",
    "        self.model_am = model_am\n",
    "        self.model_ac = model_ac\n",
    "        self.model_combined = model_combined\n",
    "        self.nr_classes = nr_classes\n",
    "                \n",
    "        self.fc = nn.Linear(model_combined.config.hidden_size, self.nr_classes)\n",
    "\n",
    "    def forward(self, tokenized_input):\n",
    "        \n",
    "        output = model_am(**tokenized_input)\n",
    "        \n",
    "        print(output[0].shape)\n",
    "        \n",
    "        output = model_combined(inputs_embeds = output[0])\n",
    "        \n",
    "        # output = self.fc(output[0])\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ca1065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a1bce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c74718ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"hello i have a dog. he is very cute.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3e93f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer(sentence, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e18af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f404430",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_am = BertModel(BertConfig.from_pretrained(\"bert-base-cased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7ee7684",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combined = BertModel(BertConfig.from_pretrained(\"bert-base-cased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45b2a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = CustomBERTKuri(model_am, model_am, model_combined, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cae51822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13, 768])\n"
     ]
    }
   ],
   "source": [
    "our_output = custom_model(tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "800fc934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.3080,  0.2992, -1.3239,  ..., -0.5256,  0.7774, -0.1664],\n",
       "         [-0.0837,  1.5324, -1.3424,  ..., -1.0329,  2.1938,  0.5698],\n",
       "         [ 0.6013,  1.8860, -0.0583,  ..., -0.0961,  2.4640,  0.6399],\n",
       "         ...,\n",
       "         [ 0.1444,  1.3482, -0.9161,  ..., -0.8573,  0.8058,  1.1466],\n",
       "         [-0.1071,  1.9615, -0.6014,  ...,  0.0418,  1.4875,  0.3819],\n",
       "         [-0.7959,  1.1424, -0.2364,  ..., -0.7716,  1.6743,  0.6361]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-3.8542e-01,  5.8907e-01,  4.7898e-01, -4.1342e-01,  3.3790e-01,\n",
       "         -1.9238e-01, -6.9722e-01,  3.1175e-01,  6.5693e-01,  1.6746e-01,\n",
       "         -6.3393e-01, -7.6122e-01,  6.4258e-01, -1.1263e-01,  1.0532e-02,\n",
       "         -3.6647e-01, -2.1205e-01,  2.5337e-01,  6.8979e-01,  1.0673e-01,\n",
       "          4.5056e-01,  7.6722e-02,  1.0427e-01, -6.5043e-01, -5.8818e-01,\n",
       "          1.8471e-01,  9.4738e-02,  5.3706e-01,  2.2777e-01, -5.3179e-01,\n",
       "          3.9168e-01, -3.9948e-01,  6.3998e-03, -5.8467e-02,  6.6622e-01,\n",
       "          1.9061e-01,  4.8809e-01, -5.3353e-01,  3.5000e-01,  3.3853e-01,\n",
       "          1.7660e-01, -3.3062e-01, -7.2405e-01,  6.0573e-03, -7.5916e-02,\n",
       "          3.2029e-01, -3.2438e-02, -8.4275e-01, -7.8131e-01,  2.0956e-01,\n",
       "         -7.4902e-01,  3.5519e-01,  2.1062e-01,  5.0404e-01,  7.4988e-01,\n",
       "         -5.5984e-01,  6.7994e-01, -2.3047e-01,  3.1184e-01, -6.3898e-01,\n",
       "          2.0707e-01, -2.8134e-01,  9.6291e-02,  6.9985e-01, -3.5003e-01,\n",
       "          7.1612e-01, -5.2566e-01, -6.0303e-01, -7.7106e-01, -1.4952e-01,\n",
       "          1.3294e-01,  4.4482e-01,  4.6527e-03,  4.6941e-01,  5.3359e-01,\n",
       "          3.7405e-01, -1.4904e-01,  4.3830e-01, -4.6311e-01, -2.0536e-01,\n",
       "         -5.6557e-01, -7.4269e-01, -8.1595e-01,  4.7996e-01, -6.4021e-01,\n",
       "          3.2881e-02,  1.4905e-01,  6.7853e-01, -4.6385e-01, -5.1629e-01,\n",
       "         -6.0351e-01, -3.9201e-01,  1.5951e-01,  5.7472e-01, -4.8025e-01,\n",
       "          2.2042e-01,  6.9155e-01,  3.6204e-01,  6.5603e-01, -3.6381e-01,\n",
       "         -2.2255e-01, -4.6753e-03,  7.3824e-01,  2.4156e-01, -9.0122e-01,\n",
       "          4.7483e-01, -2.7155e-01, -8.6515e-03, -3.9178e-01,  9.4562e-02,\n",
       "          5.9845e-02,  5.2317e-01,  5.9487e-01,  4.4311e-01, -4.2220e-01,\n",
       "          8.3402e-02, -1.6499e-01,  6.7857e-01, -1.0236e-01, -5.7648e-01,\n",
       "         -7.6804e-01,  1.8821e-02,  2.4528e-01,  2.5512e-01,  4.7815e-01,\n",
       "          7.4567e-01, -5.6145e-01,  2.6316e-02, -8.7748e-02,  9.3653e-01,\n",
       "          7.3153e-01,  8.1542e-01, -3.8091e-01,  2.0790e-01, -5.4572e-01,\n",
       "         -1.4983e-01, -8.8784e-03,  8.9272e-01,  7.8402e-01, -4.5075e-01,\n",
       "         -3.7038e-01, -1.3340e-01, -7.4793e-01, -2.9858e-01,  4.4965e-01,\n",
       "         -2.0187e-01,  2.8186e-01, -7.4529e-01,  5.7701e-01,  1.0314e-01,\n",
       "          2.7011e-01,  1.6018e-01,  6.8803e-01, -4.8978e-01,  8.1660e-01,\n",
       "          2.3725e-01,  5.7512e-01, -4.4372e-01,  6.9891e-02,  2.7464e-01,\n",
       "         -1.1447e-01, -1.7708e-01, -1.6928e-05,  8.2069e-01,  4.5596e-01,\n",
       "          1.0093e-01,  2.4834e-01, -3.7768e-01,  4.6751e-01, -1.1348e-01,\n",
       "          9.1882e-03,  4.6928e-01, -4.0055e-01, -4.2881e-01,  3.0853e-02,\n",
       "         -4.5985e-01, -1.8536e-01, -8.3175e-01,  1.3632e-01,  3.4957e-01,\n",
       "          2.1014e-01, -3.8536e-01, -2.2407e-01,  3.4479e-01, -4.5538e-01,\n",
       "          7.9142e-01,  8.4402e-01,  4.2624e-01,  7.5554e-01,  9.8202e-02,\n",
       "          2.2346e-01,  4.0147e-01,  7.7411e-01, -4.6117e-01,  7.1553e-01,\n",
       "         -2.1969e-01, -5.2886e-01,  2.8481e-01,  2.8492e-01, -6.1995e-01,\n",
       "         -9.3430e-02,  3.8149e-01,  2.4471e-01,  1.0332e-01, -6.4699e-01,\n",
       "          4.6035e-01,  2.8895e-01,  8.8339e-02, -4.5018e-01, -5.8552e-01,\n",
       "         -3.2256e-01,  4.4852e-01, -6.1095e-01,  4.9283e-02,  3.5792e-01,\n",
       "          3.7036e-01,  3.4318e-02, -4.9264e-01,  3.5030e-01, -5.5436e-01,\n",
       "         -6.6241e-01,  5.5997e-01, -1.7506e-01, -1.1743e-01, -1.0848e-01,\n",
       "          4.3794e-01, -4.1307e-01, -9.2847e-01, -1.1987e-01,  2.7554e-01,\n",
       "          9.1844e-03,  2.2930e-01,  1.6485e-01,  4.1666e-01, -3.0530e-01,\n",
       "          2.8059e-01,  1.7763e-01,  1.7132e-01,  3.8340e-01,  4.6360e-01,\n",
       "          1.8849e-01,  3.5710e-01, -3.8203e-02, -4.3913e-01,  5.6460e-01,\n",
       "          2.2255e-01, -2.4609e-01, -8.5709e-01,  8.9242e-03, -4.8251e-01,\n",
       "          1.9010e-01,  6.3969e-01, -4.1017e-01, -8.9423e-01, -3.7493e-01,\n",
       "         -6.6971e-01, -2.2569e-01, -6.2063e-01, -2.2742e-01, -1.2058e-01,\n",
       "          1.4057e-01,  7.4965e-02,  2.8381e-01,  8.0932e-02, -2.7764e-01,\n",
       "         -2.7199e-01,  7.3455e-01,  2.7209e-01, -1.1049e-01, -1.5387e-01,\n",
       "         -3.9447e-02,  4.8048e-03, -3.1784e-01, -6.1075e-01, -7.4630e-02,\n",
       "         -3.7091e-01, -2.8935e-01, -5.5400e-01,  6.8778e-01,  5.3390e-02,\n",
       "          1.3695e-01,  3.0699e-01,  1.6105e-01,  5.9395e-01,  8.8150e-01,\n",
       "          9.6571e-02,  3.3975e-02,  6.5841e-01,  2.3452e-01,  6.1184e-01,\n",
       "          2.6456e-02,  3.7603e-01, -5.0510e-03, -3.8594e-03, -4.6142e-01,\n",
       "          9.2138e-01, -2.1565e-01,  5.7658e-01, -3.1089e-01, -2.5989e-02,\n",
       "          1.3759e-01, -2.2248e-01,  8.5788e-01,  4.2648e-02, -3.7222e-01,\n",
       "          4.0189e-01, -4.3423e-01,  4.1000e-01, -2.2329e-01,  4.1758e-01,\n",
       "          9.8185e-02,  3.4987e-01, -6.6402e-02, -4.5935e-01,  1.9468e-01,\n",
       "          2.1993e-01, -3.3985e-02, -4.4264e-01, -5.5741e-01,  3.4776e-01,\n",
       "          2.8923e-01, -3.4276e-01, -4.6284e-01,  2.0596e-01, -2.4184e-01,\n",
       "         -2.9087e-01, -3.0280e-01,  7.7437e-01,  1.9055e-01,  3.4171e-02,\n",
       "         -1.2885e-01, -8.4008e-01, -7.9941e-01,  4.0122e-01,  2.1688e-01,\n",
       "          5.0244e-01, -5.0276e-01,  4.1937e-01, -1.6265e-01,  2.8180e-01,\n",
       "         -3.0213e-01, -4.5155e-01,  6.1192e-01, -6.3533e-02, -3.0286e-01,\n",
       "         -9.2516e-01, -5.1288e-02, -5.7950e-02,  3.9984e-01,  1.7452e-01,\n",
       "         -7.1602e-01,  5.4600e-01, -2.1200e-01,  1.9911e-02, -2.4835e-01,\n",
       "          4.8921e-01, -4.5611e-01, -5.3504e-01, -8.9606e-01,  1.1314e-01,\n",
       "         -7.7284e-01,  6.6452e-01, -3.6638e-01, -1.1712e-01,  4.4425e-02,\n",
       "         -6.5092e-02, -2.8369e-02,  7.9182e-01,  7.0165e-01, -9.0789e-03,\n",
       "          2.0133e-01, -4.3507e-01,  4.8665e-02,  5.2447e-01, -3.3261e-01,\n",
       "         -2.3121e-01,  3.4577e-01,  7.8729e-02,  4.3922e-02,  4.1484e-01,\n",
       "         -7.9135e-01,  6.8562e-01,  1.2912e-01, -2.1726e-01, -2.8182e-01,\n",
       "          6.5101e-01, -4.0793e-01, -1.2500e-01,  3.9242e-02, -4.0138e-01,\n",
       "         -4.9681e-01,  6.3295e-01,  4.9701e-01, -4.2736e-01, -4.0503e-02,\n",
       "          3.8152e-02,  3.8098e-01,  4.6455e-01, -2.5064e-01,  4.6427e-02,\n",
       "         -6.8518e-01, -1.3410e-02,  6.1869e-01,  2.2803e-01, -5.0956e-01,\n",
       "         -5.1974e-01, -2.2082e-01,  2.4194e-01, -5.1097e-01, -6.6418e-01,\n",
       "          3.0759e-01,  3.3378e-01,  6.6114e-01,  1.7440e-01, -9.0037e-01,\n",
       "          7.1859e-03,  1.5356e-01,  2.5595e-01, -1.7925e-01,  1.0995e-01,\n",
       "         -3.9117e-01, -1.2713e-01, -4.1518e-01,  6.4228e-01,  2.5081e-01,\n",
       "          4.1337e-01,  2.6014e-01, -5.9235e-01, -5.6507e-01,  4.5576e-01,\n",
       "          2.6306e-01,  5.3754e-01, -5.0365e-01,  6.2470e-01, -2.7071e-01,\n",
       "         -8.5212e-01,  5.7616e-01,  8.5098e-01,  4.3026e-01,  7.4502e-01,\n",
       "         -2.6452e-01,  7.0795e-01,  6.0423e-01,  6.8058e-02, -5.8403e-01,\n",
       "          6.5921e-03,  1.5669e-01,  5.7012e-01, -1.4771e-01, -8.9113e-01,\n",
       "         -7.4696e-01,  4.6287e-01,  1.8546e-01,  6.5648e-01, -6.3200e-01,\n",
       "          2.1084e-01,  6.3765e-01, -4.4499e-01, -3.0624e-01,  3.4718e-02,\n",
       "         -9.5400e-01,  2.1540e-02, -6.6303e-01,  1.3979e-01,  2.5875e-01,\n",
       "          4.1482e-01,  3.9707e-01,  5.2635e-01,  3.2642e-01, -2.8253e-01,\n",
       "          3.6346e-01,  4.1007e-01,  7.2357e-01, -3.4816e-01,  1.7930e-01,\n",
       "         -1.4338e-01,  7.5919e-01, -6.6389e-03, -1.5940e-01,  3.8455e-01,\n",
       "         -3.4988e-02, -3.0386e-01,  1.5439e-01, -1.6501e-01, -5.4223e-01,\n",
       "          4.9287e-01,  1.7624e-01, -6.1412e-01,  2.0618e-01, -5.2640e-01,\n",
       "          9.9184e-02,  1.4528e-01,  8.7898e-02, -1.9285e-01,  5.5109e-01,\n",
       "         -3.2859e-01,  3.1339e-01,  4.1524e-02,  4.1654e-01,  2.5703e-01,\n",
       "         -2.0482e-01, -2.9384e-03,  3.6325e-01,  5.3389e-01, -9.0368e-02,\n",
       "         -7.3979e-01, -2.4421e-01, -6.6855e-01, -2.3495e-01,  2.1313e-02,\n",
       "          5.0707e-01, -6.3151e-01,  2.1961e-02,  3.0801e-01,  4.6927e-01,\n",
       "          1.5519e-01, -3.8340e-01,  7.0122e-02,  7.6469e-01,  1.9788e-01,\n",
       "         -4.4042e-01,  8.3050e-01, -3.2045e-01, -3.3913e-01, -4.4041e-01,\n",
       "          1.6027e-01,  2.8571e-02,  5.1634e-02, -1.0126e-01,  4.1521e-01,\n",
       "         -1.5769e-01,  5.1241e-01, -1.8022e-01, -5.4988e-01, -2.1861e-03,\n",
       "          4.2895e-01,  8.7179e-02,  8.0429e-01,  2.4326e-01, -4.7785e-01,\n",
       "          2.8710e-01, -5.7855e-01,  8.0501e-01,  2.5033e-01,  4.9085e-01,\n",
       "         -5.0098e-02, -7.2003e-01, -8.5552e-01,  7.7173e-02, -2.0374e-01,\n",
       "          2.6316e-02,  7.3428e-01, -2.1379e-01,  5.1307e-02,  4.3739e-01,\n",
       "         -5.0925e-01,  1.5758e-02,  6.9798e-01, -4.2869e-02,  4.0729e-01,\n",
       "         -6.3937e-01, -3.3006e-01,  4.6460e-01, -1.3855e-01,  4.9280e-01,\n",
       "         -3.0426e-01,  8.0908e-01,  2.3920e-01,  3.6775e-01, -3.0718e-01,\n",
       "          4.5944e-01, -5.9087e-01, -8.3772e-01,  1.4661e-01, -3.3101e-01,\n",
       "          4.7463e-01,  1.3894e-02,  6.9484e-01,  5.8414e-01,  2.8931e-01,\n",
       "          4.2952e-01,  4.9315e-01,  6.8957e-01, -4.5228e-01,  4.1801e-01,\n",
       "          4.0872e-01, -9.1535e-01,  4.6123e-01, -2.7130e-01,  4.8900e-01,\n",
       "         -4.6040e-01, -3.7765e-01, -3.0970e-01,  4.9570e-01,  7.6410e-01,\n",
       "          7.8780e-01,  2.7824e-01,  1.4751e-01, -8.4642e-01, -5.2306e-02,\n",
       "         -6.9184e-01, -4.8104e-01, -2.3256e-01, -2.0963e-01, -7.9724e-03,\n",
       "          2.2821e-01,  3.6480e-01,  2.9572e-01,  1.8755e-01, -5.2568e-01,\n",
       "         -2.8249e-01,  6.7968e-02,  1.0621e-01, -3.0681e-02,  6.2368e-01,\n",
       "          4.0184e-01,  3.4882e-01,  4.3736e-01,  4.6193e-01,  3.0323e-01,\n",
       "          5.8556e-01, -6.2905e-01,  1.2981e-01,  3.8797e-01,  2.0525e-01,\n",
       "         -2.5462e-01,  1.0680e-01, -7.4182e-01,  3.8619e-01, -3.0242e-01,\n",
       "          5.7115e-01,  4.5086e-01, -8.0167e-01,  7.2853e-01, -1.8356e-01,\n",
       "         -6.3075e-01,  6.4558e-01, -6.2999e-02, -4.9987e-01,  2.7659e-01,\n",
       "          3.2481e-01,  3.7116e-01,  5.7024e-01, -4.0804e-01,  4.8966e-01,\n",
       "         -3.6479e-01, -4.3381e-03, -2.6503e-01, -2.4807e-01,  3.8333e-01,\n",
       "          7.3600e-01, -4.0920e-01, -2.1608e-01,  3.5284e-02, -1.4113e-01,\n",
       "          3.6808e-01, -2.8763e-01,  1.2423e-01,  4.8052e-01,  3.0592e-01,\n",
       "          6.7917e-01, -4.5606e-01,  5.8111e-01,  1.0894e-01,  2.9250e-01,\n",
       "          2.5929e-01, -5.4906e-01, -2.3193e-01,  3.9832e-01,  2.7815e-01,\n",
       "         -5.5187e-01, -3.7741e-01,  1.8392e-01, -7.4692e-01,  1.7221e-01,\n",
       "         -6.3522e-02, -5.5356e-01,  3.0361e-01, -8.7210e-01, -2.0061e-02,\n",
       "          3.9034e-02, -4.6543e-01,  3.7117e-01,  1.5666e-01, -5.1463e-02,\n",
       "          1.4781e-02, -5.4706e-01, -8.6812e-03,  1.9984e-01, -2.2753e-01,\n",
       "         -1.6641e-01,  3.9719e-01, -3.8701e-01,  7.0133e-01,  3.3540e-01,\n",
       "          1.7867e-01, -3.1960e-01, -6.3176e-01, -4.7093e-01,  6.6014e-01,\n",
       "          2.9267e-01,  2.1189e-01,  1.7457e-01,  1.9223e-01, -1.0102e-01,\n",
       "          2.1308e-01, -6.8318e-01, -7.7258e-02, -3.4844e-01, -6.4596e-01,\n",
       "         -1.8209e-01, -5.1957e-01, -1.9502e-01, -1.6190e-01, -9.2753e-02,\n",
       "         -2.5631e-01, -4.1358e-01, -1.7949e-01,  2.6051e-01,  4.8142e-01,\n",
       "         -4.0043e-01,  6.9384e-02,  1.0133e-01, -4.5207e-01,  9.5498e-02,\n",
       "          5.9073e-01, -5.4659e-01, -3.7033e-01,  2.4008e-01,  4.3806e-01,\n",
       "          6.4008e-01,  1.4325e-01,  1.7651e-01, -3.2693e-01, -5.9312e-01,\n",
       "         -6.8295e-01,  2.4181e-02, -9.4465e-01, -7.9020e-02, -3.3565e-01,\n",
       "          2.9467e-01, -2.6061e-01,  9.6337e-02,  6.5219e-01, -1.9767e-01,\n",
       "          2.4018e-01,  8.3443e-01,  7.3390e-01, -7.7799e-01, -3.0098e-01,\n",
       "          2.5191e-02, -2.6728e-01,  5.9036e-01,  3.9773e-01, -7.2379e-01,\n",
       "          3.0564e-01, -2.8604e-01, -5.6764e-02, -2.9808e-01,  3.9803e-01,\n",
       "          5.5552e-01, -5.1993e-01,  3.1954e-01,  1.4440e-01, -2.1703e-01,\n",
       "          3.9248e-01,  9.9875e-02, -9.4722e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657177b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
