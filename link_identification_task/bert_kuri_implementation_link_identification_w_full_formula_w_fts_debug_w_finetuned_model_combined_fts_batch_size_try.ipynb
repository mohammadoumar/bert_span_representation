{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08d09abd",
   "metadata": {},
   "source": [
    "# Implementation of the Kuribayashi BERT minus model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8267406a",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7daa634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.25.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.3.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2021.10.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.0.4)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.28.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.5)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (58.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: IProgress in /opt/conda/lib/python3.8/site-packages (0.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from IProgress) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.8/site-packages (1.15.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.8/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets) (1.21.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.11.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (2.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch-lr-finder in /opt/conda/lib/python3.8/site-packages (0.2.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from torch-lr-finder) (4.62.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from torch-lr-finder) (3.4.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from torch-lr-finder) (21.0)\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from torch-lr-finder) (1.10.0a0+0aef44c)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torch-lr-finder) (1.21.2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=0.4.1->torch-lr-finder) (3.10.0.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->torch-lr-finder) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->torch-lr-finder) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->torch-lr-finder) (8.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib->torch-lr-finder) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->torch-lr-finder) (0.10.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->torch-lr-finder) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers --upgrade\n",
    "!pip install ipywidgets\n",
    "!pip install IProgress\n",
    "!pip install datasets\n",
    "!pip install torch-lr-finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd8a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import BertModel, BertForSequenceClassification\n",
    "from transformers import BatchEncoding, default_data_collator, DataCollatorWithPadding\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import datasets\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d571ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.25.1\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dff4880",
   "metadata": {},
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11996f4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c84153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.model_max_length = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1416c65",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60be286f",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "0c699094-439f-4dda-85a9-815e7948540c",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "# DATA_FOLDER = '/notebooks/Data/bert_sequence_classification'\n",
    "DATA_FILE = '/notebooks/KURI-BERT/notebooks/full_formula_w_fts/Link_Identification_Task/pe_dataset_for_bert_minus_w_fts_combined_link_task.pt'\n",
    "RESULTS_FOLDER = '/notebooks/KURI-BERT/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07c543d8",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "35aada91-232a-421e-a28f-94b359c6d65d",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52544172",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "dc52e71e-65fa-4946-acdf-e4fffe9d0f79",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6573e965",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "013a6d64-65e7-4189-a468-40ecfd8a6736",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87d69bc7",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "626737f9-ff56-4992-b72b-60750375e455",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "dataset = torch.load(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55edc24b",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 6,
     "id": "4fbfcc7b-55fb-456e-ab02-2ae975803046",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['paragraph', 'paragraph_components_list', 'paragraph_labels_list', 'paragraph_markers_list', 'split', 'essay_nr', 'paragraph_fts_as_txt_list', 'paragraph_labels', 'paragraph_ac_spans', 'paragraph_am_spans', 'paragraph_w_fts_as_txt', 'ac_spans_new', 'sanity_new', 'am_spans_new', 'feature_spans_new'],\n",
       "        num_rows: 1088\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['paragraph', 'paragraph_components_list', 'paragraph_labels_list', 'paragraph_markers_list', 'split', 'essay_nr', 'paragraph_fts_as_txt_list', 'paragraph_labels', 'paragraph_ac_spans', 'paragraph_am_spans', 'paragraph_w_fts_as_txt', 'ac_spans_new', 'sanity_new', 'am_spans_new', 'feature_spans_new'],\n",
       "        num_rows: 358\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['paragraph', 'paragraph_components_list', 'paragraph_labels_list', 'paragraph_markers_list', 'split', 'essay_nr', 'paragraph_fts_as_txt_list', 'paragraph_labels', 'paragraph_ac_spans', 'paragraph_am_spans', 'paragraph_w_fts_as_txt', 'ac_spans_new', 'sanity_new', 'am_spans_new', 'feature_spans_new'],\n",
       "        num_rows: 273\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c7db435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Firstly, by paying taxes for public school, affluent people effectively contribute to narrowing down the gap between rich and poor [SEP] Structural Features: 2, Yes, No, No, No [SEP]. It is true that many poor families are not able to afford tuition fees for their kids to attend a course [SEP] Structural Features: 2, No, No, No, No [SEP]. With the the tax amount for which they pay, the rich may help a vast number of students from families with poverty background to continue their studies, and earn a better quality of life [SEP] Structural Features: 2, No, Yes, No, No [SEP].'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['paragraph_w_fts_as_txt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "067e2a0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "7\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "1\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "5\n",
      "6\n",
      "4\n",
      "6\n",
      "7\n",
      "2\n",
      "1\n",
      "5\n",
      "1\n",
      "3\n",
      "3\n",
      "4\n",
      "6\n",
      "2\n",
      "1\n",
      "5\n",
      "3\n",
      "4\n",
      "7\n",
      "4\n",
      "5\n",
      "1\n",
      "7\n",
      "4\n",
      "8\n",
      "3\n",
      "1\n",
      "7\n",
      "2\n",
      "1\n",
      "6\n",
      "2\n",
      "4\n",
      "6\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "6\n",
      "3\n",
      "7\n",
      "1\n",
      "6\n",
      "1\n",
      "6\n",
      "4\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "1\n",
      "6\n",
      "1\n",
      "1\n",
      "5\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "5\n",
      "1\n",
      "5\n",
      "7\n",
      "6\n",
      "5\n",
      "1\n",
      "5\n",
      "6\n",
      "7\n",
      "3\n",
      "6\n",
      "1\n",
      "2\n",
      "5\n",
      "7\n",
      "5\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "11\n",
      "9\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "1\n",
      "3\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "11\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "5\n",
      "4\n",
      "3\n",
      "1\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "3\n",
      "4\n",
      "6\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "3\n",
      "7\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "3\n",
      "6\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "1\n",
      "7\n",
      "6\n",
      "3\n",
      "12\n",
      "4\n",
      "2\n",
      "1\n",
      "2\n",
      "5\n",
      "4\n",
      "1\n",
      "3\n",
      "1\n",
      "5\n",
      "3\n",
      "1\n",
      "7\n",
      "2\n",
      "1\n",
      "4\n",
      "1\n",
      "3\n",
      "6\n",
      "1\n",
      "1\n",
      "5\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "1\n",
      "2\n",
      "5\n",
      "3\n",
      "6\n",
      "4\n",
      "10\n",
      "1\n",
      "6\n",
      "2\n",
      "1\n",
      "8\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "6\n",
      "4\n",
      "7\n",
      "1\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "1\n",
      "2\n",
      "7\n",
      "7\n",
      "3\n",
      "2\n",
      "4\n",
      "6\n",
      "4\n",
      "3\n",
      "1\n",
      "8\n",
      "2\n",
      "1\n",
      "6\n",
      "1\n",
      "1\n",
      "6\n",
      "7\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "1\n",
      "1\n",
      "4\n",
      "4\n",
      "6\n",
      "2\n",
      "1\n",
      "4\n",
      "5\n",
      "1\n",
      "3\n",
      "1\n",
      "6\n",
      "2\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "1\n",
      "2\n",
      "2\n",
      "7\n",
      "1\n",
      "1\n",
      "5\n",
      "1\n",
      "2\n",
      "6\n",
      "5\n",
      "3\n",
      "5\n",
      "1\n",
      "1\n",
      "3\n",
      "4\n",
      "6\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "6\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "5\n",
      "1\n",
      "3\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "5\n",
      "3\n",
      "1\n",
      "9\n",
      "3\n",
      "1\n",
      "3\n",
      "6\n",
      "6\n",
      "2\n",
      "1\n",
      "5\n",
      "5\n",
      "7\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "6\n",
      "6\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "1\n",
      "7\n",
      "1\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "3\n",
      "1\n",
      "8\n",
      "4\n",
      "5\n",
      "7\n",
      "1\n",
      "3\n",
      "4\n",
      "7\n",
      "5\n",
      "3\n",
      "2\n",
      "6\n",
      "6\n",
      "7\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "1\n",
      "10\n",
      "4\n",
      "6\n",
      "1\n",
      "5\n",
      "7\n",
      "4\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "8\n",
      "5\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "1\n",
      "8\n",
      "4\n",
      "4\n",
      "5\n",
      "6\n",
      "1\n",
      "4\n",
      "4\n",
      "6\n",
      "1\n",
      "4\n",
      "6\n",
      "5\n",
      "1\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "5\n",
      "4\n",
      "3\n",
      "6\n",
      "2\n",
      "6\n",
      "1\n",
      "4\n",
      "6\n",
      "5\n",
      "1\n",
      "2\n",
      "4\n",
      "6\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n",
      "6\n",
      "6\n",
      "2\n",
      "1\n",
      "5\n",
      "1\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "1\n",
      "5\n",
      "1\n",
      "2\n",
      "1\n",
      "9\n",
      "6\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "6\n",
      "3\n",
      "3\n",
      "4\n",
      "7\n",
      "3\n",
      "3\n",
      "1\n",
      "6\n",
      "2\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "1\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "8\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "1\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "6\n",
      "5\n",
      "1\n",
      "4\n",
      "1\n",
      "6\n",
      "1\n",
      "2\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "1\n",
      "6\n",
      "2\n",
      "8\n",
      "4\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "5\n",
      "7\n",
      "3\n",
      "5\n",
      "2\n",
      "1\n",
      "4\n",
      "7\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "5\n",
      "6\n",
      "2\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "5\n",
      "1\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "7\n",
      "2\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "2\n",
      "4\n",
      "1\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "8\n",
      "2\n",
      "1\n",
      "2\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "1\n",
      "2\n",
      "4\n",
      "6\n",
      "2\n",
      "4\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "2\n",
      "3\n",
      "2\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "5\n",
      "5\n",
      "2\n",
      "3\n",
      "1\n",
      "4\n",
      "3\n",
      "6\n",
      "1\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "1\n",
      "2\n",
      "6\n",
      "6\n",
      "5\n",
      "1\n",
      "2\n",
      "7\n",
      "4\n",
      "5\n",
      "2\n",
      "5\n",
      "4\n",
      "6\n",
      "2\n",
      "1\n",
      "4\n",
      "2\n",
      "8\n",
      "7\n",
      "4\n",
      "2\n",
      "3\n",
      "7\n",
      "7\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "6\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "6\n",
      "3\n",
      "1\n",
      "2\n",
      "4\n",
      "7\n",
      "1\n",
      "4\n",
      "1\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "7\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "6\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "5\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "5\n",
      "4\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "4\n",
      "6\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "4\n",
      "2\n",
      "1\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "1\n",
      "3\n",
      "7\n",
      "5\n",
      "7\n",
      "3\n",
      "1\n",
      "4\n",
      "5\n",
      "2\n",
      "1\n",
      "7\n",
      "4\n",
      "2\n",
      "3\n",
      "1\n",
      "9\n",
      "1\n",
      "1\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "1\n",
      "5\n",
      "8\n",
      "7\n",
      "3\n",
      "5\n",
      "1\n",
      "4\n",
      "2\n",
      "8\n",
      "6\n",
      "1\n",
      "4\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "1\n",
      "4\n",
      "3\n",
      "7\n",
      "5\n",
      "2\n",
      "1\n",
      "3\n",
      "8\n",
      "1\n",
      "2\n",
      "5\n",
      "4\n",
      "4\n",
      "1\n",
      "8\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "1\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "6\n",
      "1\n",
      "2\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "6\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "5\n",
      "2\n",
      "5\n",
      "2\n",
      "8\n",
      "6\n",
      "2\n",
      "6\n",
      "7\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "1\n",
      "2\n",
      "9\n",
      "5\n",
      "3\n",
      "1\n",
      "5\n",
      "4\n",
      "3\n",
      "1\n",
      "2\n",
      "6\n",
      "3\n",
      "6\n",
      "1\n",
      "6\n",
      "3\n",
      "5\n",
      "1\n",
      "7\n",
      "2\n",
      "1\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "7\n",
      "1\n",
      "1\n",
      "3\n",
      "2\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "1\n",
      "3\n",
      "1\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "2\n",
      "1\n",
      "1\n",
      "3\n",
      "4\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "7\n",
      "1\n",
      "4\n",
      "4\n",
      "5\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "7\n",
      "1\n",
      "3\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "7\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "8\n",
      "4\n",
      "4\n",
      "5\n",
      "1\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "1\n",
      "2\n",
      "4\n",
      "3\n",
      "1\n",
      "4\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "1\n",
      "8\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "1\n",
      "4\n",
      "2\n",
      "1\n",
      "5\n",
      "2\n",
      "10\n",
      "2\n",
      "6\n",
      "2\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "2\n",
      "2\n",
      "4\n",
      "6\n",
      "1\n",
      "1\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "6\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "6\n",
      "3\n",
      "4\n",
      "1\n",
      "6\n",
      "4\n",
      "1\n",
      "2\n",
      "6\n",
      "7\n",
      "2\n",
      "2\n",
      "2\n",
      "6\n",
      "1\n",
      "5\n",
      "4\n",
      "5\n",
      "2\n",
      "1\n",
      "3\n",
      "6\n",
      "6\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "2\n",
      "5\n",
      "1\n",
      "3\n",
      "1\n",
      "1\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "6\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for l in dataset['train']['feature_spans_new']:\n",
    "    print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "607c00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in dataset['train']['feature_spans_new'] for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37f534c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[23, 34],\n",
       " [59, 70],\n",
       " [110, 121],\n",
       " [47, 58],\n",
       " [95, 106],\n",
       " [127, 138],\n",
       " [25, 36],\n",
       " [56, 67],\n",
       " [100, 111],\n",
       " [21, 32],\n",
       " [69, 80],\n",
       " [14, 25],\n",
       " [59, 70],\n",
       " [86, 97],\n",
       " [110, 121],\n",
       " [9, 20],\n",
       " [35, 46],\n",
       " [65, 76],\n",
       " [90, 101],\n",
       " [113, 124],\n",
       " [148, 159],\n",
       " [184, 195],\n",
       " [23, 34],\n",
       " [44, 55],\n",
       " [70, 81],\n",
       " [115, 126],\n",
       " [43, 54],\n",
       " [22, 33],\n",
       " [52, 63],\n",
       " [19, 30],\n",
       " [60, 71],\n",
       " [84, 95],\n",
       " [25, 36],\n",
       " [62, 73],\n",
       " [98, 109],\n",
       " [126, 137],\n",
       " [21, 32],\n",
       " [46, 57],\n",
       " [73, 84],\n",
       " [97, 108],\n",
       " [128, 139],\n",
       " [31, 42],\n",
       " [61, 72],\n",
       " [31, 42],\n",
       " [68, 79],\n",
       " [113, 124],\n",
       " [158, 169],\n",
       " [19, 30],\n",
       " [49, 60],\n",
       " [84, 95],\n",
       " [115, 126],\n",
       " [146, 157],\n",
       " [81, 92],\n",
       " [114, 125],\n",
       " [32, 43],\n",
       " [53, 64],\n",
       " [23, 34],\n",
       " [48, 59],\n",
       " [78, 89],\n",
       " [107, 118],\n",
       " [137, 148],\n",
       " [16, 27],\n",
       " [43, 54],\n",
       " [79, 90],\n",
       " [104, 115],\n",
       " [131, 142],\n",
       " [164, 175],\n",
       " [18, 29],\n",
       " [54, 65],\n",
       " [81, 92],\n",
       " [117, 128],\n",
       " [16, 27],\n",
       " [37, 48],\n",
       " [69, 80],\n",
       " [97, 108],\n",
       " [135, 146],\n",
       " [171, 182],\n",
       " [19, 30],\n",
       " [55, 66],\n",
       " [95, 106],\n",
       " [126, 137],\n",
       " [166, 177],\n",
       " [203, 214],\n",
       " [248, 259],\n",
       " [24, 35],\n",
       " [50, 61],\n",
       " [26, 37],\n",
       " [11, 22],\n",
       " [34, 45],\n",
       " [60, 71],\n",
       " [91, 102],\n",
       " [145, 156],\n",
       " [57, 68],\n",
       " [14, 25],\n",
       " [39, 50],\n",
       " [105, 116],\n",
       " [24, 35],\n",
       " [60, 71],\n",
       " [89, 100],\n",
       " [17, 28],\n",
       " [54, 65],\n",
       " [84, 95],\n",
       " [128, 139],\n",
       " [11, 22],\n",
       " [63, 74],\n",
       " [111, 122],\n",
       " [138, 149],\n",
       " [171, 182],\n",
       " [196, 207],\n",
       " [90, 101],\n",
       " [116, 127],\n",
       " [21, 32],\n",
       " [15, 26],\n",
       " [45, 56],\n",
       " [64, 75],\n",
       " [91, 102],\n",
       " [136, 147],\n",
       " [19, 30],\n",
       " [49, 60],\n",
       " [83, 94],\n",
       " [20, 31],\n",
       " [54, 65],\n",
       " [93, 104],\n",
       " [121, 132],\n",
       " [17, 28],\n",
       " [43, 54],\n",
       " [71, 82],\n",
       " [104, 115],\n",
       " [136, 147],\n",
       " [171, 182],\n",
       " [205, 216],\n",
       " [18, 29],\n",
       " [62, 73],\n",
       " [102, 113],\n",
       " [137, 148],\n",
       " [16, 27],\n",
       " [45, 56],\n",
       " [85, 96],\n",
       " [128, 139],\n",
       " [162, 173],\n",
       " [60, 71],\n",
       " [10, 21],\n",
       " [41, 52],\n",
       " [70, 81],\n",
       " [91, 102],\n",
       " [115, 126],\n",
       " [135, 146],\n",
       " [163, 174],\n",
       " [14, 25],\n",
       " [45, 56],\n",
       " [80, 91],\n",
       " [111, 122],\n",
       " [11, 22],\n",
       " [35, 46],\n",
       " [62, 73],\n",
       " [87, 98],\n",
       " [114, 125],\n",
       " [140, 151],\n",
       " [173, 184],\n",
       " [202, 213],\n",
       " [21, 32],\n",
       " [54, 65],\n",
       " [94, 105],\n",
       " [61, 72],\n",
       " [11, 22],\n",
       " [33, 44],\n",
       " [78, 89],\n",
       " [117, 128],\n",
       " [148, 159],\n",
       " [179, 190],\n",
       " [213, 224],\n",
       " [14, 25],\n",
       " [45, 56],\n",
       " [67, 78],\n",
       " [22, 33],\n",
       " [51, 62],\n",
       " [75, 86],\n",
       " [122, 133],\n",
       " [159, 170],\n",
       " [191, 202],\n",
       " [33, 44],\n",
       " [78, 89],\n",
       " [55, 66],\n",
       " [82, 93],\n",
       " [120, 131],\n",
       " [166, 177],\n",
       " [14, 25],\n",
       " [46, 57],\n",
       " [83, 94],\n",
       " [123, 134],\n",
       " [157, 168],\n",
       " [191, 202],\n",
       " [22, 33],\n",
       " [58, 69],\n",
       " [27, 38],\n",
       " [24, 35],\n",
       " [61, 72],\n",
       " [99, 110],\n",
       " [31, 42],\n",
       " [16, 27],\n",
       " [54, 65],\n",
       " [80, 91],\n",
       " [110, 121],\n",
       " [152, 163],\n",
       " [199, 210],\n",
       " [11, 22],\n",
       " [37, 48],\n",
       " [72, 83],\n",
       " [14, 25],\n",
       " [42, 53],\n",
       " [77, 88],\n",
       " [110, 121],\n",
       " [147, 158],\n",
       " [187, 198],\n",
       " [233, 244],\n",
       " [79, 90],\n",
       " [16, 27],\n",
       " [42, 53],\n",
       " [85, 96],\n",
       " [133, 144],\n",
       " [169, 180],\n",
       " [202, 213],\n",
       " [79, 90],\n",
       " [20, 31],\n",
       " [46, 57],\n",
       " [86, 97],\n",
       " [129, 140],\n",
       " [162, 173],\n",
       " [186, 197],\n",
       " [61, 72],\n",
       " [94, 105],\n",
       " [137, 148],\n",
       " [167, 178],\n",
       " [26, 37],\n",
       " [51, 62],\n",
       " [85, 96],\n",
       " [110, 121],\n",
       " [156, 167],\n",
       " [15, 26],\n",
       " [62, 73],\n",
       " [105, 116],\n",
       " [17, 28],\n",
       " [43, 54],\n",
       " [75, 86],\n",
       " [104, 115],\n",
       " [156, 167],\n",
       " [20, 31],\n",
       " [56, 67],\n",
       " [81, 92],\n",
       " [117, 128],\n",
       " [148, 159],\n",
       " [21, 32],\n",
       " [15, 26],\n",
       " [49, 60],\n",
       " [86, 97],\n",
       " [113, 124],\n",
       " [138, 149],\n",
       " [174, 185],\n",
       " [35, 46],\n",
       " [65, 76],\n",
       " [31, 42],\n",
       " [81, 92],\n",
       " [111, 122],\n",
       " [154, 165],\n",
       " [188, 199],\n",
       " [15, 26],\n",
       " [83, 94],\n",
       " [139, 150],\n",
       " [10, 21],\n",
       " [33, 44],\n",
       " [62, 73],\n",
       " [15, 26],\n",
       " [59, 70],\n",
       " [102, 113],\n",
       " [21, 32],\n",
       " [55, 66],\n",
       " [80, 91],\n",
       " [120, 131],\n",
       " [150, 161],\n",
       " [43, 54],\n",
       " [30, 41],\n",
       " [65, 76],\n",
       " [102, 113],\n",
       " [132, 143],\n",
       " [162, 173],\n",
       " [32, 43],\n",
       " [63, 74],\n",
       " [111, 122],\n",
       " [141, 152],\n",
       " [172, 183],\n",
       " [199, 210],\n",
       " [229, 240],\n",
       " [10, 21],\n",
       " [39, 50],\n",
       " [60, 71],\n",
       " [93, 104],\n",
       " [133, 144],\n",
       " [186, 197],\n",
       " [22, 33],\n",
       " [52, 63],\n",
       " [97, 108],\n",
       " [144, 155],\n",
       " [170, 181],\n",
       " [94, 105],\n",
       " [22, 33],\n",
       " [45, 56],\n",
       " [74, 85],\n",
       " [110, 121],\n",
       " [139, 150],\n",
       " [22, 33],\n",
       " [69, 80],\n",
       " [104, 115],\n",
       " [130, 141],\n",
       " [167, 178],\n",
       " [194, 205],\n",
       " [9, 20],\n",
       " [39, 50],\n",
       " [74, 85],\n",
       " [102, 113],\n",
       " [144, 155],\n",
       " [168, 179],\n",
       " [202, 213],\n",
       " [20, 31],\n",
       " [44, 55],\n",
       " [80, 91],\n",
       " [22, 33],\n",
       " [58, 69],\n",
       " [91, 102],\n",
       " [119, 130],\n",
       " [154, 165],\n",
       " [186, 197],\n",
       " [42, 53],\n",
       " [16, 27],\n",
       " [49, 60],\n",
       " [18, 29],\n",
       " [42, 53],\n",
       " [67, 78],\n",
       " [98, 109],\n",
       " [123, 134],\n",
       " [16, 27],\n",
       " [42, 53],\n",
       " [91, 102],\n",
       " [120, 131],\n",
       " [153, 164],\n",
       " [188, 199],\n",
       " [223, 234],\n",
       " [23, 34],\n",
       " [47, 58],\n",
       " [77, 88],\n",
       " [109, 120],\n",
       " [147, 158],\n",
       " [31, 42],\n",
       " [70, 81],\n",
       " [90, 101],\n",
       " [168, 179],\n",
       " [15, 26],\n",
       " [54, 65],\n",
       " [96, 107],\n",
       " [132, 143],\n",
       " [52, 63],\n",
       " [32, 43],\n",
       " [58, 69],\n",
       " [87, 98],\n",
       " [123, 134],\n",
       " [14, 25],\n",
       " [48, 59],\n",
       " [68, 79],\n",
       " [95, 106],\n",
       " [143, 154],\n",
       " [164, 175],\n",
       " [187, 198],\n",
       " [213, 224],\n",
       " [246, 257],\n",
       " [273, 284],\n",
       " [294, 305],\n",
       " [15, 26],\n",
       " [44, 55],\n",
       " [69, 80],\n",
       " [97, 108],\n",
       " [126, 137],\n",
       " [176, 187],\n",
       " [208, 219],\n",
       " [233, 244],\n",
       " [261, 272],\n",
       " [39, 50],\n",
       " [97, 108],\n",
       " [144, 155],\n",
       " [168, 179],\n",
       " [23, 34],\n",
       " [54, 65],\n",
       " [88, 99],\n",
       " [127, 138],\n",
       " [16, 27],\n",
       " [54, 65],\n",
       " [90, 101],\n",
       " [126, 137],\n",
       " [12, 23],\n",
       " [39, 50],\n",
       " [73, 84],\n",
       " [99, 110],\n",
       " [24, 35],\n",
       " [68, 79],\n",
       " [99, 110],\n",
       " [29, 40],\n",
       " [77, 88],\n",
       " [114, 125],\n",
       " [159, 170],\n",
       " [42, 53],\n",
       " [40, 51],\n",
       " [68, 79],\n",
       " [104, 115],\n",
       " [52, 63],\n",
       " [82, 93],\n",
       " [114, 125],\n",
       " [25, 36],\n",
       " [66, 77],\n",
       " [39, 50],\n",
       " [62, 73],\n",
       " [24, 35],\n",
       " [64, 75],\n",
       " [22, 33],\n",
       " [52, 63],\n",
       " [90, 101],\n",
       " [117, 128],\n",
       " [141, 152],\n",
       " [170, 181],\n",
       " [200, 211],\n",
       " [221, 232],\n",
       " [255, 266],\n",
       " [280, 291],\n",
       " [311, 322],\n",
       " [23, 34],\n",
       " [56, 67],\n",
       " [109, 120],\n",
       " [18, 29],\n",
       " [53, 64],\n",
       " [35, 46],\n",
       " [73, 84],\n",
       " [100, 111],\n",
       " [140, 151],\n",
       " [19, 30],\n",
       " [52, 63],\n",
       " [80, 91],\n",
       " [120, 131],\n",
       " [21, 32],\n",
       " [80, 91],\n",
       " [16, 27],\n",
       " [53, 64],\n",
       " [94, 105],\n",
       " [115, 126],\n",
       " [135, 146],\n",
       " [32, 43],\n",
       " [64, 75],\n",
       " [103, 114],\n",
       " [155, 166],\n",
       " [31, 42],\n",
       " [63, 74],\n",
       " [97, 108],\n",
       " [24, 35],\n",
       " [21, 32],\n",
       " [46, 57],\n",
       " [69, 80],\n",
       " [96, 107],\n",
       " [12, 23],\n",
       " [45, 56],\n",
       " [80, 91],\n",
       " [104, 115],\n",
       " [56, 67],\n",
       " [64, 75],\n",
       " [18, 29],\n",
       " [51, 62],\n",
       " [87, 98],\n",
       " [13, 24],\n",
       " [47, 58],\n",
       " [79, 90],\n",
       " [111, 122],\n",
       " [15, 26],\n",
       " [47, 58],\n",
       " [77, 88],\n",
       " [106, 117],\n",
       " [140, 151],\n",
       " [162, 173],\n",
       " [41, 52],\n",
       " [66, 77],\n",
       " [31, 42],\n",
       " [66, 77],\n",
       " [108, 119],\n",
       " [143, 154],\n",
       " [91, 102],\n",
       " [19, 30],\n",
       " [45, 56],\n",
       " [82, 93],\n",
       " [25, 36],\n",
       " [49, 60],\n",
       " [73, 84],\n",
       " [102, 113],\n",
       " [137, 148],\n",
       " [164, 175],\n",
       " [203, 214],\n",
       " [26, 37],\n",
       " [64, 75],\n",
       " [26, 37],\n",
       " [62, 73],\n",
       " [91, 102],\n",
       " [31, 42],\n",
       " [68, 79],\n",
       " [27, 38],\n",
       " [57, 68],\n",
       " [87, 98],\n",
       " [115, 126],\n",
       " [21, 32],\n",
       " [42, 53],\n",
       " [67, 78],\n",
       " [36, 47],\n",
       " [72, 83],\n",
       " [16, 27],\n",
       " [45, 56],\n",
       " [12, 23],\n",
       " [55, 66],\n",
       " [87, 98],\n",
       " [119, 130],\n",
       " [18, 29],\n",
       " [49, 60],\n",
       " [78, 89],\n",
       " [102, 113],\n",
       " [126, 137],\n",
       " [158, 169],\n",
       " [35, 46],\n",
       " [73, 84],\n",
       " [111, 122],\n",
       " [146, 157],\n",
       " [26, 37],\n",
       " [58, 69],\n",
       " [91, 102],\n",
       " [133, 144],\n",
       " [171, 182],\n",
       " [206, 217],\n",
       " [14, 25],\n",
       " [41, 52],\n",
       " [66, 77],\n",
       " [12, 23],\n",
       " [38, 49],\n",
       " [80, 91],\n",
       " [135, 146],\n",
       " [165, 176],\n",
       " [194, 205],\n",
       " [26, 37],\n",
       " [60, 71],\n",
       " [105, 116],\n",
       " [137, 148],\n",
       " [19, 30],\n",
       " [59, 70],\n",
       " [99, 110],\n",
       " [136, 147],\n",
       " [28, 39],\n",
       " [22, 33],\n",
       " [65, 76],\n",
       " [93, 104],\n",
       " [124, 135],\n",
       " [15, 26],\n",
       " [37, 48],\n",
       " [65, 76],\n",
       " [107, 118],\n",
       " [28, 39],\n",
       " [62, 73],\n",
       " [92, 103],\n",
       " [129, 140],\n",
       " [171, 182],\n",
       " [31, 42],\n",
       " [56, 67],\n",
       " [105, 116],\n",
       " [53, 64],\n",
       " [25, 36],\n",
       " [49, 60],\n",
       " [86, 97],\n",
       " [115, 126],\n",
       " [145, 156],\n",
       " [184, 195],\n",
       " [210, 221],\n",
       " [14, 25],\n",
       " [49, 60],\n",
       " [76, 87],\n",
       " [103, 114],\n",
       " [146, 157],\n",
       " [177, 188],\n",
       " [17, 28],\n",
       " [38, 49],\n",
       " [69, 80],\n",
       " [16, 27],\n",
       " [49, 60],\n",
       " [81, 92],\n",
       " [105, 116],\n",
       " [135, 146],\n",
       " [165, 176],\n",
       " [187, 198],\n",
       " [214, 225],\n",
       " [245, 256],\n",
       " [279, 290],\n",
       " [302, 313],\n",
       " [336, 347],\n",
       " [23, 34],\n",
       " [64, 75],\n",
       " [124, 135],\n",
       " [156, 167],\n",
       " [47, 58],\n",
       " [74, 85],\n",
       " [80, 91],\n",
       " [18, 29],\n",
       " [60, 71],\n",
       " [11, 22],\n",
       " [43, 54],\n",
       " [70, 81],\n",
       " [97, 108],\n",
       " [125, 136],\n",
       " [28, 39],\n",
       " [62, 73],\n",
       " [95, 106],\n",
       " [128, 139],\n",
       " [73, 84],\n",
       " [20, 31],\n",
       " [66, 77],\n",
       " [112, 123],\n",
       " [20, 31],\n",
       " [18, 29],\n",
       " [50, 61],\n",
       " [84, 95],\n",
       " [133, 144],\n",
       " [169, 180],\n",
       " [21, 32],\n",
       " [51, 62],\n",
       " [88, 99],\n",
       " [51, 62],\n",
       " [13, 24],\n",
       " [43, 54],\n",
       " [84, 95],\n",
       " [126, 137],\n",
       " [153, 164],\n",
       " [204, 215],\n",
       " [229, 240],\n",
       " [24, 35],\n",
       " [64, 75],\n",
       " [16, 27],\n",
       " [14, 25],\n",
       " [43, 54],\n",
       " [74, 85],\n",
       " [111, 122],\n",
       " [47, 58],\n",
       " [16, 27],\n",
       " [54, 65],\n",
       " [92, 103],\n",
       " [13, 24],\n",
       " [47, 58],\n",
       " [72, 83],\n",
       " [112, 123],\n",
       " [145, 156],\n",
       " [197, 208],\n",
       " [41, 52],\n",
       " [28, 39],\n",
       " [16, 27],\n",
       " [55, 66],\n",
       " [84, 95],\n",
       " [130, 141],\n",
       " [164, 175],\n",
       " [89, 100],\n",
       " [114, 125],\n",
       " [24, 35],\n",
       " [104, 115],\n",
       " [128, 139],\n",
       " [175, 186],\n",
       " [19, 30],\n",
       " [46, 57],\n",
       " [136, 147],\n",
       " [15, 26],\n",
       " [65, 76],\n",
       " [109, 120],\n",
       " [17, 28],\n",
       " [47, 58],\n",
       " [80, 91],\n",
       " [119, 130],\n",
       " [154, 165],\n",
       " [25, 36],\n",
       " [78, 89],\n",
       " [110, 121],\n",
       " [49, 60],\n",
       " [13, 24],\n",
       " [50, 61],\n",
       " [23, 34],\n",
       " [50, 61],\n",
       " [83, 94],\n",
       " [120, 131],\n",
       " [154, 165],\n",
       " [30, 41],\n",
       " [70, 81],\n",
       " [97, 108],\n",
       " [12, 23],\n",
       " [49, 60],\n",
       " [79, 90],\n",
       " [108, 119],\n",
       " [137, 148],\n",
       " [166, 177],\n",
       " [18, 29],\n",
       " [39, 50],\n",
       " [66, 77],\n",
       " [91, 102],\n",
       " [14, 25],\n",
       " [51, 62],\n",
       " [82, 93],\n",
       " [103, 114],\n",
       " [125, 136],\n",
       " [151, 162],\n",
       " [181, 192],\n",
       " [224, 235],\n",
       " [252, 263],\n",
       " [290, 301],\n",
       " [88, 99],\n",
       " [23, 34],\n",
       " [51, 62],\n",
       " [86, 97],\n",
       " [126, 137],\n",
       " [149, 160],\n",
       " [172, 183],\n",
       " [15, 26],\n",
       " [52, 63],\n",
       " [83, 94],\n",
       " [20, 31],\n",
       " [57, 68],\n",
       " [81, 92],\n",
       " [108, 119],\n",
       " [133, 144],\n",
       " [160, 171],\n",
       " [181, 192],\n",
       " [204, 215],\n",
       " [17, 28],\n",
       " [65, 76],\n",
       " [109, 120],\n",
       " [138, 149],\n",
       " [167, 178],\n",
       " [14, 25],\n",
       " [58, 69],\n",
       " [28, 39],\n",
       " [75, 86],\n",
       " [122, 133],\n",
       " [165, 176],\n",
       " [26, 37],\n",
       " [64, 75],\n",
       " [17, 28],\n",
       " [66, 77],\n",
       " [94, 105],\n",
       " [135, 146],\n",
       " [173, 184],\n",
       " [201, 212],\n",
       " [27, 38],\n",
       " [64, 75],\n",
       " [90, 101],\n",
       " [135, 146],\n",
       " [11, 22],\n",
       " [32, 43],\n",
       " [52, 63],\n",
       " [71, 82],\n",
       " [103, 114],\n",
       " [130, 141],\n",
       " [156, 167],\n",
       " [65, 76],\n",
       " [45, 56],\n",
       " [88, 99],\n",
       " [27, 38],\n",
       " [55, 66],\n",
       " [88, 99],\n",
       " [113, 124],\n",
       " [28, 39],\n",
       " [57, 68],\n",
       " [80, 91],\n",
       " [119, 130],\n",
       " [153, 164],\n",
       " [21, 32],\n",
       " [48, 59],\n",
       " [83, 94],\n",
       " [118, 129],\n",
       " [41, 52],\n",
       " [68, 79],\n",
       " [19, 30],\n",
       " [13, 24],\n",
       " [51, 62],\n",
       " [12, 23],\n",
       " [51, 62],\n",
       " [86, 97],\n",
       " [105, 116],\n",
       " [127, 138],\n",
       " [148, 159],\n",
       " [176, 187],\n",
       " [18, 29],\n",
       " [49, 60],\n",
       " [79, 90],\n",
       " [112, 123],\n",
       " [148, 159],\n",
       " [190, 201],\n",
       " [230, 241],\n",
       " [21, 32],\n",
       " [49, 60],\n",
       " [96, 107],\n",
       " [44, 55],\n",
       " [65, 76],\n",
       " [15, 26],\n",
       " [41, 52],\n",
       " [66, 77],\n",
       " [98, 109],\n",
       " [24, 35],\n",
       " [47, 58],\n",
       " [72, 83],\n",
       " [111, 122],\n",
       " [154, 165],\n",
       " [190, 201],\n",
       " [15, 26],\n",
       " [46, 57],\n",
       " [80, 91],\n",
       " [131, 142],\n",
       " [36, 47],\n",
       " [88, 99],\n",
       " [133, 144],\n",
       " [20, 31],\n",
       " [23, 34],\n",
       " [69, 80],\n",
       " [95, 106],\n",
       " [135, 146],\n",
       " [166, 177],\n",
       " [195, 206],\n",
       " [222, 233],\n",
       " [252, 263],\n",
       " [20, 31],\n",
       " [48, 59],\n",
       " [62, 73],\n",
       " [15, 26],\n",
       " [46, 57],\n",
       " [79, 90],\n",
       " [121, 132],\n",
       " [169, 180],\n",
       " [216, 227],\n",
       " [34, 45],\n",
       " [90, 101],\n",
       " [17, 28],\n",
       " [52, 63],\n",
       " [82, 93],\n",
       " [107, 118],\n",
       " [148, 159],\n",
       " [182, 193],\n",
       " [20, 31],\n",
       " [56, 67],\n",
       " [87, 98],\n",
       " [112, 123],\n",
       " [145, 156],\n",
       " [172, 183],\n",
       " [196, 207],\n",
       " [19, 30],\n",
       " [55, 66],\n",
       " [92, 103],\n",
       " [21, 32],\n",
       " [45, 56],\n",
       " [71, 82],\n",
       " [109, 120],\n",
       " [151, 162],\n",
       " [61, 72],\n",
       " [97, 108],\n",
       " [33, 44],\n",
       " [64, 75],\n",
       " [92, 103],\n",
       " [138, 149],\n",
       " [112, 123],\n",
       " [41, 52],\n",
       " [29, 40],\n",
       " [72, 83],\n",
       " [123, 134],\n",
       " [160, 171],\n",
       " [25, 36],\n",
       " [64, 75],\n",
       " [111, 122],\n",
       " [141, 152],\n",
       " [31, 42],\n",
       " [68, 79],\n",
       " [111, 122],\n",
       " [146, 157],\n",
       " [173, 184],\n",
       " [196, 207],\n",
       " [19, 30],\n",
       " [44, 55],\n",
       " [53, 64],\n",
       " [13, 24],\n",
       " [46, 57],\n",
       " [81, 92],\n",
       " [109, 120],\n",
       " [29, 40],\n",
       " [61, 72],\n",
       " [86, 97],\n",
       " [112, 123],\n",
       " [155, 166],\n",
       " [79, 90],\n",
       " [29, 40],\n",
       " [64, 75],\n",
       " [100, 111],\n",
       " [35, 46],\n",
       " [24, 35],\n",
       " [57, 68],\n",
       " [79, 90],\n",
       " [124, 135],\n",
       " [148, 159],\n",
       " [186, 197],\n",
       " [71, 82],\n",
       " [96, 107],\n",
       " [21, 32],\n",
       " [57, 68],\n",
       " [83, 94],\n",
       " [117, 128],\n",
       " [145, 156],\n",
       " [20, 31],\n",
       " [52, 63],\n",
       " [87, 98],\n",
       " [133, 144],\n",
       " [13, 24],\n",
       " [41, 52],\n",
       " [70, 81],\n",
       " [102, 113],\n",
       " [26, 37],\n",
       " [67, 78],\n",
       " [109, 120],\n",
       " [31, 42],\n",
       " [62, 73],\n",
       " [19, 30],\n",
       " [53, 64],\n",
       " [81, 92],\n",
       " [27, 38],\n",
       " [69, 80],\n",
       " [104, 115],\n",
       " [11, 22],\n",
       " [39, 50],\n",
       " [98, 109],\n",
       " [129, 140],\n",
       " [165, 176],\n",
       " [195, 206],\n",
       " [14, 25],\n",
       " [37, 48],\n",
       " [66, 77],\n",
       " [102, 113],\n",
       " [75, 86],\n",
       " [28, 39],\n",
       " [55, 66],\n",
       " [20, 31],\n",
       " [52, 63],\n",
       " [15, 26],\n",
       " [53, 64],\n",
       " [81, 92],\n",
       " [117, 128],\n",
       " [144, 155],\n",
       " [184, 195],\n",
       " [208, 219],\n",
       " [27, 38],\n",
       " [52, 63],\n",
       " [16, 27],\n",
       " [53, 64],\n",
       " [88, 99],\n",
       " [135, 146],\n",
       " [171, 182],\n",
       " [93, 104],\n",
       " [19, 30],\n",
       " [56, 67],\n",
       " [6, 17],\n",
       " [47, 58],\n",
       " [78, 89],\n",
       " [109, 120],\n",
       " [140, 151],\n",
       " [164, 175],\n",
       " [25, 36],\n",
       " [55, 66],\n",
       " [94, 105],\n",
       " [134, 145],\n",
       " [195, 206],\n",
       " [26, 37],\n",
       " [56, 67],\n",
       " [92, 103],\n",
       " [17, 28],\n",
       " [42, 53],\n",
       " [80, 91],\n",
       " [143, 154],\n",
       " [166, 177],\n",
       " [22, 33],\n",
       " [81, 92],\n",
       " [32, 43],\n",
       " [69, 80],\n",
       " [101, 112],\n",
       " [33, 44],\n",
       " [69, 80],\n",
       " [106, 117],\n",
       " [168, 179],\n",
       " [13, 24],\n",
       " [44, 55],\n",
       " [76, 87],\n",
       " [101, 112],\n",
       " [123, 134],\n",
       " [160, 171],\n",
       " [17, 28],\n",
       " [47, 58],\n",
       " [71, 82],\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a324830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list_2 = [item for sublist in flat_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7655515e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flat_list_2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "914e2e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[273,\n",
       " 273,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 284,\n",
       " 284,\n",
       " 284,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 290,\n",
       " 291,\n",
       " 294,\n",
       " 295,\n",
       " 301,\n",
       " 302,\n",
       " 305,\n",
       " 311,\n",
       " 313,\n",
       " 322,\n",
       " 336,\n",
       " 347]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_list_2[-25:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae885fb0",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b5301f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 0\n",
    "MAX_SPAN = 0\n",
    "\n",
    "for split in ['train', 'test', 'validation']:\n",
    "    \n",
    "    for col_name in ['am_spans_new', 'ac_spans_new', 'feature_spans_new']:\n",
    "        \n",
    "        for x in dataset[split][col_name]:\n",
    "            \n",
    "            if max(x,key=itemgetter(1))[1] > MAX_SPAN:\n",
    "                \n",
    "                MAX_SPAN = max(x,key=itemgetter(1))[1]\n",
    "                MAX_SPAN = min(MAX_SPAN, tokenizer.model_max_length - 2)\n",
    "            \n",
    "            if len(x) > MAX_LENGTH:\n",
    "                \n",
    "                MAX_LENGTH = len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e73da04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SPAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "808c9919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fc960f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding(batch, padding_target):    \n",
    "    \n",
    "    if padding_target == 'am_spans':\n",
    "        \n",
    "        col_name = 'am_spans_new'\n",
    "        padding_val = [[-1,-1]]\n",
    "        max_length = MAX_LENGTH\n",
    "        \n",
    "    elif padding_target == 'ac_spans':\n",
    "        \n",
    "        col_name = 'ac_spans_new'\n",
    "        padding_val = [[-1,-1]]\n",
    "        max_length = MAX_LENGTH\n",
    "        \n",
    "    elif padding_target == 'fts_spans':\n",
    "        \n",
    "        col_name = 'feature_spans_new'\n",
    "        padding_val = [[-1,-1]]\n",
    "        max_length = MAX_LENGTH\n",
    "        \n",
    "    elif padding_target == 'label':\n",
    "    \n",
    "        col_name = 'paragraph_labels'\n",
    "        padding_val = [-100] # -1 previously       \n",
    "        max_length = MAX_LENGTH # max([len(l) for l in batch[col_name]]) # cause some batch had 4 x 10\n",
    "\n",
    "    padded_spans = []\n",
    "\n",
    "    for idx, span in enumerate(batch[col_name]):\n",
    "\n",
    "        padded_span = batch[col_name][idx] + (max_length - len(span)) * padding_val\n",
    "        padded_spans.append(padded_span)\n",
    "\n",
    "    return padded_spans         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f37c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_spans(am_spans_ll, ac_spans_ll, fts_spans_ll):\n",
    "    \n",
    "    spans_ll = []\n",
    "    \n",
    "    for am_spans, ac_spans, fts_spans in zip(am_spans_ll, ac_spans_ll, fts_spans_ll):\n",
    "        \n",
    "        spans = []\n",
    "        \n",
    "        for am_span, ac_span, fts_span in zip(am_spans, ac_spans, fts_spans):\n",
    "            \n",
    "            for idx in [0,1]:\n",
    "                \n",
    "                if am_span[idx] > MAX_SPAN:\n",
    "                    am_span[idx] = MAX_SPAN\n",
    "                if ac_span[idx] > MAX_SPAN:\n",
    "                    ac_span[idx] = MAX_SPAN\n",
    "                if fts_span[idx] > MAX_SPAN:\n",
    "                    fts_span[idx] = MAX_SPAN\n",
    "\n",
    "            span = [am_span, ac_span, fts_span]\n",
    "            spans.extend(span)\n",
    "            \n",
    "        spans_ll.append(spans)\n",
    "\n",
    "    return spans_ll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f42610c",
   "metadata": {},
   "source": [
    "### tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "646b4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length = 200 for use in the max_length in the tokenizer so that the things are of equal dim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7844334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    \n",
    "    tokenized_text = tokenizer(batch['paragraph_w_fts_as_txt'], truncation=True, padding=True, max_length=512)\n",
    "    tokenized_text['label'] = get_padding(batch, 'label')\n",
    "    tokenized_text['am_spans'] = get_padding(batch, 'am_spans')\n",
    "    tokenized_text['ac_spans'] = get_padding(batch, 'ac_spans')\n",
    "    tokenized_text['fts_spans'] = get_padding(batch, 'fts_spans')\n",
    "    tokenized_text['spans'] = get_combined_spans(tokenized_text['am_spans'], tokenized_text['ac_spans'], tokenized_text['fts_spans'])      \n",
    "    \n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e56aa58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize at 0x7f6e89bc33a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018830537796020508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798ed841981740528c04ffeb99d9d17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018155336380004883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7ca40bbddb44a78e4a7d7950465e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019657611846923828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb4ae0802fb455cb0ce8f7700804d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize, batched=True, batch_size=len(dataset['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf0d0a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ac_spans', 'ac_spans_new', 'am_spans', 'am_spans_new', 'attention_mask', 'essay_nr', 'feature_spans_new', 'fts_spans', 'input_ids', 'label', 'paragraph', 'paragraph_ac_spans', 'paragraph_am_spans', 'paragraph_components_list', 'paragraph_fts_as_txt_list', 'paragraph_labels', 'paragraph_labels_list', 'paragraph_markers_list', 'paragraph_w_fts_as_txt', 'sanity_new', 'spans', 'split', 'token_type_ids'],\n",
       "        num_rows: 1088\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ac_spans', 'ac_spans_new', 'am_spans', 'am_spans_new', 'attention_mask', 'essay_nr', 'feature_spans_new', 'fts_spans', 'input_ids', 'label', 'paragraph', 'paragraph_ac_spans', 'paragraph_am_spans', 'paragraph_components_list', 'paragraph_fts_as_txt_list', 'paragraph_labels', 'paragraph_labels_list', 'paragraph_markers_list', 'paragraph_w_fts_as_txt', 'sanity_new', 'spans', 'split', 'token_type_ids'],\n",
       "        num_rows: 358\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ac_spans', 'ac_spans_new', 'am_spans', 'am_spans_new', 'attention_mask', 'essay_nr', 'feature_spans_new', 'fts_spans', 'input_ids', 'label', 'paragraph', 'paragraph_ac_spans', 'paragraph_am_spans', 'paragraph_components_list', 'paragraph_fts_as_txt_list', 'paragraph_labels', 'paragraph_labels_list', 'paragraph_markers_list', 'paragraph_w_fts_as_txt', 'sanity_new', 'spans', 'split', 'token_type_ids'],\n",
       "        num_rows: 273\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "693f58aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0],\n",
       " [2, 21],\n",
       " [23, 34],\n",
       " [-1, -1],\n",
       " [41, 57],\n",
       " [59, 70],\n",
       " [-1, -1],\n",
       " [73, 108],\n",
       " [110, 121],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1],\n",
       " [-1, -1]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['spans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a958dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train'][0]['spans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d77968d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][1]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "756eaf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ac_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'ac_spans_new': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'am_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'am_spans_new': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'essay_nr': Value(dtype='string', id=None),\n",
       " 'feature_spans_new': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'fts_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'label': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'paragraph': Value(dtype='string', id=None),\n",
       " 'paragraph_ac_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_am_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_components_list': Sequence(feature=Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_fts_as_txt_list': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'paragraph_labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'paragraph_labels_list': Sequence(feature=Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_markers_list': Sequence(feature=Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_w_fts_as_txt': Value(dtype='string', id=None),\n",
       " 'sanity_new': Value(dtype='bool', id=None),\n",
       " 'spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'split': Value(dtype='string', id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "728fb8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ac_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'ac_spans_new': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'am_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'am_spans_new': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'essay_nr': Value(dtype='string', id=None),\n",
       " 'feature_spans_new': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'fts_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'label': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'paragraph': Value(dtype='string', id=None),\n",
       " 'paragraph_ac_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_am_spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_components_list': Sequence(feature=Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_fts_as_txt_list': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'paragraph_labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'paragraph_labels_list': Sequence(feature=Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_markers_list': Sequence(feature=Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'paragraph_w_fts_as_txt': Value(dtype='string', id=None),\n",
       " 'sanity_new': Value(dtype='bool', id=None),\n",
       " 'spans': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None),\n",
       " 'split': Value(dtype='string', id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79ade9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test'].features['spans'] = datasets.Array2D(shape=(36, 2), dtype=\"int32\")\n",
    "dataset['train'].features['spans'] = datasets.Array2D(shape=(36, 2), dtype=\"int32\")\n",
    "dataset['validation'].features['spans'] = datasets.Array2D(shape=(36, 2), dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f41cade1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018975019454956055,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8fe5475b3f44edb3121204bb161cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016875505447387695,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc8e11583654422b6e15c0203c7bf62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01758861541748047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4197b3770b2a43958496a46fdb3a037c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(lambda batch: batch, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09a97ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'token_type_ids', 'spans', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360dfbca",
   "metadata": {},
   "source": [
    "## span representation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e8cd770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minus_one(t):\n",
    "    \n",
    "    return torch.where(t == 0, 0, t-1)\n",
    "\n",
    "def plus_one(t):\n",
    "    \n",
    "    return torch.where(t >= MAX_SPAN, MAX_SPAN, t+1) # changed from t == MAX_SPAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0500d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span_representations(outputs, spans):\n",
    "    \n",
    "    #print('spans shape', spans.shape)\n",
    "    \n",
    "    batch_size = spans.shape[0]\n",
    "    \n",
    "    nr_span_indices = spans.shape[1]\n",
    "    \n",
    "    #print('nr span indices', nr_span_indices)\n",
    "    \n",
    "    # nr_span_indices = 24 # xxx. hardcode just to check\n",
    "    \n",
    "    idx_l_ams = range(0, nr_span_indices, 3) # [0,2,4,6 etc]\n",
    "    idx_l_acs = range(1, nr_span_indices, 3) # [1,3,5,7 etc]\n",
    "    idx_l_fts = range(2, nr_span_indices, 3)\n",
    "    \n",
    "    am_spans = spans[:, idx_l_ams, :] + 1 # adds 1 to all span indices (both am and ac) to offset for the CLS token in the input_ids.\n",
    "    ac_spans = spans[:, idx_l_acs, :] + 1\n",
    "    fts_spans = spans[:, idx_l_fts, :] + 1\n",
    "    \n",
    "    \n",
    "    # fix for [-1, +1] problem\n",
    "    \n",
    "    am_spans_minus_one = minus_one(am_spans) # xxx. added to solve bug 2\n",
    "    am_spans_plus_one = plus_one(am_spans) # xxx. added to solve bug 2\n",
    "    \n",
    "    ac_spans_minus_one = minus_one(ac_spans) # xxx. added to solve bug 2\n",
    "    ac_spans_plus_one = plus_one(ac_spans) # xxx. added to solve bug 2\n",
    "    \n",
    "    fts_spans_minus_one = minus_one(fts_spans) # xxx. added to solve bug 2\n",
    "    fts_spans_plus_one = plus_one(fts_spans) # xxx. added to solve bug 2\n",
    "    \n",
    "    \n",
    "    am_spans = am_spans.flatten(start_dim=1)\n",
    "    ac_spans = ac_spans.flatten(start_dim=1)\n",
    "    fts_spans = fts_spans.flatten(start_dim=1)\n",
    "    \n",
    "    nr_adus = ac_spans.shape[1] // 2\n",
    "    \n",
    "    \n",
    "    am_spans_minus_one = am_spans_minus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    am_spans_plus_one = am_spans_plus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    \n",
    "    ac_spans_minus_one = ac_spans_minus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    ac_spans_plus_one = ac_spans_plus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    \n",
    "    fts_spans_minus_one = fts_spans_minus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    fts_spans_plus_one = fts_spans_plus_one.flatten(start_dim=1) # xxx. added to solve bug 2\n",
    "    \n",
    "    ############# FOR AMs #################\n",
    "    \n",
    "    outputs_am = outputs[:,am_spans,:]\n",
    "    #print('outputs am juste directly from outputs:', outputs_am.shape)\n",
    "    outputs_am = torch.cat([outputs_am[i,i,:,:] for i in range(batch_size)], dim=0)\n",
    "    outputs_am = outputs_am.reshape(batch_size, nr_adus * 2, -1)\n",
    "    \n",
    "    #print('outputs_ am after reshape:', outputs_am.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    outputs_am_minus_one = outputs[:,am_spans_minus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_am_minus_one = torch.cat([outputs_am_minus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_am_minus_one = outputs_am_minus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    outputs_am_plus_one = outputs[:,am_spans_plus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_am_plus_one = torch.cat([outputs_am_plus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_am_plus_one = outputs_am_plus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Now that we have outputs_am i.e. outputs at am_span indices, now create the four Kuri forumlas for AMs\n",
    "    \n",
    "    # ============== the corrected 1st one =================== \n",
    "    \n",
    "    outputs_am_first_term = torch.cat([outputs_am[:,i+1,:] - outputs_am_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1) # i + 1 here means j in kuri, i here means i in kuri\n",
    "    outputs_am_first_term = outputs_am_first_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "     # ============== the corrected 2nd one ==================\n",
    "    \n",
    "    outputs_am_second_term = torch.cat([outputs_am[:,i,:] - outputs_am_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1) # changed + 2 to + 1 to make it run # changed from +1 to +2 to ensure +2 is not a problem for AMs\n",
    "    outputs_am_second_term = outputs_am_second_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "    \n",
    "        # ============== the corrected third one ================== \n",
    "    \n",
    "    outputs_am_third_term = torch.cat([outputs_am_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_am_third_term = outputs_am_third_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "\n",
    "        # ============== the corrected fourth one ==================\n",
    "    \n",
    "    outputs_am_fourth_term = torch.cat([outputs_am_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1) # changed + 2 to + 1 to make it run # changed from +1 to +2 to ensure +2 is not a problem for AMs\n",
    "    outputs_am_fourth_term = outputs_am_fourth_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "    # ============== NOW CONCATENATE THEM =========\n",
    "    \n",
    "    \n",
    "    am_minus_representations = torch.cat([outputs_am_first_term, outputs_am_second_term, outputs_am_third_term, outputs_am_fourth_term], dim=-1)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### am minus span representation according to kuribayashi paper is now above.\n",
    "    \n",
    "    \n",
    "    outputs_ac = outputs[:,ac_spans,:]\n",
    "    outputs_ac = torch.cat([outputs_ac[i,i,:,:] for i in range(batch_size)], dim=0)\n",
    "    outputs_ac = outputs_ac.reshape(batch_size, nr_adus * 2, -1)\n",
    "    \n",
    "    \n",
    "    outputs_ac_minus_one = outputs[:,ac_spans_minus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_ac_minus_one = torch.cat([outputs_ac_minus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_ac_minus_one = outputs_ac_minus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    outputs_ac_plus_one = outputs[:,ac_spans_plus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_ac_plus_one = torch.cat([outputs_ac_plus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_ac_plus_one = outputs_ac_plus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    ### Now that we have outputs_ac i.e. outputs at ac_span indices, now create the four Kuri forumlas for ACs\n",
    "    \n",
    "    \n",
    "    # ============== the corrected first one ===================\n",
    "    \n",
    "    outputs_ac_first_term = torch.cat([outputs_ac[:,i+1,:] - outputs_ac_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_ac_first_term = outputs_ac_first_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "        # ============== the correct second one ==================\n",
    "    \n",
    "    outputs_ac_second_term = torch.cat([outputs_ac[:,i,:] - outputs_ac_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1) # changed + 2 to + 1 to make it run\n",
    "    outputs_ac_second_term = outputs_ac_second_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "    \n",
    "    # ============== the corrected third term ==================\n",
    "    \n",
    "    outputs_ac_third_term = torch.cat([outputs_ac_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_ac_third_term = outputs_ac_third_term.reshape(batch_size, -1, 768)\n",
    "\n",
    "    \n",
    "     # ============== the corrected fourth term ================== xxx. for .788\n",
    "    \n",
    "    outputs_ac_fourth_term = torch.cat([outputs_ac_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1) # changed + 2 to + 1 to make it run\n",
    "    outputs_ac_fourth_term = outputs_ac_fourth_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "    # ============== NOW CONCATENATE THEM =========\n",
    "    \n",
    "    \n",
    "    ac_minus_representations = torch.cat([outputs_ac_first_term, outputs_ac_second_term, outputs_ac_third_term, outputs_ac_fourth_term], dim=-1)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### ac minus span representation according to kuribayashi paper is now above.\n",
    "    \n",
    "    \n",
    "     ############# FOR Fts #################\n",
    "    \n",
    "    outputs_fts = outputs[:,am_spans,:] # am spans for checking\n",
    "    #print('outputs fts juste directly from the outputs:', outputs_fts.shape)\n",
    "    outputs_fts = torch.cat([outputs_fts[i,i,:,:] for i in range(batch_size)], dim=0)\n",
    "    outputs_fts = outputs_fts.reshape(batch_size, nr_adus * 2, -1)\n",
    "    \n",
    "    #print('output fts after reshape:', outputs_fts.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    outputs_fts_minus_one = outputs[:,fts_spans_minus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_fts_minus_one = torch.cat([outputs_fts_minus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_fts_minus_one = outputs_fts_minus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    outputs_fts_plus_one = outputs[:,fts_spans_plus_one,:] # xxx. added to solve bug 2\n",
    "    outputs_fts_plus_one = torch.cat([outputs_fts_plus_one[i,i,:,:] for i in range(batch_size)], dim=0) # xxx. added to solve bug 2\n",
    "    outputs_fts_plus_one = outputs_fts_plus_one.reshape(batch_size, nr_adus * 2, -1) # xxx. added to solve bug 2\n",
    "    \n",
    "    #print('outputs_fts_plus_one', outputs_fts_plus_one.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Now that we have outputs_am i.e. outputs at am_span indices, now create the four Kuri forumlas for AMs\n",
    "    \n",
    "    # ============== (batch_size x nr_adus x 768) =================== \n",
    "    \n",
    "    outputs_fts_first_term = torch.cat([outputs_fts[:,i+1,:] - outputs_fts_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1) # i + 1 here means j in kuri, i here means i in kuri\n",
    "    outputs_fts_first_term = outputs_fts_first_term.reshape(batch_size, -1, 768)\n",
    "    #print('outputs_fts_first_term:', outputs_fts_first_term.shape)\n",
    "    \n",
    "     # ============== the corrected 2nd one ==================\n",
    "    \n",
    "    outputs_fts_second_term = torch.cat([outputs_fts[:,i,:] - outputs_fts_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_fts_second_term = outputs_fts_second_term.reshape(batch_size, -1, 768)\n",
    "    #print('outputs_fts_second_term:', outputs_fts_second_term.shape)\n",
    "    \n",
    "        # ============== the corrected third one ================== \n",
    "    \n",
    "    outputs_fts_third_term = torch.cat([outputs_fts_minus_one[:,i,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_fts_third_term = outputs_fts_third_term.reshape(batch_size, -1, 768)\n",
    "    \n",
    "\n",
    "        # ============== the corrected fourth one ==================\n",
    "    \n",
    "    outputs_fts_fourth_term = torch.cat([outputs_fts_plus_one[:,i+1,:] for i in range(0, nr_adus * 2, 2)], dim=1)\n",
    "    outputs_fts_fourth_term = outputs_fts_fourth_term.reshape(batch_size, -1, 768)\n",
    "    #print('outputs_fts_fourth_term:', outputs_fts_fourth_term.shape)\n",
    "    \n",
    "    # ============== NOW CONCATENATE THEM =========\n",
    "    \n",
    "    \n",
    "    fts_minus_representations = torch.cat([outputs_fts_first_term, outputs_fts_second_term, outputs_fts_third_term, outputs_fts_fourth_term], dim=-1)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### fts minus span representation according to kuribayashi paper is now above.\n",
    "    \n",
    "#     print('am rep final:', am_minus_representations.shape)\n",
    "#     print('ac rep final:', ac_minus_representations.shape)\n",
    "#     print('fts rep final:', fts_minus_representations.shape)\n",
    "    \n",
    "\n",
    "    \n",
    "    return am_minus_representations, ac_minus_representations, fts_minus_representations                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554d23d4",
   "metadata": {},
   "source": [
    "### span representation function old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac40ed20",
   "metadata": {},
   "source": [
    "## custom BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a6a3e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBERTKuri(nn.Module):\n",
    "\n",
    "    def __init__(self, first_model, model_am, model_ac, model_fts, nr_classes):\n",
    "        \n",
    "        super(CustomBERTKuri, self).__init__()\n",
    "        \n",
    "        self.first_model = first_model\n",
    "        \n",
    "        self.intermediate_linear_am = nn.Linear(3072, 768)\n",
    "        self.intermediate_linear_ac = nn.Linear(3072, 768) \n",
    "        self.intermediate_linear_fts = nn.Linear(3072, 768)\n",
    "        \n",
    "        self.model_am = model_am\n",
    "        self.model_ac = model_ac\n",
    "        self.model_fts = model_fts\n",
    "        \n",
    "        self.nr_classes = nr_classes\n",
    "                \n",
    "        self.fc = nn.Linear(self.model_am.config.hidden_size + self.model_ac.config.hidden_size + self.model_fts.config.hidden_size, self.nr_classes)\n",
    "        # self.fc = nn.Linear(self.model_am.config.hidden_size + self.model_ac.config.hidden_size, self.nr_classes) \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        batch_tokenized, batch_spans = inputs \n",
    "        #outputs = self.first_model(batch_tokenized)[0]\n",
    "        outputs = self.first_model(batch_tokenized, output_hidden_states=True)[1][12] # ** removed to correct error.\n",
    "        # spans = batch_spans # remove this spans thing cause we are now giving it just the spans themselves.\n",
    "        am_minus_representations, ac_minus_representations, fts_minus_representations = get_span_representations(outputs, batch_spans)\n",
    "#         print('passed and gotten reps for all three successfully!')\n",
    "#         print('am rep final in model:', am_minus_representations.shape)\n",
    "#         print('ac rep final in model:', ac_minus_representations.shape)\n",
    "#         print('fts rep final in model:', fts_minus_representations.shape)\n",
    "        #am_minus_representations, ac_minus_representations = get_span_representations(outputs, batch_spans)\n",
    "        \n",
    "        # am_minus_representations = \n",
    "        \n",
    "        \n",
    "        #print('am minus rep:', am_minus_representations.shape)\n",
    "        #print('ac minus rep:', ac_minus_representations.shape)\n",
    "        #print('linear layer shape:', self.intermediate_linear_am.in_features)\n",
    "\n",
    "        am_minus_representations = self.intermediate_linear_am(am_minus_representations)\n",
    "        #print('passed first linear')\n",
    "        ac_minus_representations = self.intermediate_linear_ac(ac_minus_representations)\n",
    "        #print('passed second linear')\n",
    "        fts_minus_representations = self.intermediate_linear_fts(fts_minus_representations)\n",
    "        #print('passed third linear')\n",
    "        \n",
    "        #print('am minus rep:', am_minus_representations.shape)\n",
    "        #print('ac minus rep:', ac_minus_representations.shape)\n",
    "        #print('fts minus rep:', fts_minus_representations.shape)\n",
    "\n",
    "        output_model_am = self.model_am(inputs_embeds = am_minus_representations)[0]\n",
    "        output_model_ac = self.model_ac(inputs_embeds = ac_minus_representations)[0]\n",
    "        output_model_fts = self.model_fts(inputs_embeds = fts_minus_representations)[0]\n",
    "\n",
    "        adu_representations = torch.cat([output_model_am, output_model_ac, output_model_fts], dim=-1)\n",
    "        #adu_representations = torch.cat([output_model_am, output_model_ac], dim=-1)\n",
    "        # print(\"adu rep:\", adu_representations.shape)\n",
    "        output = self.fc(adu_representations)\n",
    "        # print(\"model class output avant reshape:\", output.shape)\n",
    "        # output = output.reshape(-1, self.nr_classes)\n",
    "        # print(\"model class output apres:\", output.shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31aa372",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99155c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 40\n",
    "BATCH_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9b87011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first_model = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))\n",
    "first_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "# first_model.load_state_dict(torch.load('/notebooks/KURI-BERT/notebooks/full_formula_w_fts/icann_finetuned_work/link_identification_finetuned_model_new.pth'))\n",
    "first_model.load_state_dict(torch.load('/notebooks/KURI-BERT/notebooks/full_formula_w_fts/icann_finetuned_work/link_identification_finetuned_model_new_single.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa531298",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_am = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffe7a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ac = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41ff0849",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fts = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8bc2517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_model = CustomBERTKuri(first_model, model_am, model_ac, model_fts, 3)\n",
    "custom_model = CustomBERTKuri(first_model, model_am, model_ac, model_fts, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0dc05d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomBERTKuri(\n",
       "  (first_model): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       "  (intermediate_linear_am): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (intermediate_linear_ac): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (intermediate_linear_fts): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (model_am): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (model_ac): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (model_fts): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=2304, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "828cf348",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(ignore_index=- 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c178b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(custom_model.parameters(), lr=0.0035111917342151295)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b0044b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.8738174228603844e-05\n",
    "# 0.008111308307896872\n",
    "# best learning rate found by the whole leslie business\n",
    "# new best LR found= 9.999999999999997e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a3b8ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_BATCHES = len(dataset['train']) / BATCH_SIZE\n",
    "num_training_steps = NB_EPOCHS * NR_BATCHES\n",
    "num_warmup_steps = int(0.2 * num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ab77b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_lambda(current_step: int):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        return max(\n",
    "            0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        )\n",
    "\n",
    "    # return LambdaLR(optimizer, lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bce3fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented for LR Finder. remove it from optimizer.\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf84b0",
   "metadata": {},
   "source": [
    "### create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "264f6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset['train'], batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset['validation'], batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "314b7fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xxx. delete datasets for memory work\n",
    "# del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "004afc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(list_of_lists):\n",
    "    return [x for sublist in list_of_lists for x in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a1943b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dummy_labels(test_preds, test_labels):\n",
    "    \n",
    "    idxes = []\n",
    "    test_labels_l = []\n",
    "    for idx, val in enumerate(test_labels):\n",
    "        if val != -100:\n",
    "            idxes.append(idx)\n",
    "            test_labels_l.append(val)\n",
    "    \n",
    "    test_preds_l = []\n",
    "    for idx, val in enumerate(test_preds):\n",
    "        for good_idx in idxes:\n",
    "            if idx == good_idx:\n",
    "                test_preds_l.append(val)\n",
    "        \n",
    "    return test_preds_l, test_labels_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5dcf07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, b in enumerate(train_dataloader):\n",
    "    if i == 40:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "829954c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'input_ids': tensor([[  101,  3225,  2007,  ...,     0,     0,     0],\n",
       "         [  101,  1999,  7091,  ...,     0,     0,     0],\n",
       "         [  101,  2028,  3114,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  2174,  1010,  ...,     0,     0,     0],\n",
       "         [  101, 15847,  1010,  ...,     0,     0,     0],\n",
       "         [  101,  3452,  1010,  ...,     0,     0,     0]]),\n",
       " 'label': tensor([[   1,    1,    1,    0,    1, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    1,    1,    0, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    1,    0,    1, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    1,    1,    1, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    1,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    1,    1,    0, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    0,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    1,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   1,    1,    1,    1,    0, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    1,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   1,    0,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   1,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    1,    1,    1,    0, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    1,    1,    0,    1, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   0,    1,    1,    1,    1, -100, -100, -100, -100, -100, -100, -100],\n",
       "         [   1,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]),\n",
       " 'spans': tensor([[[-1, -1],\n",
       "          [ 0, 15],\n",
       "          [17, 28],\n",
       "          ...,\n",
       "          [-1, -1],\n",
       "          [-1, -1],\n",
       "          [-1, -1]],\n",
       " \n",
       "         [[ 0,  1],\n",
       "          [ 7, 16],\n",
       "          [18, 29],\n",
       "          ...,\n",
       "          [-1, -1],\n",
       "          [-1, -1],\n",
       "          [-1, -1]],\n",
       " \n",
       "         [[-1, -1],\n",
       "          [ 4, 21],\n",
       "          [23, 34],\n",
       "          ...,\n",
       "          [-1, -1],\n",
       "          [-1, -1],\n",
       "          [-1, -1]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0,  0],\n",
       "          [17, 42],\n",
       "          [44, 55],\n",
       "          ...,\n",
       "          [-1, -1],\n",
       "          [-1, -1],\n",
       "          [-1, -1]],\n",
       " \n",
       "         [[ 0,  0],\n",
       "          [ 2,  8],\n",
       "          [10, 21],\n",
       "          ...,\n",
       "          [-1, -1],\n",
       "          [-1, -1],\n",
       "          [-1, -1]],\n",
       " \n",
       "         [[ 0,  0],\n",
       "          [ 2, 32],\n",
       "          [34, 45],\n",
       "          ...,\n",
       "          [-1, -1],\n",
       "          [-1, -1],\n",
       "          [-1, -1]]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5c2b54",
   "metadata": {},
   "source": [
    "### training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "861deb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8944933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch_lr_finder import LRFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f2076a",
   "metadata": {},
   "source": [
    "### LR Finder Leslie Smith "
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f26b7e4",
   "metadata": {},
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, dataset):\n",
    "        'Initialization'\n",
    "        self.inputs = dataset['input_ids'], dataset['spans']\n",
    "        self.labels = dataset['label']\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        # ID = self.inputs[index]\n",
    "\n",
    "        # Load data and get label\n",
    "        X = self.inputs[0][index], self.inputs[1][index] \n",
    "        # X = torch.load('data/' + ID + '.pt')\n",
    "        y = self.labels[index]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93cf4a62",
   "metadata": {},
   "source": [
    "custom_train_dataset = CustomDataset(dataset['train'])\n",
    "custom_test_dataset = CustomDataset(dataset['test'])\n",
    "custom_val_dataset = CustomDataset(dataset['validation'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "887e0963",
   "metadata": {},
   "source": [
    "train_dataloader = DataLoader(custom_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(custom_test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(custom_val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e016ae1b",
   "metadata": {},
   "source": [
    "class CustomCrossEntropyLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss(ignore_index=- 100)\n",
    "        \n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        input = input.flatten(0,1) \n",
    "        target = target.flatten()\n",
    "        return self.loss.forward(input, target)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75fc7a42",
   "metadata": {},
   "source": [
    "loss = CustomCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd0d71e5",
   "metadata": {},
   "source": [
    "optimizer = torch.optim.AdamW(custom_model.parameters(), lr=1e-8, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b293aef",
   "metadata": {},
   "source": [
    "lr_finder = LRFinder(custom_model, optimizer, loss, device=device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f492beb9",
   "metadata": {},
   "source": [
    "lr_finder.range_test(train_dataloader, val_loader=val_dataloader, step_mode='exp')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3a85ea5",
   "metadata": {},
   "source": [
    "lr_finder.plot() # to inspect the loss-learning rate graph"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b6f6987",
   "metadata": {},
   "source": [
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20386c4b",
   "metadata": {},
   "source": [
    "## training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c27b290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss=None, optimizer=None, train_dataloader=None, val_dataloader=None, nb_epochs=20):\n",
    "    \"\"\"Training loop\"\"\"\n",
    "\n",
    "    min_f1 = -torch.inf\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Iterrate over epochs\n",
    "    for e in range(nb_epochs):\n",
    "\n",
    "        # Training\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for i, batch in enumerate(tqdm(train_dataloader)):            \n",
    "            \n",
    "            #print(i)\n",
    "            # unpack batch             \n",
    "            labels = batch['label'].to(device)\n",
    "            spans = batch['spans'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            \n",
    "            inputs = input_ids, spans\n",
    "            \n",
    "            # Reset gradients to 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute training loss\n",
    "            current_loss = loss(outputs.flatten(0,1), labels.flatten())\n",
    "            train_loss += current_loss.detach().item()\n",
    "\n",
    "            # Compute gradients\n",
    "            current_loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()            \n",
    "            \n",
    "            del batch\n",
    "        \n",
    "        scheduler.step()\n",
    "            \n",
    "        \n",
    "        # Validation\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        # torch.cuda.empty_cache()\n",
    "        \n",
    "        # Put model in eval mode\n",
    "        model.eval()\n",
    "        \n",
    "        preds_l = []\n",
    "        labels_l = []\n",
    "        \n",
    "        for batch in tqdm(val_dataloader):            \n",
    "            \n",
    "            # unpack batch             \n",
    "            labels = batch['label'].to(device)\n",
    "            spans = batch['spans'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            \n",
    "            inputs = input_ids, spans\n",
    "            \n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute validation loss\n",
    "            current_loss = loss(outputs.flatten(0,1), labels.flatten())\n",
    "            val_loss += current_loss.detach().item()\n",
    "            \n",
    "            preds_for_f1 = torch.argmax(outputs, dim=2).flatten().tolist()\n",
    "            labels_for_f1 = labels.flatten().tolist()\n",
    "            \n",
    "            preds_l.append(preds_for_f1)\n",
    "            labels_l.append(labels_for_f1)\n",
    "            \n",
    "            del batch\n",
    "        \n",
    "        # Prints\n",
    "        \n",
    "        preds_l = flatten_list(preds_l)\n",
    "        labels_l = flatten_list(labels_l)\n",
    "        \n",
    "        preds_l, labels_l = remove_dummy_labels(preds_l, labels_l)\n",
    "        \n",
    "        f1_score_epoch = f1_score(preds_l, labels_l, average='macro')        \n",
    "        \n",
    "        print(f\"Epoch {e+1}/{nb_epochs} \\\n",
    "                \\t Training Loss: {train_loss/len(train_dataloader):.3f} \\\n",
    "                \\t Validation Loss: {val_loss/len(val_dataloader):.3f} \\\n",
    "                \\t F1 score: {f1_score_epoch}\")\n",
    "        \n",
    "        train_losses.append(train_loss/len(train_dataloader))\n",
    "        val_losses.append(val_loss/len(val_dataloader))\n",
    "        \n",
    "\n",
    "        # Save model if val loss decreases\n",
    "        if f1_score_epoch > min_f1:\n",
    "\n",
    "            min_f1 = f1_score_epoch\n",
    "            torch.save(model.first_model.state_dict(), 'first_model.pt')\n",
    "            torch.save(model.model_am.state_dict(), 'model_am.pt')\n",
    "            torch.save(model.model_ac.state_dict(), 'model_ac.pt')\n",
    "            torch.save(model.model_fts.state_dict(), 'model_fts.pt')\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "            \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20c18962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.07s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40                 \t Training Loss: 0.697                 \t Validation Loss: 0.676                 \t F1 score: 0.5753529649052036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40                 \t Training Loss: 0.694                 \t Validation Loss: 0.517                 \t F1 score: 0.7384110387850805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:50<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40                 \t Training Loss: 0.452                 \t Validation Loss: 0.466                 \t F1 score: 0.7797768894264737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40                 \t Training Loss: 0.364                 \t Validation Loss: 0.466                 \t F1 score: 0.7597515684577049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40                 \t Training Loss: 0.221                 \t Validation Loss: 0.628                 \t F1 score: 0.7623178729150615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:50<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40                 \t Training Loss: 0.142                 \t Validation Loss: 0.730                 \t F1 score: 0.7682215287346066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40                 \t Training Loss: 0.134                 \t Validation Loss: 0.663                 \t F1 score: 0.7911012084848417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:50<00:00,  1.10s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40                 \t Training Loss: 0.100                 \t Validation Loss: 0.880                 \t F1 score: 0.761625364633208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:50<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40                 \t Training Loss: 0.075                 \t Validation Loss: 0.863                 \t F1 score: 0.757395813328212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:50<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40                 \t Training Loss: 0.087                 \t Validation Loss: 0.965                 \t F1 score: 0.7759479282713068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:50<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40                 \t Training Loss: 0.058                 \t Validation Loss: 0.807                 \t F1 score: 0.7794695398519568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40                 \t Training Loss: 0.075                 \t Validation Loss: 0.894                 \t F1 score: 0.7724137931034483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40                 \t Training Loss: 0.105                 \t Validation Loss: 0.744                 \t F1 score: 0.7872865638888269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40                 \t Training Loss: 0.101                 \t Validation Loss: 0.794                 \t F1 score: 0.7683703462708813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40                 \t Training Loss: 0.093                 \t Validation Loss: 0.807                 \t F1 score: 0.7687176760597418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/40                 \t Training Loss: 0.101                 \t Validation Loss: 0.680                 \t F1 score: 0.7764658213366384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40                 \t Training Loss: 0.128                 \t Validation Loss: 0.803                 \t F1 score: 0.7884386335336473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40                 \t Training Loss: 0.071                 \t Validation Loss: 0.934                 \t F1 score: 0.7702561919083941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40                 \t Training Loss: 0.066                 \t Validation Loss: 0.934                 \t F1 score: 0.7701750334826583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:50<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40                 \t Training Loss: 0.147                 \t Validation Loss: 0.767                 \t F1 score: 0.7658827658827658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40                 \t Training Loss: 0.198                 \t Validation Loss: 0.691                 \t F1 score: 0.7378569107200891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:50<00:00,  1.09s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40                 \t Training Loss: 0.241                 \t Validation Loss: 0.873                 \t F1 score: 0.37573385518591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40                 \t Training Loss: 0.695                 \t Validation Loss: 0.676                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/40                 \t Training Loss: 0.681                 \t Validation Loss: 0.686                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/40                 \t Training Loss: 0.679                 \t Validation Loss: 0.683                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40                 \t Training Loss: 0.682                 \t Validation Loss: 0.699                 \t F1 score: 0.28421839940164545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/40                 \t Training Loss: 0.691                 \t Validation Loss: 0.673                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/40                 \t Training Loss: 0.680                 \t Validation Loss: 0.674                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/40                 \t Training Loss: 0.681                 \t Validation Loss: 0.683                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/40                 \t Training Loss: 0.695                 \t Validation Loss: 0.677                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40                 \t Training Loss: 0.682                 \t Validation Loss: 0.706                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/40                 \t Training Loss: 0.683                 \t Validation Loss: 0.683                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/40                 \t Training Loss: 0.681                 \t Validation Loss: 0.680                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/40                 \t Training Loss: 0.678                 \t Validation Loss: 0.689                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/40                 \t Training Loss: 0.687                 \t Validation Loss: 0.697                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/40                 \t Training Loss: 0.687                 \t Validation Loss: 0.672                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/40                 \t Training Loss: 0.678                 \t Validation Loss: 0.672                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/40                 \t Training Loss: 0.677                 \t Validation Loss: 0.674                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/40                 \t Training Loss: 0.677                 \t Validation Loss: 0.677                 \t F1 score: 0.37614080834419816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:49<00:00,  1.08s/it]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40                 \t Training Loss: 0.677                 \t Validation Loss: 0.672                 \t F1 score: 0.37614080834419816\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train(custom_model, loss, optimizer, train_dataloader, val_dataloader, NB_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22a766",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "921e3cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load best model\n",
    "# network_2 = Network()\n",
    "\n",
    "# network_2.load_state_dict(torch.load(path))\n",
    "# network_2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09667a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(dataset['test'], batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4cc0be85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model =  BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "first_model.load_state_dict(torch.load('first_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac8ecc61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first_model = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))\n",
    "# first_model.load_state_dict(torch.load('first_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3321c629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_am = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))\n",
    "model_am.load_state_dict(torch.load('model_am.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01142d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ac = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))\n",
    "model_ac.load_state_dict(torch.load('model_ac.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f38eaae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fts = BertModel(BertConfig.from_pretrained(\"bert-base-uncased\"))\n",
    "model_fts.load_state_dict(torch.load('model_fts.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c9aa9377",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomBERTKuri(\n",
       "  (first_model): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       "  (intermediate_linear_am): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (intermediate_linear_ac): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (intermediate_linear_fts): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (model_am): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (model_ac): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (model_fts): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=2304, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best model\n",
    "\n",
    "# custom_model_2 = CustomBERTKuri(first_model, model_am, model_ac, model_fts, 3)\n",
    "custom_model_2 = CustomBERTKuri(first_model, model_am, model_ac, model_fts, 2)\n",
    "custom_model_2.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "custom_model_2.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "92890a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_dataloader=None):\n",
    "    \n",
    "    \"\"\"Prediction loop\"\"\"\n",
    "\n",
    "    preds_l = []\n",
    "    labels_l = []\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch in test_dataloader:            \n",
    "            \n",
    "        # unpack batch             \n",
    "        labels = batch['label'].to(device).flatten().tolist()\n",
    "        spans = batch['spans'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        \n",
    "        inputs = input_ids, spans\n",
    "\n",
    "        # get output\n",
    "        \n",
    "        raw_preds = model(inputs).to('cpu')\n",
    "        # print(raw_preds.shape)\n",
    "        raw_preds = raw_preds.detach()#.numpy()\n",
    "\n",
    "        # Compute argmax\n",
    "        \n",
    "        predictions = torch.argmax(raw_preds, dim=2).flatten().tolist()\n",
    "        preds_l.append(predictions)\n",
    "        labels_l.append(labels)        \n",
    "        \n",
    "        del batch\n",
    "            \n",
    "    return flatten_list(preds_l), flatten_list(labels_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f6a62685",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test_preds, test_labels = predict(custom_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c45d134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(test_labels, test_preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c2f84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove -100s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3dcb91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_preds_l, test_labels_l = remove_dummy_labels(test_preds, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f8ab92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(test_labels_l, test_preds_l, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bd84003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### -100 done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a5f48ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_preds, test_labels = predict(custom_model_2, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4c998d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -100      0.000     0.000     0.000      3033\n",
      "           0      0.132     0.766     0.225       518\n",
      "           1      0.478     0.820     0.604       745\n",
      "\n",
      "    accuracy                          0.235      4296\n",
      "   macro avg      0.203     0.529     0.276      4296\n",
      "weighted avg      0.099     0.235     0.132      4296\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, test_preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b217f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_l, test_labels_l = remove_dummy_labels(test_preds, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e8a03111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.748     0.766     0.757       518\n",
      "           1      0.835     0.820     0.827       745\n",
      "\n",
      "    accuracy                          0.798      1263\n",
      "   macro avg      0.791     0.793     0.792      1263\n",
      "weighted avg      0.799     0.798     0.798      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels_l, test_preds_l, digits=3))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92fb0183",
   "metadata": {},
   "source": [
    " precision    recall  f1-score   support\n",
    "\n",
    "           0      0.820     0.697     0.754       518\n",
    "           1      0.809     0.894     0.849       745\n",
    "\n",
    "    accuracy                          0.813      1263\n",
    "   macro avg      0.815     0.795     0.802      1263\n",
    "weighted avg      0.814     0.813     0.810      1263\n",
    "\n",
    "link identification, lr= w LR, batch size = 24, first model from icann finetune"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63d89ed4",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "           0      0.790     0.768     0.779       518\n",
    "           1      0.842     0.858     0.850       745\n",
    "\n",
    "    accuracy                          0.821      1263\n",
    "   macro avg      0.816     0.813     0.814      1263\n",
    "weighted avg      0.820     0.821     0.821      1263\n",
    "\n",
    "link identification, lr= w/o LR i.e. 0.0035111917342151295, batch size = 24, first model from icann finetune"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9099d12",
   "metadata": {},
   "source": [
    " precision    recall  f1-score   support\n",
    "\n",
    "           0      0.752     0.633     0.688       518\n",
    "           1      0.770     0.855     0.810       745\n",
    "\n",
    "    accuracy                          0.764      1263\n",
    "   macro avg      0.761     0.744     0.749      1263\n",
    "weighted avg      0.763     0.764     0.760      1263\n",
    "\n",
    "link identification, lr= from LR , batch size = 24, same default models"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecdabdd6",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "           0      0.745     0.726     0.735       518\n",
    "           1      0.813     0.827     0.820       745\n",
    "\n",
    "    accuracy                          0.785      1263\n",
    "   macro avg      0.779     0.776     0.777      1263\n",
    "weighted avg      0.785     0.785     0.785      1263\n",
    "\n",
    "link identification, lr 0.0035111917342151295, batch size = 24, same default models"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9d022d2",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "           0      0.877     0.916     0.896       155\n",
    "           1      0.728     0.644     0.683       303\n",
    "           2      0.893     0.924     0.908       805\n",
    "\n",
    "    accuracy                          0.856      1263\n",
    "   macro avg      0.832     0.828     0.829      1263\n",
    "weighted avg      0.851     0.856     0.853      1263\n",
    "\n",
    "combined, 24 batch size,  0.0035111917342151295"
   ]
  },
  {
   "cell_type": "raw",
   "id": "472ddf9c",
   "metadata": {},
   "source": [
    " precision    recall  f1-score   support\n",
    "\n",
    "           0      0.815     0.968     0.885       155\n",
    "           1      0.679     0.663     0.671       303\n",
    "           2      0.907     0.882     0.894       805\n",
    "\n",
    "    accuracy                          0.840      1263\n",
    "   macro avg      0.800     0.838     0.817      1263\n",
    "weighted avg      0.841     0.840     0.840      1263\n",
    "\n",
    "combined, 24 batch size, lr = 0.006579332246575687"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94c898f",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "           0      0.893     0.865     0.879       155\n",
    "           1      0.663     0.683     0.673       303\n",
    "           2      0.896     0.892     0.894       805\n",
    "\n",
    "    accuracy                          0.838      1263\n",
    "   macro avg      0.818     0.813     0.815      1263\n",
    "weighted avg      0.840     0.838     0.839      1263\n",
    "\n",
    "12 batch size, 0.006579332246575687"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22723b4b",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "           0      0.852     0.890     0.871       155\n",
    "           1      0.662     0.647     0.654       303\n",
    "           2      0.893     0.893     0.893       805\n",
    "\n",
    "    accuracy                          0.834      1263\n",
    "   macro avg      0.802     0.810     0.806      1263\n",
    "weighted avg      0.833     0.834     0.833      1263\n",
    "\n",
    "12 batch size, 9.999999999999997e-06 lr"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86d2dd2c",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "           0      0.760     0.839     0.798       155\n",
    "           1      0.577     0.535     0.555       303\n",
    "           2      0.862     0.868     0.865       805\n",
    "\n",
    "    accuracy                          0.785      1263\n",
    "   macro avg      0.733     0.747     0.739      1263\n",
    "weighted avg      0.781     0.785     0.782      1263\n",
    "\n",
    "12 batch size, w 1.87 lr"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d7a805a",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "           0      0.925     0.716     0.807       155\n",
    "           1      0.585     0.693     0.634       303\n",
    "           2      0.883     0.860     0.871       805\n",
    "\n",
    "    accuracy                          0.802      1263\n",
    "   macro avg      0.798     0.756     0.771      1263\n",
    "weighted avg      0.816     0.802     0.806      1263\n",
    "\n",
    "w leslie smith LR, 12 batch size"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1be5a188",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "           0      0.897     0.677     0.772       155\n",
    "           1      0.577     0.640     0.607       303\n",
    "           2      0.869     0.875     0.872       805\n",
    "\n",
    "    accuracy                          0.794      1263\n",
    "   macro avg      0.781     0.731     0.750      1263\n",
    "weighted avg      0.803     0.794     0.796      1263\n",
    "\n",
    "40 epochs. learning rate: 1.8e-5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "721f3393",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "           0      0.803     0.735     0.768       155\n",
    "           1      0.604     0.508     0.552       303\n",
    "           2      0.843     0.907     0.874       805\n",
    "\n",
    "    accuracy                          0.790      1263\n",
    "   macro avg      0.750     0.717     0.731      1263\n",
    "weighted avg      0.781     0.790     0.784      1263\n",
    "\n",
    "40 epochs. learning rate: 9.999997e-6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
